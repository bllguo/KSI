{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, LSTMattn\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 100 # 200 in paper, but too intensive for my machine\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False\n",
    "model_type = 'LSTMattn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMattn                                 --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-3                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-4                            --                        34,400\n",
       "├─Linear: 1-5                            --                        34,744\n",
       "==========================================================================================\n",
       "Total params: 4,946,144\n",
       "Trainable params: 4,946,144\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.50\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 125.70\n",
       "Params size (MB): 19.78\n",
       "Estimated Total Size (MB): 147.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = LSTMattn(n_words, n_wiki, n_embedding, n_hidden, batch_size)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.4406, Val Recall@10: 0.4461, Train Micro F1: 0.0000, Val Micro F1: 0.0000, Train Macro F1: 0.0000, Val Macro F1: 0.0000, Train Micro AUC: 0.9250, Val Micro AUC: 0.9104, Train Macro AUC: 0.5820, Val Macro AUC: 0.5881\n",
      "Epoch: 002, Train Recall@10: 0.5104, Val Recall@10: 0.5133, Train Micro F1: 0.3573, Val Micro F1: 0.3602, Train Macro F1: 0.0168, Val Macro F1: 0.0205, Train Micro AUC: 0.9350, Val Micro AUC: 0.9214, Train Macro AUC: 0.6035, Val Macro AUC: 0.6123\n",
      "Epoch: 003, Train Recall@10: 0.6852, Val Recall@10: 0.6824, Train Micro F1: 0.5851, Val Micro F1: 0.5820, Train Macro F1: 0.0612, Val Macro F1: 0.0733, Train Micro AUC: 0.9579, Val Micro AUC: 0.9486, Train Macro AUC: 0.6929, Val Macro AUC: 0.7063\n",
      "Epoch: 004, Train Recall@10: 0.7698, Val Recall@10: 0.7623, Train Micro F1: 0.6401, Val Micro F1: 0.6338, Train Macro F1: 0.1198, Val Macro F1: 0.1440, Train Micro AUC: 0.9720, Val Micro AUC: 0.9653, Train Macro AUC: 0.7649, Val Macro AUC: 0.7748\n",
      "Epoch: 005, Train Recall@10: 0.8034, Val Recall@10: 0.7939, Train Micro F1: 0.6629, Val Micro F1: 0.6518, Train Macro F1: 0.1547, Val Macro F1: 0.1828, Train Micro AUC: 0.9786, Val Micro AUC: 0.9727, Train Macro AUC: 0.8147, Val Macro AUC: 0.8221\n",
      "Epoch: 006, Train Recall@10: 0.8161, Val Recall@10: 0.8011, Train Micro F1: 0.6707, Val Micro F1: 0.6534, Train Macro F1: 0.1782, Val Macro F1: 0.2076, Train Micro AUC: 0.9813, Val Micro AUC: 0.9748, Train Macro AUC: 0.8485, Val Macro AUC: 0.8345\n",
      "Epoch: 007, Train Recall@10: 0.8244, Val Recall@10: 0.8043, Train Micro F1: 0.6763, Val Micro F1: 0.6569, Train Macro F1: 0.1938, Val Macro F1: 0.2223, Train Micro AUC: 0.9831, Val Micro AUC: 0.9759, Train Macro AUC: 0.8799, Val Macro AUC: 0.8533\n",
      "Epoch: 008, Train Recall@10: 0.8293, Val Recall@10: 0.8077, Train Micro F1: 0.6866, Val Micro F1: 0.6631, Train Macro F1: 0.2057, Val Macro F1: 0.2352, Train Micro AUC: 0.9843, Val Micro AUC: 0.9768, Train Macro AUC: 0.8984, Val Macro AUC: 0.8599\n",
      "Epoch: 009, Train Recall@10: 0.8369, Val Recall@10: 0.8108, Train Micro F1: 0.6925, Val Micro F1: 0.6654, Train Macro F1: 0.2189, Val Macro F1: 0.2466, Train Micro AUC: 0.9854, Val Micro AUC: 0.9775, Train Macro AUC: 0.9160, Val Macro AUC: 0.8709\n",
      "Epoch: 010, Train Recall@10: 0.8407, Val Recall@10: 0.8134, Train Micro F1: 0.6967, Val Micro F1: 0.6677, Train Macro F1: 0.2221, Val Macro F1: 0.2469, Train Micro AUC: 0.9863, Val Micro AUC: 0.9780, Train Macro AUC: 0.9211, Val Macro AUC: 0.8719\n",
      "Epoch: 011, Train Recall@10: 0.8454, Val Recall@10: 0.8144, Train Micro F1: 0.7016, Val Micro F1: 0.6698, Train Macro F1: 0.2331, Val Macro F1: 0.2510, Train Micro AUC: 0.9872, Val Micro AUC: 0.9781, Train Macro AUC: 0.9297, Val Macro AUC: 0.8736\n",
      "Epoch: 012, Train Recall@10: 0.8498, Val Recall@10: 0.8166, Train Micro F1: 0.7036, Val Micro F1: 0.6686, Train Macro F1: 0.2397, Val Macro F1: 0.2597, Train Micro AUC: 0.9879, Val Micro AUC: 0.9782, Train Macro AUC: 0.9320, Val Macro AUC: 0.8753\n",
      "Epoch: 013, Train Recall@10: 0.8553, Val Recall@10: 0.8155, Train Micro F1: 0.7102, Val Micro F1: 0.6710, Train Macro F1: 0.2521, Val Macro F1: 0.2715, Train Micro AUC: 0.9886, Val Micro AUC: 0.9782, Train Macro AUC: 0.9435, Val Macro AUC: 0.8710\n",
      "Epoch: 014, Train Recall@10: 0.8596, Val Recall@10: 0.8179, Train Micro F1: 0.7148, Val Micro F1: 0.6742, Train Macro F1: 0.2603, Val Macro F1: 0.2787, Train Micro AUC: 0.9893, Val Micro AUC: 0.9788, Train Macro AUC: 0.9514, Val Macro AUC: 0.8787\n",
      "Epoch: 015, Train Recall@10: 0.8637, Val Recall@10: 0.8186, Train Micro F1: 0.7192, Val Micro F1: 0.6738, Train Macro F1: 0.2759, Val Macro F1: 0.2787, Train Micro AUC: 0.9900, Val Micro AUC: 0.9784, Train Macro AUC: 0.9588, Val Macro AUC: 0.8753\n",
      "Epoch: 016, Train Recall@10: 0.8685, Val Recall@10: 0.8188, Train Micro F1: 0.7244, Val Micro F1: 0.6745, Train Macro F1: 0.2844, Val Macro F1: 0.2821, Train Micro AUC: 0.9905, Val Micro AUC: 0.9782, Train Macro AUC: 0.9620, Val Macro AUC: 0.8736\n",
      "Epoch: 017, Train Recall@10: 0.8740, Val Recall@10: 0.8206, Train Micro F1: 0.7313, Val Micro F1: 0.6781, Train Macro F1: 0.2985, Val Macro F1: 0.2887, Train Micro AUC: 0.9912, Val Micro AUC: 0.9785, Train Macro AUC: 0.9649, Val Macro AUC: 0.8749\n",
      "Epoch: 018, Train Recall@10: 0.8789, Val Recall@10: 0.8208, Train Micro F1: 0.7360, Val Micro F1: 0.6774, Train Macro F1: 0.3066, Val Macro F1: 0.2960, Train Micro AUC: 0.9918, Val Micro AUC: 0.9782, Train Macro AUC: 0.9696, Val Macro AUC: 0.8734\n",
      "Epoch: 019, Train Recall@10: 0.8823, Val Recall@10: 0.8192, Train Micro F1: 0.7414, Val Micro F1: 0.6777, Train Macro F1: 0.3270, Val Macro F1: 0.2952, Train Micro AUC: 0.9922, Val Micro AUC: 0.9779, Train Macro AUC: 0.9712, Val Macro AUC: 0.8728\n",
      "Epoch: 020, Train Recall@10: 0.8861, Val Recall@10: 0.8192, Train Micro F1: 0.7452, Val Micro F1: 0.6770, Train Macro F1: 0.3370, Val Macro F1: 0.2985, Train Micro AUC: 0.9926, Val Micro AUC: 0.9777, Train Macro AUC: 0.9735, Val Macro AUC: 0.8717\n",
      "Epoch: 021, Train Recall@10: 0.8892, Val Recall@10: 0.8182, Train Micro F1: 0.7477, Val Micro F1: 0.6778, Train Macro F1: 0.3454, Val Macro F1: 0.2984, Train Micro AUC: 0.9929, Val Micro AUC: 0.9776, Train Macro AUC: 0.9747, Val Macro AUC: 0.8705\n",
      "Epoch: 022, Train Recall@10: 0.8909, Val Recall@10: 0.8183, Train Micro F1: 0.7491, Val Micro F1: 0.6766, Train Macro F1: 0.3483, Val Macro F1: 0.3033, Train Micro AUC: 0.9931, Val Micro AUC: 0.9775, Train Macro AUC: 0.9755, Val Macro AUC: 0.8708\n",
      "Epoch: 023, Train Recall@10: 0.8925, Val Recall@10: 0.8183, Train Micro F1: 0.7501, Val Micro F1: 0.6770, Train Macro F1: 0.3514, Val Macro F1: 0.3035, Train Micro AUC: 0.9933, Val Micro AUC: 0.9774, Train Macro AUC: 0.9762, Val Macro AUC: 0.8689\n",
      "Epoch: 024, Train Recall@10: 0.8928, Val Recall@10: 0.8184, Train Micro F1: 0.7502, Val Micro F1: 0.6763, Train Macro F1: 0.3535, Val Macro F1: 0.3022, Train Micro AUC: 0.9933, Val Micro AUC: 0.9774, Train Macro AUC: 0.9763, Val Macro AUC: 0.8691\n",
      "Epoch: 025, Train Recall@10: 0.8929, Val Recall@10: 0.8187, Train Micro F1: 0.7504, Val Micro F1: 0.6773, Train Macro F1: 0.3536, Val Macro F1: 0.3030, Train Micro AUC: 0.9933, Val Micro AUC: 0.9774, Train Macro AUC: 0.9763, Val Macro AUC: 0.8691\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path=f'./log/{model_type}',\n",
    "                        device=DEVICE,\n",
    "                        init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}{model_type}_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.8179, Test Micro F1: 0.6785, Test Macro F1: 0.2844, Test Micro AUC: 0.9788, Test Macro AUC: 0.8617\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   by_label=False,\n",
    "                                                                                                   device=DEVICE,\n",
    "                                                                                                   init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMattn                                 --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,104,601\n",
       "Trainable params: 6,104,601\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 143.40\n",
       "Params size (MB): 24.42\n",
       "Estimated Total Size (MB): 186.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = LSTMattn(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6381, Val Recall@10: 0.6367, Train Micro F1: 0.3920, Val Micro F1: 0.3868, Train Macro F1: 0.0458, Val Macro F1: 0.0537, Train Micro AUC: 0.9640, Val Micro AUC: 0.9561, Train Macro AUC: 0.8051, Val Macro AUC: 0.8029\n",
      "Epoch: 002, Train Recall@10: 0.6889, Val Recall@10: 0.6802, Train Micro F1: 0.4564, Val Micro F1: 0.4487, Train Macro F1: 0.0823, Val Macro F1: 0.0936, Train Micro AUC: 0.9699, Val Micro AUC: 0.9615, Train Macro AUC: 0.8565, Val Macro AUC: 0.8349\n",
      "Epoch: 003, Train Recall@10: 0.7583, Val Recall@10: 0.7427, Train Micro F1: 0.5575, Val Micro F1: 0.5412, Train Macro F1: 0.1407, Val Macro F1: 0.1457, Train Micro AUC: 0.9770, Val Micro AUC: 0.9685, Train Macro AUC: 0.8871, Val Macro AUC: 0.8555\n",
      "Epoch: 004, Train Recall@10: 0.7891, Val Recall@10: 0.7700, Train Micro F1: 0.6172, Val Micro F1: 0.5954, Train Macro F1: 0.1966, Val Macro F1: 0.1939, Train Micro AUC: 0.9810, Val Micro AUC: 0.9721, Train Macro AUC: 0.9136, Val Macro AUC: 0.8664\n",
      "Epoch: 005, Train Recall@10: 0.8065, Val Recall@10: 0.7799, Train Micro F1: 0.6374, Val Micro F1: 0.6074, Train Macro F1: 0.2273, Val Macro F1: 0.2131, Train Micro AUC: 0.9834, Val Micro AUC: 0.9734, Train Macro AUC: 0.9270, Val Macro AUC: 0.8679\n",
      "Epoch: 006, Train Recall@10: 0.8147, Val Recall@10: 0.7806, Train Micro F1: 0.6512, Val Micro F1: 0.6146, Train Macro F1: 0.2527, Val Macro F1: 0.2316, Train Micro AUC: 0.9842, Val Micro AUC: 0.9736, Train Macro AUC: 0.9315, Val Macro AUC: 0.8693\n",
      "Epoch: 007, Train Recall@10: 0.8180, Val Recall@10: 0.7820, Train Micro F1: 0.6628, Val Micro F1: 0.6248, Train Macro F1: 0.2633, Val Macro F1: 0.2373, Train Micro AUC: 0.9847, Val Micro AUC: 0.9736, Train Macro AUC: 0.9385, Val Macro AUC: 0.8695\n",
      "Epoch: 008, Train Recall@10: 0.8166, Val Recall@10: 0.7813, Train Micro F1: 0.6493, Val Micro F1: 0.6063, Train Macro F1: 0.2535, Val Macro F1: 0.2186, Train Micro AUC: 0.9847, Val Micro AUC: 0.9728, Train Macro AUC: 0.9364, Val Macro AUC: 0.8627\n",
      "Epoch: 009, Train Recall@10: 0.8216, Val Recall@10: 0.7840, Train Micro F1: 0.6587, Val Micro F1: 0.6178, Train Macro F1: 0.2876, Val Macro F1: 0.2492, Train Micro AUC: 0.9849, Val Micro AUC: 0.9724, Train Macro AUC: 0.9420, Val Macro AUC: 0.8655\n",
      "Epoch: 010, Train Recall@10: 0.8270, Val Recall@10: 0.7838, Train Micro F1: 0.6607, Val Micro F1: 0.6166, Train Macro F1: 0.2889, Val Macro F1: 0.2451, Train Micro AUC: 0.9857, Val Micro AUC: 0.9723, Train Macro AUC: 0.9443, Val Macro AUC: 0.8632\n",
      "Epoch: 011, Train Recall@10: 0.8319, Val Recall@10: 0.7868, Train Micro F1: 0.6724, Val Micro F1: 0.6250, Train Macro F1: 0.3096, Val Macro F1: 0.2610, Train Micro AUC: 0.9864, Val Micro AUC: 0.9731, Train Macro AUC: 0.9467, Val Macro AUC: 0.8653\n",
      "Epoch: 012, Train Recall@10: 0.8351, Val Recall@10: 0.7865, Train Micro F1: 0.6828, Val Micro F1: 0.6302, Train Macro F1: 0.3422, Val Macro F1: 0.2745, Train Micro AUC: 0.9868, Val Micro AUC: 0.9727, Train Macro AUC: 0.9523, Val Macro AUC: 0.8653\n",
      "Epoch: 013, Train Recall@10: 0.8385, Val Recall@10: 0.7897, Train Micro F1: 0.6835, Val Micro F1: 0.6295, Train Macro F1: 0.3401, Val Macro F1: 0.2693, Train Micro AUC: 0.9871, Val Micro AUC: 0.9731, Train Macro AUC: 0.9524, Val Macro AUC: 0.8685\n",
      "Epoch: 014, Train Recall@10: 0.8453, Val Recall@10: 0.7857, Train Micro F1: 0.6885, Val Micro F1: 0.6299, Train Macro F1: 0.3720, Val Macro F1: 0.2810, Train Micro AUC: 0.9881, Val Micro AUC: 0.9729, Train Macro AUC: 0.9583, Val Macro AUC: 0.8640\n",
      "Epoch: 015, Train Recall@10: 0.8537, Val Recall@10: 0.7859, Train Micro F1: 0.7027, Val Micro F1: 0.6362, Train Macro F1: 0.3933, Val Macro F1: 0.2759, Train Micro AUC: 0.9892, Val Micro AUC: 0.9735, Train Macro AUC: 0.9641, Val Macro AUC: 0.8696\n",
      "Epoch: 016, Train Recall@10: 0.8616, Val Recall@10: 0.7891, Train Micro F1: 0.7154, Val Micro F1: 0.6417, Train Macro F1: 0.4305, Val Macro F1: 0.2960, Train Micro AUC: 0.9903, Val Micro AUC: 0.9739, Train Macro AUC: 0.9685, Val Macro AUC: 0.8718\n",
      "Epoch: 017, Train Recall@10: 0.8670, Val Recall@10: 0.7888, Train Micro F1: 0.7188, Val Micro F1: 0.6383, Train Macro F1: 0.4587, Val Macro F1: 0.2935, Train Micro AUC: 0.9909, Val Micro AUC: 0.9735, Train Macro AUC: 0.9715, Val Macro AUC: 0.8655\n",
      "Epoch: 018, Train Recall@10: 0.8719, Val Recall@10: 0.7897, Train Micro F1: 0.7227, Val Micro F1: 0.6322, Train Macro F1: 0.4639, Val Macro F1: 0.2900, Train Micro AUC: 0.9915, Val Micro AUC: 0.9732, Train Macro AUC: 0.9740, Val Macro AUC: 0.8665\n",
      "Epoch: 019, Train Recall@10: 0.8796, Val Recall@10: 0.7901, Train Micro F1: 0.7315, Val Micro F1: 0.6367, Train Macro F1: 0.4870, Val Macro F1: 0.2945, Train Micro AUC: 0.9923, Val Micro AUC: 0.9736, Train Macro AUC: 0.9766, Val Macro AUC: 0.8645\n",
      "Epoch: 020, Train Recall@10: 0.8866, Val Recall@10: 0.7928, Train Micro F1: 0.7394, Val Micro F1: 0.6375, Train Macro F1: 0.5078, Val Macro F1: 0.2990, Train Micro AUC: 0.9930, Val Micro AUC: 0.9737, Train Macro AUC: 0.9795, Val Macro AUC: 0.8658\n",
      "Epoch: 021, Train Recall@10: 0.8944, Val Recall@10: 0.7952, Train Micro F1: 0.7539, Val Micro F1: 0.6453, Train Macro F1: 0.5553, Val Macro F1: 0.3069, Train Micro AUC: 0.9937, Val Micro AUC: 0.9743, Train Macro AUC: 0.9820, Val Macro AUC: 0.8668\n",
      "Epoch: 022, Train Recall@10: 0.9014, Val Recall@10: 0.7966, Train Micro F1: 0.7635, Val Micro F1: 0.6475, Train Macro F1: 0.5782, Val Macro F1: 0.3095, Train Micro AUC: 0.9943, Val Micro AUC: 0.9745, Train Macro AUC: 0.9839, Val Macro AUC: 0.8683\n",
      "Epoch: 023, Train Recall@10: 0.9060, Val Recall@10: 0.7971, Train Micro F1: 0.7693, Val Micro F1: 0.6472, Train Macro F1: 0.5927, Val Macro F1: 0.3068, Train Micro AUC: 0.9947, Val Micro AUC: 0.9746, Train Macro AUC: 0.9853, Val Macro AUC: 0.8674\n",
      "Epoch: 024, Train Recall@10: 0.9086, Val Recall@10: 0.7983, Train Micro F1: 0.7738, Val Micro F1: 0.6495, Train Macro F1: 0.5970, Val Macro F1: 0.3116, Train Micro AUC: 0.9949, Val Micro AUC: 0.9748, Train Macro AUC: 0.9860, Val Macro AUC: 0.8647\n",
      "Epoch: 025, Train Recall@10: 0.9095, Val Recall@10: 0.7977, Train Micro F1: 0.7734, Val Micro F1: 0.6484, Train Macro F1: 0.5978, Val Macro F1: 0.3101, Train Micro AUC: 0.9950, Val Micro AUC: 0.9748, Train Macro AUC: 0.9861, Val Macro AUC: 0.8653\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path=f'./log/{model_type}_KSI',\n",
    "                       device=DEVICE,\n",
    "                       init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}{model_type}_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7960, Test Micro F1: 0.6460, Test Macro F1: 0.2915, Test Micro AUC: 0.9765, Test Macro AUC: 0.8754\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMattn                                 --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,104,603\n",
       "Trainable params: 6,104,603\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.40\n",
       "Params size (MB): 24.42\n",
       "Estimated Total Size (MB): 1258.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = LSTMattn(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6451, Val Recall@10: 0.6446, Train Micro F1: 0.4168, Val Micro F1: 0.4139, Train Macro F1: 0.0290, Val Macro F1: 0.0347, Train Micro AUC: 0.9630, Val Micro AUC: 0.9558, Train Macro AUC: 0.8041, Val Macro AUC: 0.8172\n",
      "Epoch: 002, Train Recall@10: 0.7118, Val Recall@10: 0.7086, Train Micro F1: 0.4962, Val Micro F1: 0.4906, Train Macro F1: 0.0999, Val Macro F1: 0.1220, Train Micro AUC: 0.9734, Val Micro AUC: 0.9673, Train Macro AUC: 0.8594, Val Macro AUC: 0.8609\n",
      "Epoch: 003, Train Recall@10: 0.7361, Val Recall@10: 0.7312, Train Micro F1: 0.5287, Val Micro F1: 0.5227, Train Macro F1: 0.1250, Val Macro F1: 0.1406, Train Micro AUC: 0.9763, Val Micro AUC: 0.9704, Train Macro AUC: 0.8742, Val Macro AUC: 0.8682\n",
      "Epoch: 004, Train Recall@10: 0.7839, Val Recall@10: 0.7763, Train Micro F1: 0.6059, Val Micro F1: 0.5961, Train Macro F1: 0.1624, Val Macro F1: 0.1763, Train Micro AUC: 0.9809, Val Micro AUC: 0.9753, Train Macro AUC: 0.8964, Val Macro AUC: 0.8869\n",
      "Epoch: 005, Train Recall@10: 0.8080, Val Recall@10: 0.7975, Train Micro F1: 0.6433, Val Micro F1: 0.6282, Train Macro F1: 0.1906, Val Macro F1: 0.2064, Train Micro AUC: 0.9836, Val Micro AUC: 0.9779, Train Macro AUC: 0.9100, Val Macro AUC: 0.9024\n",
      "Epoch: 006, Train Recall@10: 0.8259, Val Recall@10: 0.8086, Train Micro F1: 0.6651, Val Micro F1: 0.6432, Train Macro F1: 0.2206, Val Macro F1: 0.2232, Train Micro AUC: 0.9854, Val Micro AUC: 0.9793, Train Macro AUC: 0.9236, Val Macro AUC: 0.9096\n",
      "Epoch: 007, Train Recall@10: 0.8354, Val Recall@10: 0.8123, Train Micro F1: 0.6782, Val Micro F1: 0.6499, Train Macro F1: 0.2534, Val Macro F1: 0.2459, Train Micro AUC: 0.9866, Val Micro AUC: 0.9797, Train Macro AUC: 0.9319, Val Macro AUC: 0.9129\n",
      "Epoch: 008, Train Recall@10: 0.8432, Val Recall@10: 0.8170, Train Micro F1: 0.6853, Val Micro F1: 0.6541, Train Macro F1: 0.2877, Val Macro F1: 0.2570, Train Micro AUC: 0.9876, Val Micro AUC: 0.9799, Train Macro AUC: 0.9383, Val Macro AUC: 0.9132\n",
      "Epoch: 009, Train Recall@10: 0.8503, Val Recall@10: 0.8164, Train Micro F1: 0.6935, Val Micro F1: 0.6564, Train Macro F1: 0.3115, Val Macro F1: 0.2664, Train Micro AUC: 0.9885, Val Micro AUC: 0.9800, Train Macro AUC: 0.9449, Val Macro AUC: 0.9138\n",
      "Epoch: 010, Train Recall@10: 0.8558, Val Recall@10: 0.8143, Train Micro F1: 0.7048, Val Micro F1: 0.6588, Train Macro F1: 0.3469, Val Macro F1: 0.2826, Train Micro AUC: 0.9890, Val Micro AUC: 0.9797, Train Macro AUC: 0.9497, Val Macro AUC: 0.9105\n",
      "Epoch: 011, Train Recall@10: 0.8590, Val Recall@10: 0.8111, Train Micro F1: 0.7108, Val Micro F1: 0.6592, Train Macro F1: 0.3683, Val Macro F1: 0.2834, Train Micro AUC: 0.9895, Val Micro AUC: 0.9794, Train Macro AUC: 0.9555, Val Macro AUC: 0.9108\n",
      "Epoch: 012, Train Recall@10: 0.8646, Val Recall@10: 0.8118, Train Micro F1: 0.7186, Val Micro F1: 0.6613, Train Macro F1: 0.3952, Val Macro F1: 0.2885, Train Micro AUC: 0.9901, Val Micro AUC: 0.9790, Train Macro AUC: 0.9607, Val Macro AUC: 0.9035\n",
      "Epoch: 013, Train Recall@10: 0.8697, Val Recall@10: 0.8108, Train Micro F1: 0.7235, Val Micro F1: 0.6595, Train Macro F1: 0.4223, Val Macro F1: 0.2972, Train Micro AUC: 0.9907, Val Micro AUC: 0.9790, Train Macro AUC: 0.9650, Val Macro AUC: 0.9013\n",
      "Epoch: 014, Train Recall@10: 0.8736, Val Recall@10: 0.8070, Train Micro F1: 0.7238, Val Micro F1: 0.6537, Train Macro F1: 0.4357, Val Macro F1: 0.2904, Train Micro AUC: 0.9911, Val Micro AUC: 0.9784, Train Macro AUC: 0.9678, Val Macro AUC: 0.9013\n",
      "Epoch: 015, Train Recall@10: 0.8786, Val Recall@10: 0.8076, Train Micro F1: 0.7372, Val Micro F1: 0.6597, Train Macro F1: 0.4523, Val Macro F1: 0.2884, Train Micro AUC: 0.9917, Val Micro AUC: 0.9781, Train Macro AUC: 0.9713, Val Macro AUC: 0.9043\n",
      "Epoch: 016, Train Recall@10: 0.8820, Val Recall@10: 0.8027, Train Micro F1: 0.7448, Val Micro F1: 0.6590, Train Macro F1: 0.4778, Val Macro F1: 0.2937, Train Micro AUC: 0.9921, Val Micro AUC: 0.9776, Train Macro AUC: 0.9747, Val Macro AUC: 0.9004\n",
      "Epoch: 017, Train Recall@10: 0.8825, Val Recall@10: 0.7980, Train Micro F1: 0.7361, Val Micro F1: 0.6452, Train Macro F1: 0.4818, Val Macro F1: 0.2868, Train Micro AUC: 0.9922, Val Micro AUC: 0.9768, Train Macro AUC: 0.9749, Val Macro AUC: 0.8986\n",
      "Epoch: 018, Train Recall@10: 0.8884, Val Recall@10: 0.7955, Train Micro F1: 0.7440, Val Micro F1: 0.6419, Train Macro F1: 0.5251, Val Macro F1: 0.3052, Train Micro AUC: 0.9927, Val Micro AUC: 0.9761, Train Macro AUC: 0.9779, Val Macro AUC: 0.8956\n",
      "Epoch: 019, Train Recall@10: 0.9000, Val Recall@10: 0.7972, Train Micro F1: 0.7683, Val Micro F1: 0.6533, Train Macro F1: 0.5641, Val Macro F1: 0.3171, Train Micro AUC: 0.9938, Val Micro AUC: 0.9764, Train Macro AUC: 0.9817, Val Macro AUC: 0.8975\n",
      "Epoch: 020, Train Recall@10: 0.9043, Val Recall@10: 0.7940, Train Micro F1: 0.7783, Val Micro F1: 0.6548, Train Macro F1: 0.5958, Val Macro F1: 0.3166, Train Micro AUC: 0.9942, Val Micro AUC: 0.9759, Train Macro AUC: 0.9834, Val Macro AUC: 0.8941\n",
      "Epoch: 021, Train Recall@10: 0.9108, Val Recall@10: 0.7944, Train Micro F1: 0.7855, Val Micro F1: 0.6523, Train Macro F1: 0.6062, Val Macro F1: 0.3170, Train Micro AUC: 0.9948, Val Micro AUC: 0.9756, Train Macro AUC: 0.9853, Val Macro AUC: 0.8927\n",
      "Epoch: 022, Train Recall@10: 0.9148, Val Recall@10: 0.7946, Train Micro F1: 0.7930, Val Micro F1: 0.6512, Train Macro F1: 0.6256, Val Macro F1: 0.3153, Train Micro AUC: 0.9951, Val Micro AUC: 0.9753, Train Macro AUC: 0.9865, Val Macro AUC: 0.8924\n",
      "Epoch: 023, Train Recall@10: 0.9189, Val Recall@10: 0.7940, Train Micro F1: 0.7976, Val Micro F1: 0.6511, Train Macro F1: 0.6338, Val Macro F1: 0.3125, Train Micro AUC: 0.9954, Val Micro AUC: 0.9751, Train Macro AUC: 0.9874, Val Macro AUC: 0.8914\n",
      "Epoch: 024, Train Recall@10: 0.9208, Val Recall@10: 0.7932, Train Micro F1: 0.8008, Val Micro F1: 0.6498, Train Macro F1: 0.6397, Val Macro F1: 0.3062, Train Micro AUC: 0.9956, Val Micro AUC: 0.9754, Train Macro AUC: 0.9879, Val Macro AUC: 0.8912\n",
      "Epoch: 025, Train Recall@10: 0.9216, Val Recall@10: 0.7940, Train Micro F1: 0.8030, Val Micro F1: 0.6509, Train Macro F1: 0.6467, Val Macro F1: 0.3083, Train Micro AUC: 0.9956, Val Micro AUC: 0.9753, Train Macro AUC: 0.9879, Val Macro AUC: 0.8910\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path=f'./log/{model_type}_ModifiedKSI',\n",
    "                           device=DEVICE,\n",
    "                           init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}{model_type}_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7939, Test Micro F1: 0.6528, Test Macro F1: 0.3120, Test Micro AUC: 0.9763, Test Macro AUC: 0.8784\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using tfidf vectors rather than binary vectors\n",
    "dir = 'data/original_tfidf/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMattn                                 --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,104,603\n",
       "Trainable params: 6,104,603\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.40\n",
       "Params size (MB): 24.42\n",
       "Estimated Total Size (MB): 1258.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi2 = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi2.to(DEVICE)\n",
    "tfidf_model = LSTMattn(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi2)\n",
    "tfidf_model = tfidf_model.to(DEVICE)\n",
    "tfidf_summary = summary(tfidf_model, [(batch_size, avg_note_size), \n",
    "                                      (batch_size, n_vocab),\n",
    "                                      (n_wiki, n_vocab)], \n",
    "                        dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6261, Val Recall@10: 0.6211, Train Micro F1: 0.4247, Val Micro F1: 0.4219, Train Macro F1: 0.0331, Val Macro F1: 0.0400, Train Micro AUC: 0.9602, Val Micro AUC: 0.9521, Train Macro AUC: 0.7728, Val Macro AUC: 0.7855\n",
      "Epoch: 002, Train Recall@10: 0.6808, Val Recall@10: 0.6763, Train Micro F1: 0.4540, Val Micro F1: 0.4503, Train Macro F1: 0.0784, Val Macro F1: 0.0955, Train Micro AUC: 0.9690, Val Micro AUC: 0.9622, Train Macro AUC: 0.8316, Val Macro AUC: 0.8377\n",
      "Epoch: 003, Train Recall@10: 0.7122, Val Recall@10: 0.7073, Train Micro F1: 0.5043, Val Micro F1: 0.5007, Train Macro F1: 0.0989, Val Macro F1: 0.1098, Train Micro AUC: 0.9734, Val Micro AUC: 0.9672, Train Macro AUC: 0.8607, Val Macro AUC: 0.8574\n",
      "Epoch: 004, Train Recall@10: 0.7786, Val Recall@10: 0.7732, Train Micro F1: 0.6039, Val Micro F1: 0.5953, Train Macro F1: 0.1495, Val Macro F1: 0.1613, Train Micro AUC: 0.9806, Val Micro AUC: 0.9753, Train Macro AUC: 0.8914, Val Macro AUC: 0.8865\n",
      "Epoch: 005, Train Recall@10: 0.8124, Val Recall@10: 0.8011, Train Micro F1: 0.6429, Val Micro F1: 0.6302, Train Macro F1: 0.2025, Val Macro F1: 0.2124, Train Micro AUC: 0.9842, Val Micro AUC: 0.9787, Train Macro AUC: 0.9149, Val Macro AUC: 0.9007\n",
      "Epoch: 006, Train Recall@10: 0.8278, Val Recall@10: 0.8116, Train Micro F1: 0.6636, Val Micro F1: 0.6433, Train Macro F1: 0.2367, Val Macro F1: 0.2328, Train Micro AUC: 0.9859, Val Micro AUC: 0.9799, Train Macro AUC: 0.9276, Val Macro AUC: 0.9075\n",
      "Epoch: 007, Train Recall@10: 0.8376, Val Recall@10: 0.8171, Train Micro F1: 0.6767, Val Micro F1: 0.6510, Train Macro F1: 0.2677, Val Macro F1: 0.2515, Train Micro AUC: 0.9871, Val Micro AUC: 0.9802, Train Macro AUC: 0.9415, Val Macro AUC: 0.9085\n",
      "Epoch: 008, Train Recall@10: 0.8433, Val Recall@10: 0.8190, Train Micro F1: 0.6847, Val Micro F1: 0.6534, Train Macro F1: 0.2930, Val Macro F1: 0.2666, Train Micro AUC: 0.9878, Val Micro AUC: 0.9803, Train Macro AUC: 0.9478, Val Macro AUC: 0.9065\n",
      "Epoch: 009, Train Recall@10: 0.8501, Val Recall@10: 0.8182, Train Micro F1: 0.6940, Val Micro F1: 0.6559, Train Macro F1: 0.3310, Val Macro F1: 0.2790, Train Micro AUC: 0.9885, Val Micro AUC: 0.9799, Train Macro AUC: 0.9519, Val Macro AUC: 0.9057\n",
      "Epoch: 010, Train Recall@10: 0.8532, Val Recall@10: 0.8128, Train Micro F1: 0.7018, Val Micro F1: 0.6582, Train Macro F1: 0.3566, Val Macro F1: 0.2851, Train Micro AUC: 0.9889, Val Micro AUC: 0.9792, Train Macro AUC: 0.9551, Val Macro AUC: 0.9097\n",
      "Epoch: 011, Train Recall@10: 0.8570, Val Recall@10: 0.8091, Train Micro F1: 0.7053, Val Micro F1: 0.6557, Train Macro F1: 0.3825, Val Macro F1: 0.2865, Train Micro AUC: 0.9893, Val Micro AUC: 0.9782, Train Macro AUC: 0.9585, Val Macro AUC: 0.9002\n",
      "Epoch: 012, Train Recall@10: 0.8602, Val Recall@10: 0.8078, Train Micro F1: 0.7097, Val Micro F1: 0.6533, Train Macro F1: 0.4124, Val Macro F1: 0.2981, Train Micro AUC: 0.9898, Val Micro AUC: 0.9772, Train Macro AUC: 0.9607, Val Macro AUC: 0.8908\n",
      "Epoch: 013, Train Recall@10: 0.8638, Val Recall@10: 0.8032, Train Micro F1: 0.7096, Val Micro F1: 0.6469, Train Macro F1: 0.4068, Val Macro F1: 0.2851, Train Micro AUC: 0.9901, Val Micro AUC: 0.9760, Train Macro AUC: 0.9640, Val Macro AUC: 0.8891\n",
      "Epoch: 014, Train Recall@10: 0.8681, Val Recall@10: 0.7998, Train Micro F1: 0.7149, Val Micro F1: 0.6474, Train Macro F1: 0.4253, Val Macro F1: 0.2869, Train Micro AUC: 0.9906, Val Micro AUC: 0.9749, Train Macro AUC: 0.9667, Val Macro AUC: 0.8763\n",
      "Epoch: 015, Train Recall@10: 0.8738, Val Recall@10: 0.7961, Train Micro F1: 0.7278, Val Micro F1: 0.6504, Train Macro F1: 0.4612, Val Macro F1: 0.3074, Train Micro AUC: 0.9913, Val Micro AUC: 0.9748, Train Macro AUC: 0.9712, Val Macro AUC: 0.8839\n",
      "Epoch: 016, Train Recall@10: 0.8774, Val Recall@10: 0.7919, Train Micro F1: 0.7243, Val Micro F1: 0.6393, Train Macro F1: 0.4762, Val Macro F1: 0.2988, Train Micro AUC: 0.9917, Val Micro AUC: 0.9737, Train Macro AUC: 0.9731, Val Macro AUC: 0.8787\n",
      "Epoch: 017, Train Recall@10: 0.8868, Val Recall@10: 0.7925, Train Micro F1: 0.7414, Val Micro F1: 0.6411, Train Macro F1: 0.5236, Val Macro F1: 0.3182, Train Micro AUC: 0.9926, Val Micro AUC: 0.9736, Train Macro AUC: 0.9772, Val Macro AUC: 0.8769\n",
      "Epoch: 018, Train Recall@10: 0.8913, Val Recall@10: 0.7930, Train Micro F1: 0.7512, Val Micro F1: 0.6446, Train Macro F1: 0.5524, Val Macro F1: 0.3132, Train Micro AUC: 0.9931, Val Micro AUC: 0.9734, Train Macro AUC: 0.9794, Val Macro AUC: 0.8737\n",
      "Epoch: 019, Train Recall@10: 0.8985, Val Recall@10: 0.7889, Train Micro F1: 0.7656, Val Micro F1: 0.6487, Train Macro F1: 0.5697, Val Macro F1: 0.3109, Train Micro AUC: 0.9937, Val Micro AUC: 0.9732, Train Macro AUC: 0.9812, Val Macro AUC: 0.8638\n",
      "Epoch: 020, Train Recall@10: 0.9048, Val Recall@10: 0.7921, Train Micro F1: 0.7751, Val Micro F1: 0.6496, Train Macro F1: 0.5971, Val Macro F1: 0.3131, Train Micro AUC: 0.9943, Val Micro AUC: 0.9730, Train Macro AUC: 0.9830, Val Macro AUC: 0.8618\n",
      "Epoch: 021, Train Recall@10: 0.9104, Val Recall@10: 0.7912, Train Micro F1: 0.7826, Val Micro F1: 0.6507, Train Macro F1: 0.6172, Val Macro F1: 0.3194, Train Micro AUC: 0.9948, Val Micro AUC: 0.9732, Train Macro AUC: 0.9850, Val Macro AUC: 0.8651\n",
      "Epoch: 022, Train Recall@10: 0.9151, Val Recall@10: 0.7924, Train Micro F1: 0.7880, Val Micro F1: 0.6492, Train Macro F1: 0.6345, Val Macro F1: 0.3145, Train Micro AUC: 0.9952, Val Micro AUC: 0.9732, Train Macro AUC: 0.9858, Val Macro AUC: 0.8643\n",
      "Epoch: 023, Train Recall@10: 0.9187, Val Recall@10: 0.7910, Train Micro F1: 0.7931, Val Micro F1: 0.6474, Train Macro F1: 0.6533, Val Macro F1: 0.3124, Train Micro AUC: 0.9955, Val Micro AUC: 0.9731, Train Macro AUC: 0.9863, Val Macro AUC: 0.8630\n",
      "Epoch: 024, Train Recall@10: 0.9223, Val Recall@10: 0.7905, Train Micro F1: 0.7979, Val Micro F1: 0.6481, Train Macro F1: 0.6686, Val Macro F1: 0.3130, Train Micro AUC: 0.9957, Val Micro AUC: 0.9733, Train Macro AUC: 0.9870, Val Macro AUC: 0.8628\n",
      "Epoch: 025, Train Recall@10: 0.9233, Val Recall@10: 0.7917, Train Micro F1: 0.7996, Val Micro F1: 0.6490, Train Macro F1: 0.6683, Val Macro F1: 0.3140, Train Micro AUC: 0.9958, Val Micro AUC: 0.9735, Train Macro AUC: 0.9873, Val Macro AUC: 0.8641\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(tfidf_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_tfidf_ksi = train_model(tfidf_model, \n",
    "                             train_dataloader=train_dataloader,\n",
    "                             val_dataloader=val_dataloader,\n",
    "                             wikivec=wikivec,\n",
    "                             optimizer=optimizer,\n",
    "                             scheduler=scheduler,\n",
    "                             n_epochs=n_epochs, \n",
    "                             profile=profile, \n",
    "                             log_path=f'./log/{model_type}_ModifiedKSI_tfidf',\n",
    "                             device=DEVICE,\n",
    "                             init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(tfidf_model, f'{dir}{model_type}_ModifiedKSI_tfidf_model.pt')\n",
    "if profile:\n",
    "    print(prof_tfidf_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7925, Test Micro F1: 0.6491, Test Macro F1: 0.3164, Test Micro AUC: 0.9751, Test Macro AUC: 0.8693\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(tfidf_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del tfidf_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
