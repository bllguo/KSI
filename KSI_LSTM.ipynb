{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, LSTM\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 100 # 200 in paper, but too intensive for my machine\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False\n",
    "model_type = 'LSTM'\n",
    "early_stopping = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-3                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-4                            [32, 344]                 34,744\n",
       "==========================================================================================\n",
       "Total params: 4,911,744\n",
       "Trainable params: 4,911,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.50\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 125.78\n",
       "Params size (MB): 19.65\n",
       "Estimated Total Size (MB): 147.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, batch_size)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.4447, Val Recall@10: 0.4500, Train Micro F1: 0.0000, Val Micro F1: 0.0000, Train Macro F1: 0.0000, Val Macro F1: 0.0000, Train Micro AUC: 0.9265, Val Micro AUC: 0.9120, Train Macro AUC: 0.5737, Val Macro AUC: 0.5759\n",
      "Epoch: 002, Train Recall@10: 0.4519, Val Recall@10: 0.4566, Train Micro F1: 0.0000, Val Micro F1: 0.0000, Train Macro F1: 0.0000, Val Macro F1: 0.0000, Train Micro AUC: 0.9292, Val Micro AUC: 0.9150, Train Macro AUC: 0.5886, Val Macro AUC: 0.5944\n",
      "Epoch: 003, Train Recall@10: 0.4587, Val Recall@10: 0.4627, Train Micro F1: 0.0395, Val Micro F1: 0.0419, Train Macro F1: 0.0018, Val Macro F1: 0.0023, Train Micro AUC: 0.9310, Val Micro AUC: 0.9170, Train Macro AUC: 0.6103, Val Macro AUC: 0.6185\n",
      "Epoch: 004, Train Recall@10: 0.4833, Val Recall@10: 0.4871, Train Micro F1: 0.1279, Val Micro F1: 0.1276, Train Macro F1: 0.0051, Val Macro F1: 0.0061, Train Micro AUC: 0.9355, Val Micro AUC: 0.9223, Train Macro AUC: 0.6526, Val Macro AUC: 0.6536\n",
      "Epoch: 005, Train Recall@10: 0.5068, Val Recall@10: 0.5095, Train Micro F1: 0.1883, Val Micro F1: 0.1890, Train Macro F1: 0.0077, Val Macro F1: 0.0094, Train Micro AUC: 0.9407, Val Micro AUC: 0.9284, Train Macro AUC: 0.6916, Val Macro AUC: 0.6885\n",
      "Epoch: 006, Train Recall@10: 0.5423, Val Recall@10: 0.5432, Train Micro F1: 0.2339, Val Micro F1: 0.2342, Train Macro F1: 0.0115, Val Macro F1: 0.0138, Train Micro AUC: 0.9460, Val Micro AUC: 0.9343, Train Macro AUC: 0.7254, Val Macro AUC: 0.7196\n",
      "Epoch: 007, Train Recall@10: 0.5609, Val Recall@10: 0.5615, Train Micro F1: 0.3174, Val Micro F1: 0.3189, Train Macro F1: 0.0169, Val Macro F1: 0.0206, Train Micro AUC: 0.9497, Val Micro AUC: 0.9385, Train Macro AUC: 0.7558, Val Macro AUC: 0.7366\n",
      "Epoch: 008, Train Recall@10: 0.5834, Val Recall@10: 0.5812, Train Micro F1: 0.3803, Val Micro F1: 0.3799, Train Macro F1: 0.0218, Val Macro F1: 0.0265, Train Micro AUC: 0.9530, Val Micro AUC: 0.9421, Train Macro AUC: 0.7784, Val Macro AUC: 0.7454\n",
      "Epoch: 009, Train Recall@10: 0.6025, Val Recall@10: 0.5990, Train Micro F1: 0.4369, Val Micro F1: 0.4360, Train Macro F1: 0.0278, Val Macro F1: 0.0339, Train Micro AUC: 0.9563, Val Micro AUC: 0.9458, Train Macro AUC: 0.8082, Val Macro AUC: 0.7608\n",
      "Epoch: 010, Train Recall@10: 0.6210, Val Recall@10: 0.6160, Train Micro F1: 0.4682, Val Micro F1: 0.4660, Train Macro F1: 0.0331, Val Macro F1: 0.0401, Train Micro AUC: 0.9588, Val Micro AUC: 0.9486, Train Macro AUC: 0.8303, Val Macro AUC: 0.7740\n",
      "Epoch: 011, Train Recall@10: 0.6382, Val Recall@10: 0.6316, Train Micro F1: 0.4902, Val Micro F1: 0.4855, Train Macro F1: 0.0356, Val Macro F1: 0.0429, Train Micro AUC: 0.9613, Val Micro AUC: 0.9513, Train Macro AUC: 0.8454, Val Macro AUC: 0.7838\n",
      "Epoch: 012, Train Recall@10: 0.6519, Val Recall@10: 0.6468, Train Micro F1: 0.5026, Val Micro F1: 0.4975, Train Macro F1: 0.0372, Val Macro F1: 0.0445, Train Micro AUC: 0.9633, Val Micro AUC: 0.9534, Train Macro AUC: 0.8557, Val Macro AUC: 0.7934\n",
      "Epoch: 013, Train Recall@10: 0.6686, Val Recall@10: 0.6618, Train Micro F1: 0.5226, Val Micro F1: 0.5154, Train Macro F1: 0.0400, Val Macro F1: 0.0485, Train Micro AUC: 0.9653, Val Micro AUC: 0.9555, Train Macro AUC: 0.8669, Val Macro AUC: 0.7993\n",
      "Epoch: 014, Train Recall@10: 0.6807, Val Recall@10: 0.6712, Train Micro F1: 0.5324, Val Micro F1: 0.5254, Train Macro F1: 0.0425, Val Macro F1: 0.0516, Train Micro AUC: 0.9667, Val Micro AUC: 0.9568, Train Macro AUC: 0.8737, Val Macro AUC: 0.8022\n",
      "Epoch: 015, Train Recall@10: 0.6891, Val Recall@10: 0.6800, Train Micro F1: 0.5395, Val Micro F1: 0.5324, Train Macro F1: 0.0452, Val Macro F1: 0.0548, Train Micro AUC: 0.9681, Val Micro AUC: 0.9580, Train Macro AUC: 0.8803, Val Macro AUC: 0.8071\n",
      "Epoch: 016, Train Recall@10: 0.6980, Val Recall@10: 0.6841, Train Micro F1: 0.5511, Val Micro F1: 0.5424, Train Macro F1: 0.0495, Val Macro F1: 0.0587, Train Micro AUC: 0.9694, Val Micro AUC: 0.9591, Train Macro AUC: 0.8865, Val Macro AUC: 0.8127\n",
      "Epoch: 017, Train Recall@10: 0.7048, Val Recall@10: 0.6896, Train Micro F1: 0.5598, Val Micro F1: 0.5475, Train Macro F1: 0.0533, Val Macro F1: 0.0628, Train Micro AUC: 0.9704, Val Micro AUC: 0.9599, Train Macro AUC: 0.8911, Val Macro AUC: 0.8142\n",
      "Epoch: 018, Train Recall@10: 0.7137, Val Recall@10: 0.6969, Train Micro F1: 0.5717, Val Micro F1: 0.5573, Train Macro F1: 0.0577, Val Macro F1: 0.0678, Train Micro AUC: 0.9716, Val Micro AUC: 0.9609, Train Macro AUC: 0.8966, Val Macro AUC: 0.8174\n",
      "Epoch: 019, Train Recall@10: 0.7189, Val Recall@10: 0.6971, Train Micro F1: 0.5789, Val Micro F1: 0.5631, Train Macro F1: 0.0616, Val Macro F1: 0.0719, Train Micro AUC: 0.9723, Val Micro AUC: 0.9612, Train Macro AUC: 0.8993, Val Macro AUC: 0.8178\n",
      "Epoch: 020, Train Recall@10: 0.7258, Val Recall@10: 0.7038, Train Micro F1: 0.5851, Val Micro F1: 0.5668, Train Macro F1: 0.0638, Val Macro F1: 0.0735, Train Micro AUC: 0.9734, Val Micro AUC: 0.9619, Train Macro AUC: 0.9027, Val Macro AUC: 0.8206\n",
      "Epoch: 021, Train Recall@10: 0.7302, Val Recall@10: 0.7069, Train Micro F1: 0.5912, Val Micro F1: 0.5719, Train Macro F1: 0.0673, Val Macro F1: 0.0777, Train Micro AUC: 0.9740, Val Micro AUC: 0.9623, Train Macro AUC: 0.9060, Val Macro AUC: 0.8238\n",
      "Epoch: 022, Train Recall@10: 0.7359, Val Recall@10: 0.7106, Train Micro F1: 0.5980, Val Micro F1: 0.5758, Train Macro F1: 0.0701, Val Macro F1: 0.0809, Train Micro AUC: 0.9746, Val Micro AUC: 0.9628, Train Macro AUC: 0.9090, Val Macro AUC: 0.8241\n",
      "Epoch: 023, Train Recall@10: 0.7400, Val Recall@10: 0.7114, Train Micro F1: 0.6034, Val Micro F1: 0.5806, Train Macro F1: 0.0732, Val Macro F1: 0.0847, Train Micro AUC: 0.9754, Val Micro AUC: 0.9632, Train Macro AUC: 0.9113, Val Macro AUC: 0.8253\n",
      "Epoch: 024, Train Recall@10: 0.7447, Val Recall@10: 0.7142, Train Micro F1: 0.6073, Val Micro F1: 0.5802, Train Macro F1: 0.0757, Val Macro F1: 0.0858, Train Micro AUC: 0.9759, Val Micro AUC: 0.9634, Train Macro AUC: 0.9134, Val Macro AUC: 0.8288\n",
      "Epoch: 025, Train Recall@10: 0.7498, Val Recall@10: 0.7186, Train Micro F1: 0.6133, Val Micro F1: 0.5856, Train Macro F1: 0.0788, Val Macro F1: 0.0898, Train Micro AUC: 0.9767, Val Micro AUC: 0.9639, Train Macro AUC: 0.9161, Val Macro AUC: 0.8287\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path=f'./log/{model_type}',\n",
    "                        device=DEVICE,\n",
    "                        init_hidden=True,\n",
    "                        early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}{model_type}_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7142, Test Micro F1: 0.5831, Test Macro F1: 0.0813, Test Micro AUC: 0.9654, Test Macro AUC: 0.8224\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   device=DEVICE,\n",
    "                                                                                                   init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,345\n",
       "Trainable params: 6,139,345\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 143.48\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 186.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6637, Val Recall@10: 0.6596, Train Micro F1: 0.4001, Val Micro F1: 0.3931, Train Macro F1: 0.0586, Val Macro F1: 0.0697, Train Micro AUC: 0.9673, Val Micro AUC: 0.9592, Train Macro AUC: 0.8271, Val Macro AUC: 0.8142\n",
      "Epoch: 002, Train Recall@10: 0.7000, Val Recall@10: 0.6918, Train Micro F1: 0.4708, Val Micro F1: 0.4597, Train Macro F1: 0.0888, Val Macro F1: 0.1007, Train Micro AUC: 0.9721, Val Micro AUC: 0.9636, Train Macro AUC: 0.8625, Val Macro AUC: 0.8371\n",
      "Epoch: 003, Train Recall@10: 0.7356, Val Recall@10: 0.7224, Train Micro F1: 0.5342, Val Micro F1: 0.5202, Train Macro F1: 0.1227, Val Macro F1: 0.1339, Train Micro AUC: 0.9763, Val Micro AUC: 0.9677, Train Macro AUC: 0.8863, Val Macro AUC: 0.8515\n",
      "Epoch: 004, Train Recall@10: 0.7603, Val Recall@10: 0.7424, Train Micro F1: 0.5753, Val Micro F1: 0.5559, Train Macro F1: 0.1569, Val Macro F1: 0.1573, Train Micro AUC: 0.9793, Val Micro AUC: 0.9703, Train Macro AUC: 0.9033, Val Macro AUC: 0.8617\n",
      "Epoch: 005, Train Recall@10: 0.7771, Val Recall@10: 0.7542, Train Micro F1: 0.6006, Val Micro F1: 0.5747, Train Macro F1: 0.1808, Val Macro F1: 0.1768, Train Micro AUC: 0.9814, Val Micro AUC: 0.9717, Train Macro AUC: 0.9162, Val Macro AUC: 0.8681\n",
      "Epoch: 006, Train Recall@10: 0.7897, Val Recall@10: 0.7602, Train Micro F1: 0.6181, Val Micro F1: 0.5834, Train Macro F1: 0.2083, Val Macro F1: 0.1894, Train Micro AUC: 0.9831, Val Micro AUC: 0.9725, Train Macro AUC: 0.9273, Val Macro AUC: 0.8726\n",
      "Epoch: 007, Train Recall@10: 0.8026, Val Recall@10: 0.7645, Train Micro F1: 0.6342, Val Micro F1: 0.5916, Train Macro F1: 0.2324, Val Macro F1: 0.1927, Train Micro AUC: 0.9846, Val Micro AUC: 0.9728, Train Macro AUC: 0.9368, Val Macro AUC: 0.8749\n",
      "Epoch: 008, Train Recall@10: 0.8149, Val Recall@10: 0.7670, Train Micro F1: 0.6480, Val Micro F1: 0.5942, Train Macro F1: 0.2642, Val Macro F1: 0.2033, Train Micro AUC: 0.9859, Val Micro AUC: 0.9726, Train Macro AUC: 0.9444, Val Macro AUC: 0.8758\n",
      "Epoch: 009, Train Recall@10: 0.8233, Val Recall@10: 0.7646, Train Micro F1: 0.6546, Val Micro F1: 0.5935, Train Macro F1: 0.2893, Val Macro F1: 0.2041, Train Micro AUC: 0.9869, Val Micro AUC: 0.9717, Train Macro AUC: 0.9507, Val Macro AUC: 0.8732\n",
      "Epoch: 010, Train Recall@10: 0.8318, Val Recall@10: 0.7615, Train Micro F1: 0.6633, Val Micro F1: 0.5912, Train Macro F1: 0.3176, Val Macro F1: 0.2065, Train Micro AUC: 0.9878, Val Micro AUC: 0.9706, Train Macro AUC: 0.9562, Val Macro AUC: 0.8699\n",
      "Epoch: 011, Train Recall@10: 0.8380, Val Recall@10: 0.7583, Train Micro F1: 0.6723, Val Micro F1: 0.5891, Train Macro F1: 0.3587, Val Macro F1: 0.2108, Train Micro AUC: 0.9885, Val Micro AUC: 0.9691, Train Macro AUC: 0.9605, Val Macro AUC: 0.8650\n",
      "Epoch: 012, Train Recall@10: 0.8452, Val Recall@10: 0.7552, Train Micro F1: 0.6824, Val Micro F1: 0.5883, Train Macro F1: 0.3976, Val Macro F1: 0.2169, Train Micro AUC: 0.9893, Val Micro AUC: 0.9675, Train Macro AUC: 0.9644, Val Macro AUC: 0.8602\n",
      "Epoch: 013, Train Recall@10: 0.8527, Val Recall@10: 0.7489, Train Micro F1: 0.6919, Val Micro F1: 0.5849, Train Macro F1: 0.4345, Val Macro F1: 0.2163, Train Micro AUC: 0.9900, Val Micro AUC: 0.9658, Train Macro AUC: 0.9676, Val Macro AUC: 0.8564\n",
      "Early stopping at epoch 13\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path=f'./log/{model_type}_KSI',\n",
    "                       device=DEVICE,\n",
    "                       init_hidden=True,\n",
    "                       early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}{model_type}_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7622, Test Micro F1: 0.5933, Test Macro F1: 0.1892, Test Micro AUC: 0.9743, Test Macro AUC: 0.8796\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,347\n",
       "Trainable params: 6,139,347\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.49\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 1258.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6959, Val Recall@10: 0.6950, Train Micro F1: 0.4661, Val Micro F1: 0.4611, Train Macro F1: 0.0663, Val Macro F1: 0.0821, Train Micro AUC: 0.9708, Val Micro AUC: 0.9646, Train Macro AUC: 0.8380, Val Macro AUC: 0.8439\n",
      "Epoch: 002, Train Recall@10: 0.7223, Val Recall@10: 0.7196, Train Micro F1: 0.5010, Val Micro F1: 0.4954, Train Macro F1: 0.1046, Val Macro F1: 0.1285, Train Micro AUC: 0.9748, Val Micro AUC: 0.9690, Train Macro AUC: 0.8624, Val Macro AUC: 0.8605\n",
      "Epoch: 003, Train Recall@10: 0.7405, Val Recall@10: 0.7356, Train Micro F1: 0.5245, Val Micro F1: 0.5162, Train Macro F1: 0.1325, Val Macro F1: 0.1497, Train Micro AUC: 0.9770, Val Micro AUC: 0.9713, Train Macro AUC: 0.8767, Val Macro AUC: 0.8694\n",
      "Epoch: 004, Train Recall@10: 0.7575, Val Recall@10: 0.7528, Train Micro F1: 0.5501, Val Micro F1: 0.5429, Train Macro F1: 0.1538, Val Macro F1: 0.1657, Train Micro AUC: 0.9789, Val Micro AUC: 0.9731, Train Macro AUC: 0.8889, Val Macro AUC: 0.8774\n",
      "Epoch: 005, Train Recall@10: 0.7683, Val Recall@10: 0.7623, Train Micro F1: 0.5665, Val Micro F1: 0.5566, Train Macro F1: 0.1692, Val Macro F1: 0.1789, Train Micro AUC: 0.9803, Val Micro AUC: 0.9744, Train Macro AUC: 0.8995, Val Macro AUC: 0.8843\n",
      "Epoch: 006, Train Recall@10: 0.7765, Val Recall@10: 0.7695, Train Micro F1: 0.5813, Val Micro F1: 0.5717, Train Macro F1: 0.1820, Val Macro F1: 0.1893, Train Micro AUC: 0.9814, Val Micro AUC: 0.9753, Train Macro AUC: 0.9099, Val Macro AUC: 0.8902\n",
      "Epoch: 007, Train Recall@10: 0.7825, Val Recall@10: 0.7721, Train Micro F1: 0.5946, Val Micro F1: 0.5801, Train Macro F1: 0.1912, Val Macro F1: 0.1896, Train Micro AUC: 0.9823, Val Micro AUC: 0.9760, Train Macro AUC: 0.9187, Val Macro AUC: 0.8953\n",
      "Epoch: 008, Train Recall@10: 0.7892, Val Recall@10: 0.7765, Train Micro F1: 0.6038, Val Micro F1: 0.5861, Train Macro F1: 0.2075, Val Macro F1: 0.1939, Train Micro AUC: 0.9832, Val Micro AUC: 0.9766, Train Macro AUC: 0.9268, Val Macro AUC: 0.8987\n",
      "Epoch: 009, Train Recall@10: 0.7954, Val Recall@10: 0.7811, Train Micro F1: 0.6122, Val Micro F1: 0.5919, Train Macro F1: 0.2195, Val Macro F1: 0.1963, Train Micro AUC: 0.9839, Val Micro AUC: 0.9771, Train Macro AUC: 0.9343, Val Macro AUC: 0.9014\n",
      "Epoch: 010, Train Recall@10: 0.8012, Val Recall@10: 0.7836, Train Micro F1: 0.6210, Val Micro F1: 0.5965, Train Macro F1: 0.2368, Val Macro F1: 0.2024, Train Micro AUC: 0.9845, Val Micro AUC: 0.9775, Train Macro AUC: 0.9409, Val Macro AUC: 0.9021\n",
      "Epoch: 011, Train Recall@10: 0.8080, Val Recall@10: 0.7892, Train Micro F1: 0.6306, Val Micro F1: 0.6037, Train Macro F1: 0.2551, Val Macro F1: 0.2108, Train Micro AUC: 0.9852, Val Micro AUC: 0.9779, Train Macro AUC: 0.9474, Val Macro AUC: 0.9022\n",
      "Epoch: 012, Train Recall@10: 0.8146, Val Recall@10: 0.7929, Train Micro F1: 0.6391, Val Micro F1: 0.6102, Train Macro F1: 0.2749, Val Macro F1: 0.2185, Train Micro AUC: 0.9859, Val Micro AUC: 0.9782, Train Macro AUC: 0.9523, Val Macro AUC: 0.9015\n",
      "Epoch: 013, Train Recall@10: 0.8199, Val Recall@10: 0.7960, Train Micro F1: 0.6450, Val Micro F1: 0.6122, Train Macro F1: 0.2900, Val Macro F1: 0.2233, Train Micro AUC: 0.9864, Val Micro AUC: 0.9784, Train Macro AUC: 0.9561, Val Macro AUC: 0.9021\n",
      "Epoch: 014, Train Recall@10: 0.8242, Val Recall@10: 0.7962, Train Micro F1: 0.6535, Val Micro F1: 0.6174, Train Macro F1: 0.3131, Val Macro F1: 0.2289, Train Micro AUC: 0.9869, Val Micro AUC: 0.9785, Train Macro AUC: 0.9590, Val Macro AUC: 0.9017\n",
      "Epoch: 015, Train Recall@10: 0.8287, Val Recall@10: 0.7969, Train Micro F1: 0.6601, Val Micro F1: 0.6208, Train Macro F1: 0.3343, Val Macro F1: 0.2363, Train Micro AUC: 0.9874, Val Micro AUC: 0.9785, Train Macro AUC: 0.9615, Val Macro AUC: 0.9020\n",
      "Epoch: 016, Train Recall@10: 0.8320, Val Recall@10: 0.7975, Train Micro F1: 0.6642, Val Micro F1: 0.6223, Train Macro F1: 0.3514, Val Macro F1: 0.2369, Train Micro AUC: 0.9878, Val Micro AUC: 0.9785, Train Macro AUC: 0.9632, Val Macro AUC: 0.9014\n",
      "Epoch: 017, Train Recall@10: 0.8367, Val Recall@10: 0.7990, Train Micro F1: 0.6716, Val Micro F1: 0.6239, Train Macro F1: 0.3751, Val Macro F1: 0.2405, Train Micro AUC: 0.9882, Val Micro AUC: 0.9785, Train Macro AUC: 0.9651, Val Macro AUC: 0.9012\n",
      "Epoch: 018, Train Recall@10: 0.8397, Val Recall@10: 0.7983, Train Micro F1: 0.6769, Val Micro F1: 0.6259, Train Macro F1: 0.3946, Val Macro F1: 0.2459, Train Micro AUC: 0.9885, Val Micro AUC: 0.9784, Train Macro AUC: 0.9667, Val Macro AUC: 0.9007\n",
      "Epoch: 019, Train Recall@10: 0.8446, Val Recall@10: 0.7976, Train Micro F1: 0.6823, Val Micro F1: 0.6268, Train Macro F1: 0.4093, Val Macro F1: 0.2476, Train Micro AUC: 0.9890, Val Micro AUC: 0.9783, Train Macro AUC: 0.9682, Val Macro AUC: 0.8997\n",
      "Epoch: 020, Train Recall@10: 0.8480, Val Recall@10: 0.7956, Train Micro F1: 0.6878, Val Micro F1: 0.6265, Train Macro F1: 0.4250, Val Macro F1: 0.2507, Train Micro AUC: 0.9894, Val Micro AUC: 0.9781, Train Macro AUC: 0.9698, Val Macro AUC: 0.8995\n",
      "Epoch: 021, Train Recall@10: 0.8513, Val Recall@10: 0.7953, Train Micro F1: 0.6934, Val Micro F1: 0.6275, Train Macro F1: 0.4452, Val Macro F1: 0.2547, Train Micro AUC: 0.9898, Val Micro AUC: 0.9780, Train Macro AUC: 0.9711, Val Macro AUC: 0.8991\n",
      "Epoch: 022, Train Recall@10: 0.8546, Val Recall@10: 0.7946, Train Micro F1: 0.6981, Val Micro F1: 0.6281, Train Macro F1: 0.4625, Val Macro F1: 0.2534, Train Micro AUC: 0.9901, Val Micro AUC: 0.9777, Train Macro AUC: 0.9723, Val Macro AUC: 0.8971\n",
      "Early stopping at epoch 22\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path=f'./log/{model_type}_ModifiedKSI',\n",
    "                           device=DEVICE,\n",
    "                           init_hidden=True,\n",
    "                           early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}{model_type}_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7940, Test Micro F1: 0.6226, Test Macro F1: 0.2437, Test Micro AUC: 0.9798, Test Macro AUC: 0.9000\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using tfidf vectors rather than binary vectors\n",
    "dir = 'data/original_tfidf/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,347\n",
       "Trainable params: 6,139,347\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.49\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 1258.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi2 = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi2.to(DEVICE)\n",
    "tfidf_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi2)\n",
    "tfidf_model = tfidf_model.to(DEVICE)\n",
    "tfidf_summary = summary(tfidf_model, [(batch_size, avg_note_size), \n",
    "                                      (batch_size, n_vocab),\n",
    "                                      (n_wiki, n_vocab)], \n",
    "                        dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7107, Val Recall@10: 0.7099, Train Micro F1: 0.4842, Val Micro F1: 0.4788, Train Macro F1: 0.0854, Val Macro F1: 0.1029, Train Micro AUC: 0.9733, Val Micro AUC: 0.9675, Train Macro AUC: 0.8474, Val Macro AUC: 0.8533\n",
      "Epoch: 002, Train Recall@10: 0.7286, Val Recall@10: 0.7252, Train Micro F1: 0.5027, Val Micro F1: 0.4965, Train Macro F1: 0.1223, Val Macro F1: 0.1403, Train Micro AUC: 0.9756, Val Micro AUC: 0.9697, Train Macro AUC: 0.8641, Val Macro AUC: 0.8623\n",
      "Epoch: 003, Train Recall@10: 0.7407, Val Recall@10: 0.7352, Train Micro F1: 0.5210, Val Micro F1: 0.5133, Train Macro F1: 0.1462, Val Macro F1: 0.1613, Train Micro AUC: 0.9772, Val Micro AUC: 0.9712, Train Macro AUC: 0.8744, Val Macro AUC: 0.8687\n",
      "Epoch: 004, Train Recall@10: 0.7533, Val Recall@10: 0.7465, Train Micro F1: 0.5416, Val Micro F1: 0.5323, Train Macro F1: 0.1646, Val Macro F1: 0.1711, Train Micro AUC: 0.9787, Val Micro AUC: 0.9727, Train Macro AUC: 0.8859, Val Macro AUC: 0.8767\n",
      "Epoch: 005, Train Recall@10: 0.7660, Val Recall@10: 0.7570, Train Micro F1: 0.5598, Val Micro F1: 0.5502, Train Macro F1: 0.1818, Val Macro F1: 0.1814, Train Micro AUC: 0.9801, Val Micro AUC: 0.9740, Train Macro AUC: 0.8976, Val Macro AUC: 0.8838\n",
      "Epoch: 006, Train Recall@10: 0.7768, Val Recall@10: 0.7662, Train Micro F1: 0.5779, Val Micro F1: 0.5644, Train Macro F1: 0.1976, Val Macro F1: 0.1888, Train Micro AUC: 0.9814, Val Micro AUC: 0.9751, Train Macro AUC: 0.9080, Val Macro AUC: 0.8887\n",
      "Epoch: 007, Train Recall@10: 0.7844, Val Recall@10: 0.7715, Train Micro F1: 0.5914, Val Micro F1: 0.5753, Train Macro F1: 0.2107, Val Macro F1: 0.1924, Train Micro AUC: 0.9825, Val Micro AUC: 0.9760, Train Macro AUC: 0.9173, Val Macro AUC: 0.8932\n",
      "Epoch: 008, Train Recall@10: 0.7915, Val Recall@10: 0.7762, Train Micro F1: 0.6022, Val Micro F1: 0.5827, Train Macro F1: 0.2229, Val Macro F1: 0.1994, Train Micro AUC: 0.9834, Val Micro AUC: 0.9766, Train Macro AUC: 0.9267, Val Macro AUC: 0.8956\n",
      "Epoch: 009, Train Recall@10: 0.7974, Val Recall@10: 0.7801, Train Micro F1: 0.6094, Val Micro F1: 0.5874, Train Macro F1: 0.2375, Val Macro F1: 0.2029, Train Micro AUC: 0.9842, Val Micro AUC: 0.9770, Train Macro AUC: 0.9369, Val Macro AUC: 0.8980\n",
      "Epoch: 010, Train Recall@10: 0.8031, Val Recall@10: 0.7823, Train Micro F1: 0.6196, Val Micro F1: 0.5921, Train Macro F1: 0.2587, Val Macro F1: 0.2077, Train Micro AUC: 0.9849, Val Micro AUC: 0.9773, Train Macro AUC: 0.9455, Val Macro AUC: 0.8997\n",
      "Epoch: 011, Train Recall@10: 0.8091, Val Recall@10: 0.7851, Train Micro F1: 0.6285, Val Micro F1: 0.5988, Train Macro F1: 0.2768, Val Macro F1: 0.2213, Train Micro AUC: 0.9855, Val Micro AUC: 0.9775, Train Macro AUC: 0.9512, Val Macro AUC: 0.9018\n",
      "Epoch: 012, Train Recall@10: 0.8142, Val Recall@10: 0.7873, Train Micro F1: 0.6362, Val Micro F1: 0.6035, Train Macro F1: 0.2932, Val Macro F1: 0.2314, Train Micro AUC: 0.9860, Val Micro AUC: 0.9776, Train Macro AUC: 0.9549, Val Macro AUC: 0.9017\n",
      "Epoch: 013, Train Recall@10: 0.8193, Val Recall@10: 0.7889, Train Micro F1: 0.6421, Val Micro F1: 0.6065, Train Macro F1: 0.3122, Val Macro F1: 0.2343, Train Micro AUC: 0.9866, Val Micro AUC: 0.9778, Train Macro AUC: 0.9579, Val Macro AUC: 0.9029\n",
      "Epoch: 014, Train Recall@10: 0.8234, Val Recall@10: 0.7890, Train Micro F1: 0.6502, Val Micro F1: 0.6123, Train Macro F1: 0.3310, Val Macro F1: 0.2391, Train Micro AUC: 0.9870, Val Micro AUC: 0.9777, Train Macro AUC: 0.9606, Val Macro AUC: 0.9027\n",
      "Epoch: 015, Train Recall@10: 0.8281, Val Recall@10: 0.7912, Train Micro F1: 0.6567, Val Micro F1: 0.6139, Train Macro F1: 0.3585, Val Macro F1: 0.2410, Train Micro AUC: 0.9875, Val Micro AUC: 0.9777, Train Macro AUC: 0.9625, Val Macro AUC: 0.9022\n",
      "Epoch: 016, Train Recall@10: 0.8322, Val Recall@10: 0.7915, Train Micro F1: 0.6630, Val Micro F1: 0.6174, Train Macro F1: 0.3830, Val Macro F1: 0.2442, Train Micro AUC: 0.9879, Val Micro AUC: 0.9776, Train Macro AUC: 0.9646, Val Macro AUC: 0.9014\n",
      "Epoch: 017, Train Recall@10: 0.8370, Val Recall@10: 0.7926, Train Micro F1: 0.6688, Val Micro F1: 0.6175, Train Macro F1: 0.3992, Val Macro F1: 0.2506, Train Micro AUC: 0.9883, Val Micro AUC: 0.9775, Train Macro AUC: 0.9663, Val Macro AUC: 0.9015\n",
      "Epoch: 018, Train Recall@10: 0.8403, Val Recall@10: 0.7908, Train Micro F1: 0.6725, Val Micro F1: 0.6181, Train Macro F1: 0.4173, Val Macro F1: 0.2482, Train Micro AUC: 0.9887, Val Micro AUC: 0.9773, Train Macro AUC: 0.9674, Val Macro AUC: 0.9009\n",
      "Epoch: 019, Train Recall@10: 0.8448, Val Recall@10: 0.7913, Train Micro F1: 0.6808, Val Micro F1: 0.6198, Train Macro F1: 0.4407, Val Macro F1: 0.2549, Train Micro AUC: 0.9892, Val Micro AUC: 0.9771, Train Macro AUC: 0.9692, Val Macro AUC: 0.8994\n",
      "Epoch: 020, Train Recall@10: 0.8491, Val Recall@10: 0.7911, Train Micro F1: 0.6878, Val Micro F1: 0.6199, Train Macro F1: 0.4570, Val Macro F1: 0.2587, Train Micro AUC: 0.9896, Val Micro AUC: 0.9769, Train Macro AUC: 0.9708, Val Macro AUC: 0.8983\n",
      "Epoch: 021, Train Recall@10: 0.8529, Val Recall@10: 0.7889, Train Micro F1: 0.6950, Val Micro F1: 0.6220, Train Macro F1: 0.4695, Val Macro F1: 0.2695, Train Micro AUC: 0.9900, Val Micro AUC: 0.9765, Train Macro AUC: 0.9721, Val Macro AUC: 0.8955\n",
      "Epoch: 022, Train Recall@10: 0.8570, Val Recall@10: 0.7891, Train Micro F1: 0.7008, Val Micro F1: 0.6222, Train Macro F1: 0.4801, Val Macro F1: 0.2657, Train Micro AUC: 0.9904, Val Micro AUC: 0.9762, Train Macro AUC: 0.9734, Val Macro AUC: 0.8928\n",
      "Early stopping at epoch 22\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(tfidf_model.parameters())\n",
    "prof_tfidf_ksi = train_model(tfidf_model, \n",
    "                             train_dataloader=train_dataloader,\n",
    "                             val_dataloader=val_dataloader,\n",
    "                             wikivec=wikivec,\n",
    "                             optimizer=optimizer,\n",
    "                             n_epochs=n_epochs, \n",
    "                             profile=profile, \n",
    "                             log_path=f'./log/{model_type}_ModifiedKSI_tfidf',\n",
    "                             device=DEVICE,\n",
    "                             init_hidden=True,\n",
    "                             early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(tfidf_model, f'{dir}{model_type}_ModifiedKSI_tfidf_model.pt')\n",
    "if profile:\n",
    "    print(prof_tfidf_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7887, Test Micro F1: 0.6141, Test Macro F1: 0.2484, Test Micro AUC: 0.9792, Test Macro AUC: 0.8961\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(tfidf_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del tfidf_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
