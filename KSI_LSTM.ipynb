{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e659e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, LSTM\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043df625",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 200\n",
    "batch_size = 32\n",
    "n_epochs = 1\n",
    "save = False\n",
    "profile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61eed9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0b5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22090f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,100\n",
       "├─Dropout: 1-2                           [32, 2455, 100]           --\n",
       "├─LSTM: 1-3                              [32, 2455, 200]           241,600\n",
       "├─Linear: 1-4                            [32, 344]                 69,144\n",
       "==========================================================================================\n",
       "Total params: 5,106,844\n",
       "Trainable params: 5,106,844\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 19.14\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 188.63\n",
       "Params size (MB): 20.43\n",
       "Estimated Total Size (MB): 210.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = LSTM(n_words, n_wiki, n_embedding, n_hidden)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path='./log/LSTM',\n",
    "                        device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6acda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}LSTM_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40335216",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   by_label=False,\n",
    "                                                                                                   device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path='./log/LSTM_KSI',\n",
    "                       device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45251b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}LSTM_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path='./log/LSTM_ModifiedKSI',\n",
    "                           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75113db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}LSTM_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:KSI2] *",
   "language": "python",
   "name": "conda-env-KSI2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
