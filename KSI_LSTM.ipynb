{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, LSTM\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 100 # 200 in paper, but too intensive for my machine\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False\n",
    "model_type = 'LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-3                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-4                            [32, 344]                 34,744\n",
       "==========================================================================================\n",
       "Total params: 4,911,744\n",
       "Trainable params: 4,911,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.50\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 125.78\n",
       "Params size (MB): 19.65\n",
       "Estimated Total Size (MB): 147.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, batch_size)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.4407, Val Recall@10: 0.4462, Train Micro F1: 0.0000, Val Micro F1: 0.0000, Train Macro F1: 0.0000, Val Macro F1: 0.0000, Train Micro AUC: 0.9245, Val Micro AUC: 0.9099, Train Macro AUC: 0.4644, Val Macro AUC: 0.4581\n",
      "Epoch: 002, Train Recall@10: 0.4441, Val Recall@10: 0.4502, Train Micro F1: 0.0000, Val Micro F1: 0.0000, Train Macro F1: 0.0000, Val Macro F1: 0.0000, Train Micro AUC: 0.9279, Val Micro AUC: 0.9137, Train Macro AUC: 0.5853, Val Macro AUC: 0.5927\n",
      "Epoch: 003, Train Recall@10: 0.5024, Val Recall@10: 0.5075, Train Micro F1: 0.1708, Val Micro F1: 0.1745, Train Macro F1: 0.0067, Val Macro F1: 0.0083, Train Micro AUC: 0.9402, Val Micro AUC: 0.9279, Train Macro AUC: 0.6644, Val Macro AUC: 0.6666\n",
      "Epoch: 004, Train Recall@10: 0.5562, Val Recall@10: 0.5551, Train Micro F1: 0.2825, Val Micro F1: 0.2833, Train Macro F1: 0.0147, Val Macro F1: 0.0179, Train Micro AUC: 0.9494, Val Micro AUC: 0.9381, Train Macro AUC: 0.7471, Val Macro AUC: 0.7332\n",
      "Epoch: 005, Train Recall@10: 0.5984, Val Recall@10: 0.5944, Train Micro F1: 0.4050, Val Micro F1: 0.4042, Train Macro F1: 0.0306, Val Macro F1: 0.0374, Train Micro AUC: 0.9558, Val Micro AUC: 0.9455, Train Macro AUC: 0.8085, Val Macro AUC: 0.7717\n",
      "Epoch: 006, Train Recall@10: 0.6200, Val Recall@10: 0.6144, Train Micro F1: 0.4647, Val Micro F1: 0.4605, Train Macro F1: 0.0444, Val Macro F1: 0.0534, Train Micro AUC: 0.9592, Val Micro AUC: 0.9487, Train Macro AUC: 0.8500, Val Macro AUC: 0.7810\n",
      "Epoch: 007, Train Recall@10: 0.6357, Val Recall@10: 0.6322, Train Micro F1: 0.4986, Val Micro F1: 0.4943, Train Macro F1: 0.0539, Val Macro F1: 0.0638, Train Micro AUC: 0.9613, Val Micro AUC: 0.9508, Train Macro AUC: 0.8754, Val Macro AUC: 0.7938\n",
      "Epoch: 008, Train Recall@10: 0.6213, Val Recall@10: 0.6144, Train Micro F1: 0.5035, Val Micro F1: 0.4984, Train Macro F1: 0.0542, Val Macro F1: 0.0669, Train Micro AUC: 0.9597, Val Micro AUC: 0.9481, Train Macro AUC: 0.8789, Val Macro AUC: 0.7896\n",
      "Epoch: 009, Train Recall@10: 0.6487, Val Recall@10: 0.6399, Train Micro F1: 0.4965, Val Micro F1: 0.4912, Train Macro F1: 0.0596, Val Macro F1: 0.0696, Train Micro AUC: 0.9639, Val Micro AUC: 0.9524, Train Macro AUC: 0.8932, Val Macro AUC: 0.7974\n",
      "Epoch: 010, Train Recall@10: 0.6569, Val Recall@10: 0.6479, Train Micro F1: 0.5218, Val Micro F1: 0.5132, Train Macro F1: 0.0640, Val Macro F1: 0.0758, Train Micro AUC: 0.9646, Val Micro AUC: 0.9530, Train Macro AUC: 0.8951, Val Macro AUC: 0.7950\n",
      "Epoch: 011, Train Recall@10: 0.6686, Val Recall@10: 0.6569, Train Micro F1: 0.5222, Val Micro F1: 0.5136, Train Macro F1: 0.0663, Val Macro F1: 0.0760, Train Micro AUC: 0.9666, Val Micro AUC: 0.9546, Train Macro AUC: 0.9034, Val Macro AUC: 0.7987\n",
      "Epoch: 012, Train Recall@10: 0.6750, Val Recall@10: 0.6645, Train Micro F1: 0.5343, Val Micro F1: 0.5234, Train Macro F1: 0.0766, Val Macro F1: 0.0823, Train Micro AUC: 0.9674, Val Micro AUC: 0.9554, Train Macro AUC: 0.9066, Val Macro AUC: 0.7991\n",
      "Epoch: 013, Train Recall@10: 0.6832, Val Recall@10: 0.6735, Train Micro F1: 0.5461, Val Micro F1: 0.5354, Train Macro F1: 0.0857, Val Macro F1: 0.0881, Train Micro AUC: 0.9688, Val Micro AUC: 0.9566, Train Macro AUC: 0.9107, Val Macro AUC: 0.7969\n",
      "Epoch: 014, Train Recall@10: 0.6830, Val Recall@10: 0.6703, Train Micro F1: 0.5430, Val Micro F1: 0.5334, Train Macro F1: 0.0844, Val Macro F1: 0.0848, Train Micro AUC: 0.9691, Val Micro AUC: 0.9569, Train Macro AUC: 0.9114, Val Macro AUC: 0.7991\n",
      "Epoch: 015, Train Recall@10: 0.6872, Val Recall@10: 0.6760, Train Micro F1: 0.5516, Val Micro F1: 0.5412, Train Macro F1: 0.0915, Val Macro F1: 0.0923, Train Micro AUC: 0.9699, Val Micro AUC: 0.9574, Train Macro AUC: 0.9131, Val Macro AUC: 0.7963\n",
      "Epoch: 016, Train Recall@10: 0.6945, Val Recall@10: 0.6814, Train Micro F1: 0.5591, Val Micro F1: 0.5472, Train Macro F1: 0.1090, Val Macro F1: 0.0945, Train Micro AUC: 0.9710, Val Micro AUC: 0.9582, Train Macro AUC: 0.9174, Val Macro AUC: 0.7981\n",
      "Epoch: 017, Train Recall@10: 0.7011, Val Recall@10: 0.6892, Train Micro F1: 0.5610, Val Micro F1: 0.5477, Train Macro F1: 0.1180, Val Macro F1: 0.0925, Train Micro AUC: 0.9719, Val Micro AUC: 0.9594, Train Macro AUC: 0.9197, Val Macro AUC: 0.8029\n",
      "Epoch: 018, Train Recall@10: 0.7048, Val Recall@10: 0.6921, Train Micro F1: 0.5634, Val Micro F1: 0.5493, Train Macro F1: 0.1248, Val Macro F1: 0.0924, Train Micro AUC: 0.9724, Val Micro AUC: 0.9597, Train Macro AUC: 0.9205, Val Macro AUC: 0.8031\n",
      "Epoch: 019, Train Recall@10: 0.7066, Val Recall@10: 0.6922, Train Micro F1: 0.5673, Val Micro F1: 0.5522, Train Macro F1: 0.1298, Val Macro F1: 0.0972, Train Micro AUC: 0.9729, Val Micro AUC: 0.9599, Train Macro AUC: 0.9217, Val Macro AUC: 0.8007\n",
      "Epoch: 020, Train Recall@10: 0.7101, Val Recall@10: 0.6954, Train Micro F1: 0.5678, Val Micro F1: 0.5540, Train Macro F1: 0.1402, Val Macro F1: 0.0980, Train Micro AUC: 0.9734, Val Micro AUC: 0.9603, Train Macro AUC: 0.9229, Val Macro AUC: 0.8012\n",
      "Epoch: 021, Train Recall@10: 0.7119, Val Recall@10: 0.6968, Train Micro F1: 0.5670, Val Micro F1: 0.5523, Train Macro F1: 0.1317, Val Macro F1: 0.0954, Train Micro AUC: 0.9737, Val Micro AUC: 0.9607, Train Macro AUC: 0.9232, Val Macro AUC: 0.8028\n",
      "Epoch: 022, Train Recall@10: 0.7133, Val Recall@10: 0.6973, Train Micro F1: 0.5647, Val Micro F1: 0.5493, Train Macro F1: 0.1279, Val Macro F1: 0.0962, Train Micro AUC: 0.9740, Val Micro AUC: 0.9609, Train Macro AUC: 0.9239, Val Macro AUC: 0.8037\n",
      "Epoch: 023, Train Recall@10: 0.7149, Val Recall@10: 0.6989, Train Micro F1: 0.5639, Val Micro F1: 0.5478, Train Macro F1: 0.1256, Val Macro F1: 0.0960, Train Micro AUC: 0.9741, Val Micro AUC: 0.9610, Train Macro AUC: 0.9242, Val Macro AUC: 0.8041\n",
      "Epoch: 024, Train Recall@10: 0.7156, Val Recall@10: 0.6990, Train Micro F1: 0.5641, Val Micro F1: 0.5478, Train Macro F1: 0.1275, Val Macro F1: 0.0963, Train Micro AUC: 0.9742, Val Micro AUC: 0.9611, Train Macro AUC: 0.9242, Val Macro AUC: 0.8038\n",
      "Epoch: 025, Train Recall@10: 0.7157, Val Recall@10: 0.6993, Train Micro F1: 0.5653, Val Micro F1: 0.5492, Train Macro F1: 0.1274, Val Macro F1: 0.0967, Train Micro AUC: 0.9742, Val Micro AUC: 0.9611, Train Macro AUC: 0.9242, Val Macro AUC: 0.8038\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path=f'./log/{model_type}',\n",
    "                        device=DEVICE,\n",
    "                        init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}{model_type}_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.6914, Test Micro F1: 0.5432, Test Macro F1: 0.0876, Test Micro AUC: 0.9627, Test Macro AUC: 0.7962\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   device=DEVICE,\n",
    "                                                                                                   init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,345\n",
       "Trainable params: 6,139,345\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 143.48\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 186.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6388, Val Recall@10: 0.6383, Train Micro F1: 0.3978, Val Micro F1: 0.3913, Train Macro F1: 0.0476, Val Macro F1: 0.0556, Train Micro AUC: 0.9638, Val Micro AUC: 0.9560, Train Macro AUC: 0.7964, Val Macro AUC: 0.7968\n",
      "Epoch: 002, Train Recall@10: 0.6828, Val Recall@10: 0.6765, Train Micro F1: 0.4331, Val Micro F1: 0.4237, Train Macro F1: 0.0811, Val Macro F1: 0.0920, Train Micro AUC: 0.9692, Val Micro AUC: 0.9607, Train Macro AUC: 0.8499, Val Macro AUC: 0.8305\n",
      "Epoch: 003, Train Recall@10: 0.7400, Val Recall@10: 0.7253, Train Micro F1: 0.5338, Val Micro F1: 0.5177, Train Macro F1: 0.1349, Val Macro F1: 0.1430, Train Micro AUC: 0.9762, Val Micro AUC: 0.9673, Train Macro AUC: 0.8899, Val Macro AUC: 0.8586\n",
      "Epoch: 004, Train Recall@10: 0.7728, Val Recall@10: 0.7531, Train Micro F1: 0.5762, Val Micro F1: 0.5555, Train Macro F1: 0.1803, Val Macro F1: 0.1759, Train Micro AUC: 0.9801, Val Micro AUC: 0.9703, Train Macro AUC: 0.9163, Val Macro AUC: 0.8684\n",
      "Epoch: 005, Train Recall@10: 0.7840, Val Recall@10: 0.7563, Train Micro F1: 0.5980, Val Micro F1: 0.5702, Train Macro F1: 0.2068, Val Macro F1: 0.1867, Train Micro AUC: 0.9815, Val Micro AUC: 0.9707, Train Macro AUC: 0.9330, Val Macro AUC: 0.8693\n",
      "Epoch: 006, Train Recall@10: 0.7875, Val Recall@10: 0.7572, Train Micro F1: 0.6140, Val Micro F1: 0.5836, Train Macro F1: 0.2268, Val Macro F1: 0.1989, Train Micro AUC: 0.9819, Val Micro AUC: 0.9704, Train Macro AUC: 0.9407, Val Macro AUC: 0.8703\n",
      "Epoch: 007, Train Recall@10: 0.7882, Val Recall@10: 0.7537, Train Micro F1: 0.6272, Val Micro F1: 0.5992, Train Macro F1: 0.2519, Val Macro F1: 0.2139, Train Micro AUC: 0.9822, Val Micro AUC: 0.9703, Train Macro AUC: 0.9482, Val Macro AUC: 0.8766\n",
      "Epoch: 008, Train Recall@10: 0.7841, Val Recall@10: 0.7500, Train Micro F1: 0.6184, Val Micro F1: 0.5848, Train Macro F1: 0.2678, Val Macro F1: 0.2235, Train Micro AUC: 0.9816, Val Micro AUC: 0.9689, Train Macro AUC: 0.9503, Val Macro AUC: 0.8716\n",
      "Epoch: 009, Train Recall@10: 0.7782, Val Recall@10: 0.7447, Train Micro F1: 0.6264, Val Micro F1: 0.5937, Train Macro F1: 0.2790, Val Macro F1: 0.2119, Train Micro AUC: 0.9810, Val Micro AUC: 0.9677, Train Macro AUC: 0.9505, Val Macro AUC: 0.8651\n",
      "Epoch: 010, Train Recall@10: 0.7748, Val Recall@10: 0.7384, Train Micro F1: 0.5923, Val Micro F1: 0.5628, Train Macro F1: 0.2423, Val Macro F1: 0.1837, Train Micro AUC: 0.9804, Val Micro AUC: 0.9658, Train Macro AUC: 0.9519, Val Macro AUC: 0.8574\n",
      "Epoch: 011, Train Recall@10: 0.7798, Val Recall@10: 0.7397, Train Micro F1: 0.5961, Val Micro F1: 0.5636, Train Macro F1: 0.2781, Val Macro F1: 0.2068, Train Micro AUC: 0.9806, Val Micro AUC: 0.9655, Train Macro AUC: 0.9535, Val Macro AUC: 0.8592\n",
      "Epoch: 012, Train Recall@10: 0.7827, Val Recall@10: 0.7417, Train Micro F1: 0.6092, Val Micro F1: 0.5764, Train Macro F1: 0.3162, Val Macro F1: 0.2215, Train Micro AUC: 0.9813, Val Micro AUC: 0.9662, Train Macro AUC: 0.9543, Val Macro AUC: 0.8610\n",
      "Epoch: 013, Train Recall@10: 0.7929, Val Recall@10: 0.7503, Train Micro F1: 0.6255, Val Micro F1: 0.5874, Train Macro F1: 0.3185, Val Macro F1: 0.2110, Train Micro AUC: 0.9830, Val Micro AUC: 0.9679, Train Macro AUC: 0.9590, Val Macro AUC: 0.8604\n",
      "Epoch: 014, Train Recall@10: 0.7948, Val Recall@10: 0.7496, Train Micro F1: 0.6247, Val Micro F1: 0.5827, Train Macro F1: 0.3327, Val Macro F1: 0.2159, Train Micro AUC: 0.9832, Val Micro AUC: 0.9677, Train Macro AUC: 0.9608, Val Macro AUC: 0.8587\n",
      "Epoch: 015, Train Recall@10: 0.7952, Val Recall@10: 0.7465, Train Micro F1: 0.6255, Val Micro F1: 0.5827, Train Macro F1: 0.3516, Val Macro F1: 0.2224, Train Micro AUC: 0.9832, Val Micro AUC: 0.9673, Train Macro AUC: 0.9609, Val Macro AUC: 0.8626\n",
      "Epoch: 016, Train Recall@10: 0.8056, Val Recall@10: 0.7524, Train Micro F1: 0.6508, Val Micro F1: 0.6014, Train Macro F1: 0.3786, Val Macro F1: 0.2337, Train Micro AUC: 0.9850, Val Micro AUC: 0.9690, Train Macro AUC: 0.9642, Val Macro AUC: 0.8656\n",
      "Epoch: 017, Train Recall@10: 0.8064, Val Recall@10: 0.7496, Train Micro F1: 0.6543, Val Micro F1: 0.6024, Train Macro F1: 0.3975, Val Macro F1: 0.2377, Train Micro AUC: 0.9852, Val Micro AUC: 0.9686, Train Macro AUC: 0.9652, Val Macro AUC: 0.8633\n",
      "Epoch: 018, Train Recall@10: 0.8142, Val Recall@10: 0.7522, Train Micro F1: 0.6544, Val Micro F1: 0.5979, Train Macro F1: 0.4115, Val Macro F1: 0.2228, Train Micro AUC: 0.9861, Val Micro AUC: 0.9685, Train Macro AUC: 0.9681, Val Macro AUC: 0.8619\n",
      "Epoch: 019, Train Recall@10: 0.8216, Val Recall@10: 0.7543, Train Micro F1: 0.6593, Val Micro F1: 0.6006, Train Macro F1: 0.4416, Val Macro F1: 0.2319, Train Micro AUC: 0.9870, Val Micro AUC: 0.9689, Train Macro AUC: 0.9700, Val Macro AUC: 0.8642\n",
      "Epoch: 020, Train Recall@10: 0.8296, Val Recall@10: 0.7570, Train Micro F1: 0.6711, Val Micro F1: 0.6052, Train Macro F1: 0.4648, Val Macro F1: 0.2356, Train Micro AUC: 0.9881, Val Micro AUC: 0.9696, Train Macro AUC: 0.9722, Val Macro AUC: 0.8632\n",
      "Epoch: 021, Train Recall@10: 0.8367, Val Recall@10: 0.7625, Train Micro F1: 0.6865, Val Micro F1: 0.6131, Train Macro F1: 0.4951, Val Macro F1: 0.2412, Train Micro AUC: 0.9890, Val Micro AUC: 0.9705, Train Macro AUC: 0.9740, Val Macro AUC: 0.8642\n",
      "Epoch: 022, Train Recall@10: 0.8429, Val Recall@10: 0.7645, Train Micro F1: 0.6942, Val Micro F1: 0.6161, Train Macro F1: 0.5305, Val Macro F1: 0.2388, Train Micro AUC: 0.9897, Val Micro AUC: 0.9710, Train Macro AUC: 0.9758, Val Macro AUC: 0.8643\n",
      "Epoch: 023, Train Recall@10: 0.8507, Val Recall@10: 0.7686, Train Micro F1: 0.6986, Val Micro F1: 0.6133, Train Macro F1: 0.5484, Val Macro F1: 0.2370, Train Micro AUC: 0.9904, Val Micro AUC: 0.9715, Train Macro AUC: 0.9776, Val Macro AUC: 0.8665\n",
      "Epoch: 024, Train Recall@10: 0.8546, Val Recall@10: 0.7704, Train Micro F1: 0.7026, Val Micro F1: 0.6137, Train Macro F1: 0.5476, Val Macro F1: 0.2366, Train Micro AUC: 0.9908, Val Micro AUC: 0.9719, Train Macro AUC: 0.9784, Val Macro AUC: 0.8673\n",
      "Epoch: 025, Train Recall@10: 0.8551, Val Recall@10: 0.7703, Train Micro F1: 0.7047, Val Micro F1: 0.6163, Train Macro F1: 0.5501, Val Macro F1: 0.2359, Train Micro AUC: 0.9909, Val Micro AUC: 0.9720, Train Macro AUC: 0.9786, Val Macro AUC: 0.8668\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path=f'./log/{model_type}_KSI',\n",
    "                       device=DEVICE,\n",
    "                       init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}{model_type}_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7674, Test Micro F1: 0.6162, Test Macro F1: 0.2412, Test Micro AUC: 0.9734, Test Macro AUC: 0.8576\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,347\n",
       "Trainable params: 6,139,347\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.49\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 1258.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6621, Val Recall@10: 0.6613, Train Micro F1: 0.4390, Val Micro F1: 0.4345, Train Macro F1: 0.0363, Val Macro F1: 0.0429, Train Micro AUC: 0.9653, Val Micro AUC: 0.9585, Train Macro AUC: 0.8057, Val Macro AUC: 0.8209\n",
      "Epoch: 002, Train Recall@10: 0.7175, Val Recall@10: 0.7153, Train Micro F1: 0.5017, Val Micro F1: 0.4981, Train Macro F1: 0.1002, Val Macro F1: 0.1227, Train Micro AUC: 0.9740, Val Micro AUC: 0.9681, Train Macro AUC: 0.8592, Val Macro AUC: 0.8593\n",
      "Epoch: 003, Train Recall@10: 0.7456, Val Recall@10: 0.7413, Train Micro F1: 0.5217, Val Micro F1: 0.5162, Train Macro F1: 0.1329, Val Macro F1: 0.1475, Train Micro AUC: 0.9775, Val Micro AUC: 0.9716, Train Macro AUC: 0.8837, Val Macro AUC: 0.8800\n",
      "Epoch: 004, Train Recall@10: 0.7669, Val Recall@10: 0.7621, Train Micro F1: 0.5607, Val Micro F1: 0.5532, Train Macro F1: 0.1667, Val Macro F1: 0.1714, Train Micro AUC: 0.9803, Val Micro AUC: 0.9743, Train Macro AUC: 0.9062, Val Macro AUC: 0.8925\n",
      "Epoch: 005, Train Recall@10: 0.7813, Val Recall@10: 0.7721, Train Micro F1: 0.5798, Val Micro F1: 0.5685, Train Macro F1: 0.1817, Val Macro F1: 0.1835, Train Micro AUC: 0.9818, Val Micro AUC: 0.9751, Train Macro AUC: 0.9270, Val Macro AUC: 0.9004\n",
      "Epoch: 006, Train Recall@10: 0.7874, Val Recall@10: 0.7708, Train Micro F1: 0.5797, Val Micro F1: 0.5664, Train Macro F1: 0.2075, Val Macro F1: 0.1970, Train Micro AUC: 0.9827, Val Micro AUC: 0.9755, Train Macro AUC: 0.9384, Val Macro AUC: 0.9010\n",
      "Epoch: 007, Train Recall@10: 0.7961, Val Recall@10: 0.7789, Train Micro F1: 0.6101, Val Micro F1: 0.5925, Train Macro F1: 0.2377, Val Macro F1: 0.2100, Train Micro AUC: 0.9838, Val Micro AUC: 0.9759, Train Macro AUC: 0.9505, Val Macro AUC: 0.9023\n",
      "Epoch: 008, Train Recall@10: 0.8010, Val Recall@10: 0.7790, Train Micro F1: 0.6155, Val Micro F1: 0.5931, Train Macro F1: 0.2557, Val Macro F1: 0.2121, Train Micro AUC: 0.9844, Val Micro AUC: 0.9760, Train Macro AUC: 0.9553, Val Macro AUC: 0.9033\n",
      "Epoch: 009, Train Recall@10: 0.8050, Val Recall@10: 0.7792, Train Micro F1: 0.6244, Val Micro F1: 0.5979, Train Macro F1: 0.2940, Val Macro F1: 0.2203, Train Micro AUC: 0.9850, Val Micro AUC: 0.9757, Train Macro AUC: 0.9594, Val Macro AUC: 0.8964\n",
      "Epoch: 010, Train Recall@10: 0.8122, Val Recall@10: 0.7785, Train Micro F1: 0.6323, Val Micro F1: 0.6004, Train Macro F1: 0.3173, Val Macro F1: 0.2293, Train Micro AUC: 0.9858, Val Micro AUC: 0.9758, Train Macro AUC: 0.9626, Val Macro AUC: 0.8971\n",
      "Epoch: 011, Train Recall@10: 0.8141, Val Recall@10: 0.7767, Train Micro F1: 0.6373, Val Micro F1: 0.6004, Train Macro F1: 0.3389, Val Macro F1: 0.2397, Train Micro AUC: 0.9861, Val Micro AUC: 0.9752, Train Macro AUC: 0.9642, Val Macro AUC: 0.8930\n",
      "Epoch: 012, Train Recall@10: 0.8186, Val Recall@10: 0.7747, Train Micro F1: 0.6491, Val Micro F1: 0.6062, Train Macro F1: 0.3801, Val Macro F1: 0.2427, Train Micro AUC: 0.9866, Val Micro AUC: 0.9745, Train Macro AUC: 0.9665, Val Macro AUC: 0.8891\n",
      "Epoch: 013, Train Recall@10: 0.8225, Val Recall@10: 0.7719, Train Micro F1: 0.6596, Val Micro F1: 0.6103, Train Macro F1: 0.4091, Val Macro F1: 0.2519, Train Micro AUC: 0.9872, Val Micro AUC: 0.9741, Train Macro AUC: 0.9683, Val Macro AUC: 0.8861\n",
      "Epoch: 014, Train Recall@10: 0.8254, Val Recall@10: 0.7678, Train Micro F1: 0.6668, Val Micro F1: 0.6105, Train Macro F1: 0.4299, Val Macro F1: 0.2437, Train Micro AUC: 0.9876, Val Micro AUC: 0.9733, Train Macro AUC: 0.9699, Val Macro AUC: 0.8789\n",
      "Epoch: 015, Train Recall@10: 0.8293, Val Recall@10: 0.7654, Train Micro F1: 0.6626, Val Micro F1: 0.6016, Train Macro F1: 0.4382, Val Macro F1: 0.2355, Train Micro AUC: 0.9880, Val Micro AUC: 0.9729, Train Macro AUC: 0.9718, Val Macro AUC: 0.8796\n",
      "Epoch: 016, Train Recall@10: 0.8342, Val Recall@10: 0.7642, Train Micro F1: 0.6782, Val Micro F1: 0.6102, Train Macro F1: 0.4769, Val Macro F1: 0.2458, Train Micro AUC: 0.9886, Val Micro AUC: 0.9729, Train Macro AUC: 0.9732, Val Macro AUC: 0.8773\n",
      "Epoch: 017, Train Recall@10: 0.8391, Val Recall@10: 0.7630, Train Micro F1: 0.6765, Val Micro F1: 0.6028, Train Macro F1: 0.4821, Val Macro F1: 0.2462, Train Micro AUC: 0.9891, Val Micro AUC: 0.9725, Train Macro AUC: 0.9748, Val Macro AUC: 0.8756\n",
      "Epoch: 018, Train Recall@10: 0.8423, Val Recall@10: 0.7648, Train Micro F1: 0.6755, Val Micro F1: 0.5980, Train Macro F1: 0.4971, Val Macro F1: 0.2542, Train Micro AUC: 0.9894, Val Micro AUC: 0.9725, Train Macro AUC: 0.9759, Val Macro AUC: 0.8760\n",
      "Epoch: 019, Train Recall@10: 0.8470, Val Recall@10: 0.7630, Train Micro F1: 0.6939, Val Micro F1: 0.6094, Train Macro F1: 0.5487, Val Macro F1: 0.2733, Train Micro AUC: 0.9899, Val Micro AUC: 0.9727, Train Macro AUC: 0.9771, Val Macro AUC: 0.8740\n",
      "Epoch: 020, Train Recall@10: 0.8527, Val Recall@10: 0.7621, Train Micro F1: 0.7115, Val Micro F1: 0.6193, Train Macro F1: 0.5868, Val Macro F1: 0.2740, Train Micro AUC: 0.9905, Val Micro AUC: 0.9724, Train Macro AUC: 0.9784, Val Macro AUC: 0.8692\n",
      "Epoch: 021, Train Recall@10: 0.8579, Val Recall@10: 0.7615, Train Micro F1: 0.7145, Val Micro F1: 0.6149, Train Macro F1: 0.5878, Val Macro F1: 0.2680, Train Micro AUC: 0.9909, Val Micro AUC: 0.9719, Train Macro AUC: 0.9791, Val Macro AUC: 0.8657\n",
      "Epoch: 022, Train Recall@10: 0.8638, Val Recall@10: 0.7605, Train Micro F1: 0.7127, Val Micro F1: 0.6076, Train Macro F1: 0.5915, Val Macro F1: 0.2594, Train Micro AUC: 0.9915, Val Micro AUC: 0.9716, Train Macro AUC: 0.9802, Val Macro AUC: 0.8653\n",
      "Epoch: 023, Train Recall@10: 0.8684, Val Recall@10: 0.7627, Train Micro F1: 0.7198, Val Micro F1: 0.6060, Train Macro F1: 0.6132, Val Macro F1: 0.2631, Train Micro AUC: 0.9919, Val Micro AUC: 0.9718, Train Macro AUC: 0.9811, Val Macro AUC: 0.8660\n",
      "Epoch: 024, Train Recall@10: 0.8730, Val Recall@10: 0.7644, Train Micro F1: 0.7256, Val Micro F1: 0.6067, Train Macro F1: 0.6207, Val Macro F1: 0.2653, Train Micro AUC: 0.9923, Val Micro AUC: 0.9722, Train Macro AUC: 0.9818, Val Macro AUC: 0.8673\n",
      "Epoch: 025, Train Recall@10: 0.8739, Val Recall@10: 0.7653, Train Micro F1: 0.7286, Val Micro F1: 0.6092, Train Macro F1: 0.6229, Val Macro F1: 0.2687, Train Micro AUC: 0.9923, Val Micro AUC: 0.9724, Train Macro AUC: 0.9820, Val Macro AUC: 0.8678\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path=f'./log/{model_type}_ModifiedKSI',\n",
    "                           device=DEVICE,\n",
    "                           init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}{model_type}_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7625, Test Micro F1: 0.6079, Test Macro F1: 0.2572, Test Micro AUC: 0.9739, Test Macro AUC: 0.8711\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using tfidf vectors rather than binary vectors\n",
    "dir = 'data/original_tfidf/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [2455, 32, 100]           --\n",
       "├─LSTM: 1-4                              [2455, 32, 100]           80,800\n",
       "├─Linear: 1-5                            [32, 344]                 34,744\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,139,347\n",
       "Trainable params: 6,139,347\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.54\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.49\n",
       "Params size (MB): 24.56\n",
       "Estimated Total Size (MB): 1258.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi2 = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi2.to(DEVICE)\n",
    "tfidf_model = LSTM(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi2)\n",
    "tfidf_model = tfidf_model.to(DEVICE)\n",
    "tfidf_summary = summary(tfidf_model, [(batch_size, avg_note_size), \n",
    "                                      (batch_size, n_vocab),\n",
    "                                      (n_wiki, n_vocab)], \n",
    "                        dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6843, Val Recall@10: 0.6828, Train Micro F1: 0.4748, Val Micro F1: 0.4692, Train Macro F1: 0.0531, Val Macro F1: 0.0635, Train Micro AUC: 0.9688, Val Micro AUC: 0.9627, Train Macro AUC: 0.8222, Val Macro AUC: 0.8316\n",
      "Epoch: 002, Train Recall@10: 0.7240, Val Recall@10: 0.7203, Train Micro F1: 0.5005, Val Micro F1: 0.4938, Train Macro F1: 0.1232, Val Macro F1: 0.1431, Train Micro AUC: 0.9748, Val Micro AUC: 0.9688, Train Macro AUC: 0.8639, Val Macro AUC: 0.8615\n",
      "Epoch: 003, Train Recall@10: 0.7580, Val Recall@10: 0.7505, Train Micro F1: 0.5613, Val Micro F1: 0.5524, Train Macro F1: 0.1648, Val Macro F1: 0.1681, Train Micro AUC: 0.9784, Val Micro AUC: 0.9725, Train Macro AUC: 0.8879, Val Macro AUC: 0.8818\n",
      "Epoch: 004, Train Recall@10: 0.7862, Val Recall@10: 0.7800, Train Micro F1: 0.5980, Val Micro F1: 0.5885, Train Macro F1: 0.1821, Val Macro F1: 0.1859, Train Micro AUC: 0.9818, Val Micro AUC: 0.9759, Train Macro AUC: 0.9129, Val Macro AUC: 0.8982\n",
      "Epoch: 005, Train Recall@10: 0.7969, Val Recall@10: 0.7842, Train Micro F1: 0.6167, Val Micro F1: 0.5994, Train Macro F1: 0.2075, Val Macro F1: 0.1972, Train Micro AUC: 0.9832, Val Micro AUC: 0.9763, Train Macro AUC: 0.9338, Val Macro AUC: 0.9029\n",
      "Epoch: 006, Train Recall@10: 0.8023, Val Recall@10: 0.7852, Train Micro F1: 0.6219, Val Micro F1: 0.6009, Train Macro F1: 0.2450, Val Macro F1: 0.2083, Train Micro AUC: 0.9840, Val Micro AUC: 0.9761, Train Macro AUC: 0.9458, Val Macro AUC: 0.9022\n",
      "Epoch: 007, Train Recall@10: 0.8079, Val Recall@10: 0.7861, Train Micro F1: 0.6242, Val Micro F1: 0.5981, Train Macro F1: 0.2631, Val Macro F1: 0.2130, Train Micro AUC: 0.9847, Val Micro AUC: 0.9762, Train Macro AUC: 0.9511, Val Macro AUC: 0.9000\n",
      "Epoch: 008, Train Recall@10: 0.8138, Val Recall@10: 0.7860, Train Micro F1: 0.6369, Val Micro F1: 0.6063, Train Macro F1: 0.2926, Val Macro F1: 0.2300, Train Micro AUC: 0.9855, Val Micro AUC: 0.9760, Train Macro AUC: 0.9572, Val Macro AUC: 0.8940\n",
      "Epoch: 009, Train Recall@10: 0.8161, Val Recall@10: 0.7820, Train Micro F1: 0.6398, Val Micro F1: 0.6042, Train Macro F1: 0.3307, Val Macro F1: 0.2376, Train Micro AUC: 0.9858, Val Micro AUC: 0.9752, Train Macro AUC: 0.9595, Val Macro AUC: 0.8879\n",
      "Epoch: 010, Train Recall@10: 0.8170, Val Recall@10: 0.7765, Train Micro F1: 0.6378, Val Micro F1: 0.5944, Train Macro F1: 0.3456, Val Macro F1: 0.2356, Train Micro AUC: 0.9861, Val Micro AUC: 0.9744, Train Macro AUC: 0.9612, Val Macro AUC: 0.8843\n",
      "Epoch: 011, Train Recall@10: 0.8156, Val Recall@10: 0.7715, Train Micro F1: 0.6429, Val Micro F1: 0.5952, Train Macro F1: 0.3639, Val Macro F1: 0.2369, Train Micro AUC: 0.9859, Val Micro AUC: 0.9729, Train Macro AUC: 0.9606, Val Macro AUC: 0.8770\n",
      "Epoch: 012, Train Recall@10: 0.8204, Val Recall@10: 0.7686, Train Micro F1: 0.6547, Val Micro F1: 0.6001, Train Macro F1: 0.3842, Val Macro F1: 0.2425, Train Micro AUC: 0.9865, Val Micro AUC: 0.9723, Train Macro AUC: 0.9627, Val Macro AUC: 0.8745\n",
      "Epoch: 013, Train Recall@10: 0.8245, Val Recall@10: 0.7645, Train Micro F1: 0.6651, Val Micro F1: 0.6042, Train Macro F1: 0.4157, Val Macro F1: 0.2477, Train Micro AUC: 0.9870, Val Micro AUC: 0.9713, Train Macro AUC: 0.9655, Val Macro AUC: 0.8694\n",
      "Epoch: 014, Train Recall@10: 0.8285, Val Recall@10: 0.7620, Train Micro F1: 0.6728, Val Micro F1: 0.6028, Train Macro F1: 0.4370, Val Macro F1: 0.2522, Train Micro AUC: 0.9874, Val Micro AUC: 0.9707, Train Macro AUC: 0.9673, Val Macro AUC: 0.8695\n",
      "Epoch: 015, Train Recall@10: 0.8326, Val Recall@10: 0.7578, Train Micro F1: 0.6853, Val Micro F1: 0.6085, Train Macro F1: 0.4678, Val Macro F1: 0.2648, Train Micro AUC: 0.9881, Val Micro AUC: 0.9699, Train Macro AUC: 0.9689, Val Macro AUC: 0.8638\n",
      "Epoch: 016, Train Recall@10: 0.8364, Val Recall@10: 0.7528, Train Micro F1: 0.6873, Val Micro F1: 0.6023, Train Macro F1: 0.4838, Val Macro F1: 0.2446, Train Micro AUC: 0.9886, Val Micro AUC: 0.9687, Train Macro AUC: 0.9714, Val Macro AUC: 0.8597\n",
      "Epoch: 017, Train Recall@10: 0.8375, Val Recall@10: 0.7507, Train Micro F1: 0.6857, Val Micro F1: 0.5978, Train Macro F1: 0.4978, Val Macro F1: 0.2483, Train Micro AUC: 0.9887, Val Micro AUC: 0.9682, Train Macro AUC: 0.9717, Val Macro AUC: 0.8591\n",
      "Epoch: 018, Train Recall@10: 0.8386, Val Recall@10: 0.7488, Train Micro F1: 0.6858, Val Micro F1: 0.5947, Train Macro F1: 0.5149, Val Macro F1: 0.2520, Train Micro AUC: 0.9888, Val Micro AUC: 0.9680, Train Macro AUC: 0.9723, Val Macro AUC: 0.8587\n",
      "Epoch: 019, Train Recall@10: 0.8487, Val Recall@10: 0.7507, Train Micro F1: 0.7014, Val Micro F1: 0.6009, Train Macro F1: 0.5437, Val Macro F1: 0.2555, Train Micro AUC: 0.9899, Val Micro AUC: 0.9687, Train Macro AUC: 0.9749, Val Macro AUC: 0.8582\n",
      "Epoch: 020, Train Recall@10: 0.8619, Val Recall@10: 0.7505, Train Micro F1: 0.7224, Val Micro F1: 0.6057, Train Macro F1: 0.5861, Val Macro F1: 0.2548, Train Micro AUC: 0.9913, Val Micro AUC: 0.9678, Train Macro AUC: 0.9779, Val Macro AUC: 0.8515\n",
      "Epoch: 021, Train Recall@10: 0.8628, Val Recall@10: 0.7470, Train Micro F1: 0.7217, Val Micro F1: 0.6018, Train Macro F1: 0.5882, Val Macro F1: 0.2532, Train Micro AUC: 0.9914, Val Micro AUC: 0.9662, Train Macro AUC: 0.9782, Val Macro AUC: 0.8455\n",
      "Epoch: 022, Train Recall@10: 0.8732, Val Recall@10: 0.7503, Train Micro F1: 0.7288, Val Micro F1: 0.5986, Train Macro F1: 0.6058, Val Macro F1: 0.2516, Train Micro AUC: 0.9923, Val Micro AUC: 0.9663, Train Macro AUC: 0.9802, Val Macro AUC: 0.8441\n",
      "Epoch: 023, Train Recall@10: 0.8814, Val Recall@10: 0.7530, Train Micro F1: 0.7400, Val Micro F1: 0.6006, Train Macro F1: 0.6260, Val Macro F1: 0.2514, Train Micro AUC: 0.9929, Val Micro AUC: 0.9672, Train Macro AUC: 0.9814, Val Macro AUC: 0.8478\n",
      "Epoch: 024, Train Recall@10: 0.8864, Val Recall@10: 0.7549, Train Micro F1: 0.7478, Val Micro F1: 0.6024, Train Macro F1: 0.6380, Val Macro F1: 0.2566, Train Micro AUC: 0.9933, Val Micro AUC: 0.9678, Train Macro AUC: 0.9820, Val Macro AUC: 0.8490\n",
      "Epoch: 025, Train Recall@10: 0.8879, Val Recall@10: 0.7565, Train Micro F1: 0.7510, Val Micro F1: 0.6042, Train Macro F1: 0.6352, Val Macro F1: 0.2579, Train Micro AUC: 0.9934, Val Micro AUC: 0.9681, Train Macro AUC: 0.9824, Val Macro AUC: 0.8495\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(tfidf_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_tfidf_ksi = train_model(tfidf_model, \n",
    "                             train_dataloader=train_dataloader,\n",
    "                             val_dataloader=val_dataloader,\n",
    "                             wikivec=wikivec,\n",
    "                             optimizer=optimizer,\n",
    "                             scheduler=scheduler,\n",
    "                             n_epochs=n_epochs, \n",
    "                             profile=profile, \n",
    "                             log_path=f'./log/{model_type}_ModifiedKSI_tfidf',\n",
    "                             device=DEVICE,\n",
    "                             init_hidden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(tfidf_model, f'{dir}{model_type}_ModifiedKSI_tfidf_model.pt')\n",
    "if profile:\n",
    "    print(prof_tfidf_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7545, Test Micro F1: 0.6045, Test Macro F1: 0.2591, Test Micro AUC: 0.9698, Test Macro AUC: 0.8503\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(tfidf_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE,\n",
    "                                                                                                  init_hidden=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del tfidf_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
