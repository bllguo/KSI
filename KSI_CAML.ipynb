{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, CAML\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 100 # 300 in paper, but too intensive for my machine\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False\n",
    "model_type = 'CAML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-3                            [32, 100, 2456]           100,100\n",
       "├─Linear: 1-4                            --                        34,400\n",
       "├─Linear: 1-5                            --                        34,744\n",
       "==========================================================================================\n",
       "Total params: 4,965,444\n",
       "Trainable params: 4,965,444\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.02\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 125.72\n",
       "Params size (MB): 19.86\n",
       "Estimated Total Size (MB): 147.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CAML(n_words, n_wiki, n_embedding, n_hidden)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.5400, Val Recall@10: 0.5413, Train Micro F1: 0.3866, Val Micro F1: 0.3877, Train Macro F1: 0.0192, Val Macro F1: 0.0232, Train Micro AUC: 0.9415, Val Micro AUC: 0.9289, Train Macro AUC: 0.6295, Val Macro AUC: 0.6378\n",
      "Epoch: 002, Train Recall@10: 0.6906, Val Recall@10: 0.6807, Train Micro F1: 0.5660, Val Micro F1: 0.5541, Train Macro F1: 0.0677, Val Macro F1: 0.0797, Train Micro AUC: 0.9606, Val Micro AUC: 0.9513, Train Macro AUC: 0.7239, Val Macro AUC: 0.7244\n",
      "Epoch: 003, Train Recall@10: 0.7604, Val Recall@10: 0.7453, Train Micro F1: 0.6210, Val Micro F1: 0.5964, Train Macro F1: 0.1184, Val Macro F1: 0.1313, Train Micro AUC: 0.9692, Val Micro AUC: 0.9601, Train Macro AUC: 0.7728, Val Macro AUC: 0.7495\n",
      "Epoch: 004, Train Recall@10: 0.7750, Val Recall@10: 0.7557, Train Micro F1: 0.6315, Val Micro F1: 0.6065, Train Macro F1: 0.1432, Val Macro F1: 0.1575, Train Micro AUC: 0.9715, Val Micro AUC: 0.9624, Train Macro AUC: 0.7658, Val Macro AUC: 0.7508\n",
      "Epoch: 005, Train Recall@10: 0.7751, Val Recall@10: 0.7533, Train Micro F1: 0.6250, Val Micro F1: 0.5964, Train Macro F1: 0.1459, Val Macro F1: 0.1595, Train Micro AUC: 0.9701, Val Micro AUC: 0.9599, Train Macro AUC: 0.7419, Val Macro AUC: 0.7327\n",
      "Epoch: 006, Train Recall@10: 0.7615, Val Recall@10: 0.7405, Train Micro F1: 0.6257, Val Micro F1: 0.5946, Train Macro F1: 0.1417, Val Macro F1: 0.1533, Train Micro AUC: 0.9672, Val Micro AUC: 0.9562, Train Macro AUC: 0.7172, Val Macro AUC: 0.7125\n",
      "Epoch: 007, Train Recall@10: 0.7623, Val Recall@10: 0.7366, Train Micro F1: 0.6315, Val Micro F1: 0.5984, Train Macro F1: 0.1388, Val Macro F1: 0.1515, Train Micro AUC: 0.9662, Val Micro AUC: 0.9549, Train Macro AUC: 0.7016, Val Macro AUC: 0.7076\n",
      "Epoch: 008, Train Recall@10: 0.7659, Val Recall@10: 0.7382, Train Micro F1: 0.6288, Val Micro F1: 0.5893, Train Macro F1: 0.1397, Val Macro F1: 0.1478, Train Micro AUC: 0.9666, Val Micro AUC: 0.9545, Train Macro AUC: 0.6970, Val Macro AUC: 0.6992\n",
      "Epoch: 009, Train Recall@10: 0.7667, Val Recall@10: 0.7358, Train Micro F1: 0.6447, Val Micro F1: 0.6058, Train Macro F1: 0.1465, Val Macro F1: 0.1548, Train Micro AUC: 0.9650, Val Micro AUC: 0.9524, Train Macro AUC: 0.6968, Val Macro AUC: 0.7080\n",
      "Epoch: 010, Train Recall@10: 0.7718, Val Recall@10: 0.7401, Train Micro F1: 0.6476, Val Micro F1: 0.6002, Train Macro F1: 0.1514, Val Macro F1: 0.1593, Train Micro AUC: 0.9659, Val Micro AUC: 0.9531, Train Macro AUC: 0.7008, Val Macro AUC: 0.6971\n",
      "Epoch: 011, Train Recall@10: 0.7672, Val Recall@10: 0.7345, Train Micro F1: 0.6506, Val Micro F1: 0.6013, Train Macro F1: 0.1492, Val Macro F1: 0.1546, Train Micro AUC: 0.9656, Val Micro AUC: 0.9530, Train Macro AUC: 0.6955, Val Macro AUC: 0.6948\n",
      "Epoch: 012, Train Recall@10: 0.7724, Val Recall@10: 0.7333, Train Micro F1: 0.6570, Val Micro F1: 0.6012, Train Macro F1: 0.1582, Val Macro F1: 0.1619, Train Micro AUC: 0.9642, Val Micro AUC: 0.9499, Train Macro AUC: 0.7034, Val Macro AUC: 0.6952\n",
      "Epoch: 013, Train Recall@10: 0.7725, Val Recall@10: 0.7312, Train Micro F1: 0.6681, Val Micro F1: 0.6071, Train Macro F1: 0.1596, Val Macro F1: 0.1605, Train Micro AUC: 0.9600, Val Micro AUC: 0.9444, Train Macro AUC: 0.7131, Val Macro AUC: 0.6818\n",
      "Epoch: 014, Train Recall@10: 0.7774, Val Recall@10: 0.7296, Train Micro F1: 0.6749, Val Micro F1: 0.6076, Train Macro F1: 0.1608, Val Macro F1: 0.1550, Train Micro AUC: 0.9643, Val Micro AUC: 0.9483, Train Macro AUC: 0.7016, Val Macro AUC: 0.6815\n",
      "Epoch: 015, Train Recall@10: 0.7870, Val Recall@10: 0.7374, Train Micro F1: 0.6833, Val Micro F1: 0.6117, Train Macro F1: 0.1693, Val Macro F1: 0.1631, Train Micro AUC: 0.9665, Val Micro AUC: 0.9503, Train Macro AUC: 0.7162, Val Macro AUC: 0.6959\n",
      "Epoch: 016, Train Recall@10: 0.7909, Val Recall@10: 0.7357, Train Micro F1: 0.6881, Val Micro F1: 0.6065, Train Macro F1: 0.1732, Val Macro F1: 0.1636, Train Micro AUC: 0.9664, Val Micro AUC: 0.9494, Train Macro AUC: 0.7155, Val Macro AUC: 0.6830\n",
      "Epoch: 017, Train Recall@10: 0.7976, Val Recall@10: 0.7413, Train Micro F1: 0.6993, Val Micro F1: 0.6132, Train Macro F1: 0.1797, Val Macro F1: 0.1695, Train Micro AUC: 0.9667, Val Micro AUC: 0.9481, Train Macro AUC: 0.7090, Val Macro AUC: 0.6755\n",
      "Epoch: 018, Train Recall@10: 0.8030, Val Recall@10: 0.7477, Train Micro F1: 0.7023, Val Micro F1: 0.6126, Train Macro F1: 0.1802, Val Macro F1: 0.1705, Train Micro AUC: 0.9683, Val Micro AUC: 0.9512, Train Macro AUC: 0.7201, Val Macro AUC: 0.6865\n",
      "Epoch: 019, Train Recall@10: 0.8114, Val Recall@10: 0.7495, Train Micro F1: 0.7154, Val Micro F1: 0.6171, Train Macro F1: 0.1867, Val Macro F1: 0.1690, Train Micro AUC: 0.9695, Val Micro AUC: 0.9512, Train Macro AUC: 0.7258, Val Macro AUC: 0.6874\n",
      "Epoch: 020, Train Recall@10: 0.8154, Val Recall@10: 0.7497, Train Micro F1: 0.7165, Val Micro F1: 0.6159, Train Macro F1: 0.1873, Val Macro F1: 0.1724, Train Micro AUC: 0.9714, Val Micro AUC: 0.9529, Train Macro AUC: 0.7270, Val Macro AUC: 0.6804\n",
      "Epoch: 021, Train Recall@10: 0.8187, Val Recall@10: 0.7550, Train Micro F1: 0.7234, Val Micro F1: 0.6210, Train Macro F1: 0.1917, Val Macro F1: 0.1741, Train Micro AUC: 0.9725, Val Micro AUC: 0.9526, Train Macro AUC: 0.7305, Val Macro AUC: 0.6865\n",
      "Epoch: 022, Train Recall@10: 0.8223, Val Recall@10: 0.7545, Train Micro F1: 0.7264, Val Micro F1: 0.6232, Train Macro F1: 0.1931, Val Macro F1: 0.1745, Train Micro AUC: 0.9733, Val Micro AUC: 0.9528, Train Macro AUC: 0.7347, Val Macro AUC: 0.6939\n",
      "Epoch: 023, Train Recall@10: 0.8237, Val Recall@10: 0.7577, Train Micro F1: 0.7262, Val Micro F1: 0.6228, Train Macro F1: 0.1938, Val Macro F1: 0.1775, Train Micro AUC: 0.9740, Val Micro AUC: 0.9538, Train Macro AUC: 0.7376, Val Macro AUC: 0.6816\n",
      "Epoch: 024, Train Recall@10: 0.8254, Val Recall@10: 0.7607, Train Micro F1: 0.7289, Val Micro F1: 0.6242, Train Macro F1: 0.1961, Val Macro F1: 0.1785, Train Micro AUC: 0.9743, Val Micro AUC: 0.9548, Train Macro AUC: 0.7369, Val Macro AUC: 0.6872\n",
      "Epoch: 025, Train Recall@10: 0.8258, Val Recall@10: 0.7601, Train Micro F1: 0.7300, Val Micro F1: 0.6213, Train Macro F1: 0.1966, Val Macro F1: 0.1764, Train Micro AUC: 0.9746, Val Micro AUC: 0.9541, Train Macro AUC: 0.7359, Val Macro AUC: 0.6748\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path=f'./log/{model_type}',\n",
    "                        device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}{model_type}_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7543, Test Micro F1: 0.6224, Test Macro F1: 0.1653, Test Micro AUC: 0.9557, Test Macro AUC: 0.6728\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,901\n",
       "Trainable params: 6,123,901\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 143.42\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 186.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6643, Val Recall@10: 0.6612, Train Micro F1: 0.4511, Val Micro F1: 0.4464, Train Macro F1: 0.0500, Val Macro F1: 0.0604, Train Micro AUC: 0.9666, Val Micro AUC: 0.9589, Train Macro AUC: 0.8158, Val Macro AUC: 0.8108\n",
      "Epoch: 002, Train Recall@10: 0.7594, Val Recall@10: 0.7463, Train Micro F1: 0.5769, Val Micro F1: 0.5610, Train Macro F1: 0.1080, Val Macro F1: 0.1205, Train Micro AUC: 0.9767, Val Micro AUC: 0.9689, Train Macro AUC: 0.8849, Val Macro AUC: 0.8532\n",
      "Epoch: 003, Train Recall@10: 0.7928, Val Recall@10: 0.7743, Train Micro F1: 0.6312, Val Micro F1: 0.6038, Train Macro F1: 0.1766, Val Macro F1: 0.1829, Train Micro AUC: 0.9805, Val Micro AUC: 0.9717, Train Macro AUC: 0.9044, Val Macro AUC: 0.8600\n",
      "Epoch: 004, Train Recall@10: 0.8068, Val Recall@10: 0.7816, Train Micro F1: 0.6537, Val Micro F1: 0.6186, Train Macro F1: 0.2270, Val Macro F1: 0.2099, Train Micro AUC: 0.9817, Val Micro AUC: 0.9724, Train Macro AUC: 0.8984, Val Macro AUC: 0.8525\n",
      "Epoch: 005, Train Recall@10: 0.8000, Val Recall@10: 0.7683, Train Micro F1: 0.6381, Val Micro F1: 0.6014, Train Macro F1: 0.2143, Val Macro F1: 0.2049, Train Micro AUC: 0.9800, Val Micro AUC: 0.9692, Train Macro AUC: 0.8611, Val Macro AUC: 0.8173\n",
      "Epoch: 006, Train Recall@10: 0.7990, Val Recall@10: 0.7642, Train Micro F1: 0.6398, Val Micro F1: 0.5981, Train Macro F1: 0.2352, Val Macro F1: 0.2242, Train Micro AUC: 0.9797, Val Micro AUC: 0.9685, Train Macro AUC: 0.8470, Val Macro AUC: 0.8188\n",
      "Epoch: 007, Train Recall@10: 0.7911, Val Recall@10: 0.7535, Train Micro F1: 0.6286, Val Micro F1: 0.5823, Train Macro F1: 0.2106, Val Macro F1: 0.1887, Train Micro AUC: 0.9776, Val Micro AUC: 0.9654, Train Macro AUC: 0.8132, Val Macro AUC: 0.7910\n",
      "Epoch: 008, Train Recall@10: 0.7935, Val Recall@10: 0.7564, Train Micro F1: 0.6197, Val Micro F1: 0.5717, Train Macro F1: 0.2235, Val Macro F1: 0.2013, Train Micro AUC: 0.9778, Val Micro AUC: 0.9644, Train Macro AUC: 0.8321, Val Macro AUC: 0.7902\n",
      "Epoch: 009, Train Recall@10: 0.7991, Val Recall@10: 0.7552, Train Micro F1: 0.6471, Val Micro F1: 0.5947, Train Macro F1: 0.2541, Val Macro F1: 0.2248, Train Micro AUC: 0.9791, Val Micro AUC: 0.9659, Train Macro AUC: 0.8385, Val Macro AUC: 0.8073\n",
      "Epoch: 010, Train Recall@10: 0.7990, Val Recall@10: 0.7557, Train Micro F1: 0.6450, Val Micro F1: 0.5859, Train Macro F1: 0.2399, Val Macro F1: 0.2106, Train Micro AUC: 0.9789, Val Micro AUC: 0.9655, Train Macro AUC: 0.8208, Val Macro AUC: 0.7987\n",
      "Epoch: 011, Train Recall@10: 0.8039, Val Recall@10: 0.7539, Train Micro F1: 0.6506, Val Micro F1: 0.5886, Train Macro F1: 0.2485, Val Macro F1: 0.2218, Train Micro AUC: 0.9796, Val Micro AUC: 0.9657, Train Macro AUC: 0.8426, Val Macro AUC: 0.8000\n",
      "Epoch: 012, Train Recall@10: 0.8081, Val Recall@10: 0.7535, Train Micro F1: 0.6648, Val Micro F1: 0.5958, Train Macro F1: 0.2663, Val Macro F1: 0.2279, Train Micro AUC: 0.9793, Val Micro AUC: 0.9650, Train Macro AUC: 0.8389, Val Macro AUC: 0.8005\n",
      "Epoch: 013, Train Recall@10: 0.8048, Val Recall@10: 0.7466, Train Micro F1: 0.6684, Val Micro F1: 0.5957, Train Macro F1: 0.2722, Val Macro F1: 0.2245, Train Micro AUC: 0.9784, Val Micro AUC: 0.9629, Train Macro AUC: 0.8564, Val Macro AUC: 0.8034\n",
      "Epoch: 014, Train Recall@10: 0.8128, Val Recall@10: 0.7507, Train Micro F1: 0.6727, Val Micro F1: 0.5933, Train Macro F1: 0.2837, Val Macro F1: 0.2211, Train Micro AUC: 0.9803, Val Micro AUC: 0.9638, Train Macro AUC: 0.8442, Val Macro AUC: 0.7938\n",
      "Epoch: 015, Train Recall@10: 0.8239, Val Recall@10: 0.7550, Train Micro F1: 0.6902, Val Micro F1: 0.6057, Train Macro F1: 0.2970, Val Macro F1: 0.2286, Train Micro AUC: 0.9823, Val Micro AUC: 0.9655, Train Macro AUC: 0.8596, Val Macro AUC: 0.7987\n",
      "Epoch: 016, Train Recall@10: 0.8288, Val Recall@10: 0.7542, Train Micro F1: 0.6999, Val Micro F1: 0.6088, Train Macro F1: 0.3142, Val Macro F1: 0.2434, Train Micro AUC: 0.9829, Val Micro AUC: 0.9650, Train Macro AUC: 0.8687, Val Macro AUC: 0.7993\n",
      "Epoch: 017, Train Recall@10: 0.8318, Val Recall@10: 0.7539, Train Micro F1: 0.6927, Val Micro F1: 0.5882, Train Macro F1: 0.3184, Val Macro F1: 0.2365, Train Micro AUC: 0.9830, Val Micro AUC: 0.9638, Train Macro AUC: 0.8673, Val Macro AUC: 0.7989\n",
      "Epoch: 018, Train Recall@10: 0.8421, Val Recall@10: 0.7539, Train Micro F1: 0.7107, Val Micro F1: 0.5976, Train Macro F1: 0.3390, Val Macro F1: 0.2364, Train Micro AUC: 0.9845, Val Micro AUC: 0.9640, Train Macro AUC: 0.8879, Val Macro AUC: 0.7961\n",
      "Epoch: 019, Train Recall@10: 0.8482, Val Recall@10: 0.7531, Train Micro F1: 0.7165, Val Micro F1: 0.5984, Train Macro F1: 0.3593, Val Macro F1: 0.2393, Train Micro AUC: 0.9858, Val Micro AUC: 0.9642, Train Macro AUC: 0.8890, Val Macro AUC: 0.7991\n",
      "Epoch: 020, Train Recall@10: 0.8569, Val Recall@10: 0.7589, Train Micro F1: 0.7263, Val Micro F1: 0.5999, Train Macro F1: 0.3786, Val Macro F1: 0.2433, Train Micro AUC: 0.9871, Val Micro AUC: 0.9651, Train Macro AUC: 0.8958, Val Macro AUC: 0.8068\n",
      "Epoch: 021, Train Recall@10: 0.8644, Val Recall@10: 0.7627, Train Micro F1: 0.7420, Val Micro F1: 0.6106, Train Macro F1: 0.3985, Val Macro F1: 0.2485, Train Micro AUC: 0.9882, Val Micro AUC: 0.9660, Train Macro AUC: 0.9060, Val Macro AUC: 0.8123\n",
      "Epoch: 022, Train Recall@10: 0.8727, Val Recall@10: 0.7675, Train Micro F1: 0.7532, Val Micro F1: 0.6161, Train Macro F1: 0.4234, Val Macro F1: 0.2511, Train Micro AUC: 0.9894, Val Micro AUC: 0.9666, Train Macro AUC: 0.9083, Val Macro AUC: 0.8122\n",
      "Epoch: 023, Train Recall@10: 0.8785, Val Recall@10: 0.7686, Train Micro F1: 0.7579, Val Micro F1: 0.6148, Train Macro F1: 0.4428, Val Macro F1: 0.2559, Train Micro AUC: 0.9899, Val Micro AUC: 0.9670, Train Macro AUC: 0.9115, Val Macro AUC: 0.8103\n",
      "Epoch: 024, Train Recall@10: 0.8807, Val Recall@10: 0.7701, Train Micro F1: 0.7613, Val Micro F1: 0.6164, Train Macro F1: 0.4417, Val Macro F1: 0.2502, Train Micro AUC: 0.9903, Val Micro AUC: 0.9671, Train Macro AUC: 0.9139, Val Macro AUC: 0.7997\n",
      "Epoch: 025, Train Recall@10: 0.8818, Val Recall@10: 0.7680, Train Micro F1: 0.7630, Val Micro F1: 0.6158, Train Macro F1: 0.4415, Val Macro F1: 0.2485, Train Micro AUC: 0.9903, Val Micro AUC: 0.9673, Train Macro AUC: 0.9154, Val Macro AUC: 0.8016\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path=f'./log/{model_type}_KSI',\n",
    "                       device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}{model_type}_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7666, Test Micro F1: 0.6143, Test Macro F1: 0.2488, Test Micro AUC: 0.9687, Test Macro AUC: 0.8042\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,903\n",
       "Trainable params: 6,123,903\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.43\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 1258.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6667, Val Recall@10: 0.6642, Train Micro F1: 0.4905, Val Micro F1: 0.4871, Train Macro F1: 0.0525, Val Macro F1: 0.0643, Train Micro AUC: 0.9666, Val Micro AUC: 0.9597, Train Macro AUC: 0.8078, Val Macro AUC: 0.8363\n",
      "Epoch: 002, Train Recall@10: 0.7579, Val Recall@10: 0.7516, Train Micro F1: 0.5694, Val Micro F1: 0.5602, Train Macro F1: 0.1086, Val Macro F1: 0.1298, Train Micro AUC: 0.9769, Val Micro AUC: 0.9711, Train Macro AUC: 0.8840, Val Macro AUC: 0.8804\n",
      "Epoch: 003, Train Recall@10: 0.7902, Val Recall@10: 0.7825, Train Micro F1: 0.6188, Val Micro F1: 0.6006, Train Macro F1: 0.1573, Val Macro F1: 0.1719, Train Micro AUC: 0.9809, Val Micro AUC: 0.9749, Train Macro AUC: 0.9046, Val Macro AUC: 0.8938\n",
      "Epoch: 004, Train Recall@10: 0.8014, Val Recall@10: 0.7870, Train Micro F1: 0.6327, Val Micro F1: 0.6094, Train Macro F1: 0.1913, Val Macro F1: 0.2013, Train Micro AUC: 0.9815, Val Micro AUC: 0.9749, Train Macro AUC: 0.8946, Val Macro AUC: 0.8742\n",
      "Epoch: 005, Train Recall@10: 0.8014, Val Recall@10: 0.7828, Train Micro F1: 0.6322, Val Micro F1: 0.6066, Train Macro F1: 0.2046, Val Macro F1: 0.2037, Train Micro AUC: 0.9807, Val Micro AUC: 0.9733, Train Macro AUC: 0.8711, Val Macro AUC: 0.8351\n",
      "Epoch: 006, Train Recall@10: 0.8035, Val Recall@10: 0.7828, Train Micro F1: 0.6296, Val Micro F1: 0.5986, Train Macro F1: 0.2077, Val Macro F1: 0.2012, Train Micro AUC: 0.9806, Val Micro AUC: 0.9729, Train Macro AUC: 0.8600, Val Macro AUC: 0.8386\n",
      "Epoch: 007, Train Recall@10: 0.8076, Val Recall@10: 0.7842, Train Micro F1: 0.6332, Val Micro F1: 0.6004, Train Macro F1: 0.2127, Val Macro F1: 0.2082, Train Micro AUC: 0.9811, Val Micro AUC: 0.9731, Train Macro AUC: 0.8545, Val Macro AUC: 0.8447\n",
      "Epoch: 008, Train Recall@10: 0.8130, Val Recall@10: 0.7858, Train Micro F1: 0.6364, Val Micro F1: 0.5971, Train Macro F1: 0.2340, Val Macro F1: 0.2234, Train Micro AUC: 0.9820, Val Micro AUC: 0.9733, Train Macro AUC: 0.8504, Val Macro AUC: 0.8355\n",
      "Epoch: 009, Train Recall@10: 0.8182, Val Recall@10: 0.7826, Train Micro F1: 0.6508, Val Micro F1: 0.6023, Train Macro F1: 0.2494, Val Macro F1: 0.2241, Train Micro AUC: 0.9826, Val Micro AUC: 0.9728, Train Macro AUC: 0.8548, Val Macro AUC: 0.8451\n",
      "Epoch: 010, Train Recall@10: 0.8241, Val Recall@10: 0.7822, Train Micro F1: 0.6589, Val Micro F1: 0.6036, Train Macro F1: 0.2742, Val Macro F1: 0.2306, Train Micro AUC: 0.9833, Val Micro AUC: 0.9724, Train Macro AUC: 0.8615, Val Macro AUC: 0.8329\n",
      "Epoch: 011, Train Recall@10: 0.8308, Val Recall@10: 0.7794, Train Micro F1: 0.6710, Val Micro F1: 0.6048, Train Macro F1: 0.2926, Val Macro F1: 0.2293, Train Micro AUC: 0.9836, Val Micro AUC: 0.9715, Train Macro AUC: 0.8628, Val Macro AUC: 0.8296\n",
      "Epoch: 012, Train Recall@10: 0.8347, Val Recall@10: 0.7785, Train Micro F1: 0.6818, Val Micro F1: 0.6092, Train Macro F1: 0.2886, Val Macro F1: 0.2367, Train Micro AUC: 0.9841, Val Micro AUC: 0.9713, Train Macro AUC: 0.8667, Val Macro AUC: 0.8379\n",
      "Epoch: 013, Train Recall@10: 0.8370, Val Recall@10: 0.7735, Train Micro F1: 0.6873, Val Micro F1: 0.6081, Train Macro F1: 0.3125, Val Macro F1: 0.2336, Train Micro AUC: 0.9842, Val Micro AUC: 0.9702, Train Macro AUC: 0.8829, Val Macro AUC: 0.8319\n",
      "Epoch: 014, Train Recall@10: 0.8417, Val Recall@10: 0.7721, Train Micro F1: 0.6965, Val Micro F1: 0.6099, Train Macro F1: 0.3283, Val Macro F1: 0.2352, Train Micro AUC: 0.9851, Val Micro AUC: 0.9700, Train Macro AUC: 0.8935, Val Macro AUC: 0.8301\n",
      "Epoch: 015, Train Recall@10: 0.8463, Val Recall@10: 0.7649, Train Micro F1: 0.7098, Val Micro F1: 0.6101, Train Macro F1: 0.3525, Val Macro F1: 0.2435, Train Micro AUC: 0.9854, Val Micro AUC: 0.9686, Train Macro AUC: 0.8964, Val Macro AUC: 0.8346\n",
      "Epoch: 016, Train Recall@10: 0.8498, Val Recall@10: 0.7568, Train Micro F1: 0.7119, Val Micro F1: 0.6014, Train Macro F1: 0.3468, Val Macro F1: 0.2369, Train Micro AUC: 0.9855, Val Micro AUC: 0.9670, Train Macro AUC: 0.8979, Val Macro AUC: 0.8431\n",
      "Epoch: 017, Train Recall@10: 0.8584, Val Recall@10: 0.7584, Train Micro F1: 0.7191, Val Micro F1: 0.5998, Train Macro F1: 0.4010, Val Macro F1: 0.2516, Train Micro AUC: 0.9868, Val Micro AUC: 0.9674, Train Macro AUC: 0.9025, Val Macro AUC: 0.8347\n",
      "Epoch: 018, Train Recall@10: 0.8669, Val Recall@10: 0.7560, Train Micro F1: 0.7337, Val Micro F1: 0.6038, Train Macro F1: 0.4351, Val Macro F1: 0.2679, Train Micro AUC: 0.9877, Val Micro AUC: 0.9666, Train Macro AUC: 0.9080, Val Macro AUC: 0.8374\n",
      "Epoch: 019, Train Recall@10: 0.8766, Val Recall@10: 0.7588, Train Micro F1: 0.7520, Val Micro F1: 0.6145, Train Macro F1: 0.4706, Val Macro F1: 0.2723, Train Micro AUC: 0.9889, Val Micro AUC: 0.9664, Train Macro AUC: 0.9090, Val Macro AUC: 0.8216\n",
      "Epoch: 020, Train Recall@10: 0.8839, Val Recall@10: 0.7576, Train Micro F1: 0.7677, Val Micro F1: 0.6192, Train Macro F1: 0.4836, Val Macro F1: 0.2700, Train Micro AUC: 0.9899, Val Micro AUC: 0.9665, Train Macro AUC: 0.9191, Val Macro AUC: 0.8246\n",
      "Epoch: 021, Train Recall@10: 0.8892, Val Recall@10: 0.7570, Train Micro F1: 0.7740, Val Micro F1: 0.6154, Train Macro F1: 0.4951, Val Macro F1: 0.2590, Train Micro AUC: 0.9905, Val Micro AUC: 0.9657, Train Macro AUC: 0.9235, Val Macro AUC: 0.8195\n",
      "Epoch: 022, Train Recall@10: 0.8934, Val Recall@10: 0.7591, Train Micro F1: 0.7792, Val Micro F1: 0.6164, Train Macro F1: 0.5009, Val Macro F1: 0.2553, Train Micro AUC: 0.9910, Val Micro AUC: 0.9657, Train Macro AUC: 0.9245, Val Macro AUC: 0.8243\n",
      "Epoch: 023, Train Recall@10: 0.8970, Val Recall@10: 0.7583, Train Micro F1: 0.7806, Val Micro F1: 0.6132, Train Macro F1: 0.5127, Val Macro F1: 0.2503, Train Micro AUC: 0.9915, Val Micro AUC: 0.9661, Train Macro AUC: 0.9292, Val Macro AUC: 0.8245\n",
      "Epoch: 024, Train Recall@10: 0.9000, Val Recall@10: 0.7589, Train Micro F1: 0.7852, Val Micro F1: 0.6128, Train Macro F1: 0.5157, Val Macro F1: 0.2568, Train Micro AUC: 0.9918, Val Micro AUC: 0.9661, Train Macro AUC: 0.9296, Val Macro AUC: 0.8265\n",
      "Epoch: 025, Train Recall@10: 0.9013, Val Recall@10: 0.7574, Train Micro F1: 0.7871, Val Micro F1: 0.6138, Train Macro F1: 0.5165, Val Macro F1: 0.2493, Train Micro AUC: 0.9919, Val Micro AUC: 0.9658, Train Macro AUC: 0.9296, Val Macro AUC: 0.8221\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path=f'./log/{model_type}_ModifiedKSI',\n",
    "                           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}{model_type}_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7619, Test Micro F1: 0.6139, Test Macro F1: 0.2686, Test Micro AUC: 0.9677, Test Macro AUC: 0.8122\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using tfidf vectors rather than binary vectors\n",
    "dir = 'data/original_tfidf/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,903\n",
       "Trainable params: 6,123,903\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.43\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 1258.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi2 = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi2.to(DEVICE)\n",
    "tfidf_model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi2)\n",
    "tfidf_model = tfidf_model.to(DEVICE)\n",
    "tfidf_summary = summary(tfidf_model, [(batch_size, avg_note_size), \n",
    "                                      (batch_size, n_vocab),\n",
    "                                      (n_wiki, n_vocab)], \n",
    "                        dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6806, Val Recall@10: 0.6762, Train Micro F1: 0.4953, Val Micro F1: 0.4908, Train Macro F1: 0.0642, Val Macro F1: 0.0783, Train Micro AUC: 0.9681, Val Micro AUC: 0.9612, Train Macro AUC: 0.8252, Val Macro AUC: 0.8375\n",
      "Epoch: 002, Train Recall@10: 0.7656, Val Recall@10: 0.7585, Train Micro F1: 0.5847, Val Micro F1: 0.5752, Train Macro F1: 0.1237, Val Macro F1: 0.1431, Train Micro AUC: 0.9779, Val Micro AUC: 0.9721, Train Macro AUC: 0.8872, Val Macro AUC: 0.8771\n",
      "Epoch: 003, Train Recall@10: 0.7965, Val Recall@10: 0.7853, Train Micro F1: 0.6309, Val Micro F1: 0.6117, Train Macro F1: 0.1800, Val Macro F1: 0.1972, Train Micro AUC: 0.9815, Val Micro AUC: 0.9753, Train Macro AUC: 0.9105, Val Macro AUC: 0.8951\n",
      "Epoch: 004, Train Recall@10: 0.8115, Val Recall@10: 0.7941, Train Micro F1: 0.6456, Val Micro F1: 0.6180, Train Macro F1: 0.2286, Val Macro F1: 0.2334, Train Micro AUC: 0.9833, Val Micro AUC: 0.9762, Train Macro AUC: 0.9100, Val Macro AUC: 0.8736\n",
      "Epoch: 005, Train Recall@10: 0.8095, Val Recall@10: 0.7872, Train Micro F1: 0.6355, Val Micro F1: 0.6045, Train Macro F1: 0.2315, Val Macro F1: 0.2177, Train Micro AUC: 0.9823, Val Micro AUC: 0.9748, Train Macro AUC: 0.8833, Val Macro AUC: 0.8553\n",
      "Epoch: 006, Train Recall@10: 0.8066, Val Recall@10: 0.7826, Train Micro F1: 0.6305, Val Micro F1: 0.5947, Train Macro F1: 0.2313, Val Macro F1: 0.2179, Train Micro AUC: 0.9812, Val Micro AUC: 0.9732, Train Macro AUC: 0.8654, Val Macro AUC: 0.8507\n",
      "Epoch: 007, Train Recall@10: 0.8123, Val Recall@10: 0.7841, Train Micro F1: 0.6509, Val Micro F1: 0.6087, Train Macro F1: 0.2503, Val Macro F1: 0.2283, Train Micro AUC: 0.9822, Val Micro AUC: 0.9736, Train Macro AUC: 0.8506, Val Macro AUC: 0.8520\n",
      "Epoch: 008, Train Recall@10: 0.8147, Val Recall@10: 0.7805, Train Micro F1: 0.6453, Val Micro F1: 0.5977, Train Macro F1: 0.2444, Val Macro F1: 0.2180, Train Micro AUC: 0.9827, Val Micro AUC: 0.9731, Train Macro AUC: 0.8570, Val Macro AUC: 0.8393\n",
      "Epoch: 009, Train Recall@10: 0.8213, Val Recall@10: 0.7817, Train Micro F1: 0.6647, Val Micro F1: 0.6121, Train Macro F1: 0.2695, Val Macro F1: 0.2219, Train Micro AUC: 0.9833, Val Micro AUC: 0.9722, Train Macro AUC: 0.8492, Val Macro AUC: 0.8263\n",
      "Epoch: 010, Train Recall@10: 0.8294, Val Recall@10: 0.7807, Train Micro F1: 0.6755, Val Micro F1: 0.6139, Train Macro F1: 0.2868, Val Macro F1: 0.2398, Train Micro AUC: 0.9844, Val Micro AUC: 0.9719, Train Macro AUC: 0.8593, Val Macro AUC: 0.8346\n",
      "Epoch: 011, Train Recall@10: 0.8314, Val Recall@10: 0.7749, Train Micro F1: 0.6776, Val Micro F1: 0.6092, Train Macro F1: 0.3112, Val Macro F1: 0.2512, Train Micro AUC: 0.9845, Val Micro AUC: 0.9701, Train Macro AUC: 0.8634, Val Macro AUC: 0.8269\n",
      "Epoch: 012, Train Recall@10: 0.8382, Val Recall@10: 0.7731, Train Micro F1: 0.6855, Val Micro F1: 0.6044, Train Macro F1: 0.3206, Val Macro F1: 0.2488, Train Micro AUC: 0.9854, Val Micro AUC: 0.9691, Train Macro AUC: 0.8751, Val Macro AUC: 0.8175\n",
      "Epoch: 013, Train Recall@10: 0.8420, Val Recall@10: 0.7653, Train Micro F1: 0.6910, Val Micro F1: 0.5992, Train Macro F1: 0.3397, Val Macro F1: 0.2564, Train Micro AUC: 0.9845, Val Micro AUC: 0.9667, Train Macro AUC: 0.8817, Val Macro AUC: 0.8193\n",
      "Epoch: 014, Train Recall@10: 0.8492, Val Recall@10: 0.7601, Train Micro F1: 0.7050, Val Micro F1: 0.6021, Train Macro F1: 0.3740, Val Macro F1: 0.2504, Train Micro AUC: 0.9863, Val Micro AUC: 0.9662, Train Macro AUC: 0.8831, Val Macro AUC: 0.8132\n",
      "Epoch: 015, Train Recall@10: 0.8535, Val Recall@10: 0.7536, Train Micro F1: 0.7165, Val Micro F1: 0.6027, Train Macro F1: 0.3911, Val Macro F1: 0.2575, Train Micro AUC: 0.9870, Val Micro AUC: 0.9647, Train Macro AUC: 0.8893, Val Macro AUC: 0.8162\n",
      "Epoch: 016, Train Recall@10: 0.8603, Val Recall@10: 0.7481, Train Micro F1: 0.7210, Val Micro F1: 0.5962, Train Macro F1: 0.4221, Val Macro F1: 0.2666, Train Micro AUC: 0.9872, Val Micro AUC: 0.9632, Train Macro AUC: 0.8943, Val Macro AUC: 0.8206\n",
      "Epoch: 017, Train Recall@10: 0.8672, Val Recall@10: 0.7529, Train Micro F1: 0.7339, Val Micro F1: 0.6010, Train Macro F1: 0.4382, Val Macro F1: 0.2739, Train Micro AUC: 0.9888, Val Micro AUC: 0.9643, Train Macro AUC: 0.8970, Val Macro AUC: 0.8223\n",
      "Epoch: 018, Train Recall@10: 0.8732, Val Recall@10: 0.7496, Train Micro F1: 0.7393, Val Micro F1: 0.5987, Train Macro F1: 0.4509, Val Macro F1: 0.2601, Train Micro AUC: 0.9894, Val Micro AUC: 0.9634, Train Macro AUC: 0.9028, Val Macro AUC: 0.8142\n",
      "Epoch: 019, Train Recall@10: 0.8826, Val Recall@10: 0.7522, Train Micro F1: 0.7529, Val Micro F1: 0.5994, Train Macro F1: 0.4814, Val Macro F1: 0.2731, Train Micro AUC: 0.9905, Val Micro AUC: 0.9646, Train Macro AUC: 0.9088, Val Macro AUC: 0.8148\n",
      "Epoch: 020, Train Recall@10: 0.8890, Val Recall@10: 0.7520, Train Micro F1: 0.7676, Val Micro F1: 0.6044, Train Macro F1: 0.5051, Val Macro F1: 0.2765, Train Micro AUC: 0.9913, Val Micro AUC: 0.9642, Train Macro AUC: 0.9138, Val Macro AUC: 0.8145\n",
      "Epoch: 021, Train Recall@10: 0.8940, Val Recall@10: 0.7499, Train Micro F1: 0.7776, Val Micro F1: 0.6084, Train Macro F1: 0.5329, Val Macro F1: 0.2736, Train Micro AUC: 0.9918, Val Micro AUC: 0.9637, Train Macro AUC: 0.9181, Val Macro AUC: 0.8097\n",
      "Epoch: 022, Train Recall@10: 0.8995, Val Recall@10: 0.7515, Train Micro F1: 0.7843, Val Micro F1: 0.6072, Train Macro F1: 0.5480, Val Macro F1: 0.2746, Train Micro AUC: 0.9923, Val Micro AUC: 0.9632, Train Macro AUC: 0.9220, Val Macro AUC: 0.8087\n",
      "Epoch: 023, Train Recall@10: 0.9028, Val Recall@10: 0.7519, Train Micro F1: 0.7894, Val Micro F1: 0.6060, Train Macro F1: 0.5595, Val Macro F1: 0.2722, Train Micro AUC: 0.9928, Val Micro AUC: 0.9629, Train Macro AUC: 0.9252, Val Macro AUC: 0.8081\n",
      "Epoch: 024, Train Recall@10: 0.9074, Val Recall@10: 0.7540, Train Micro F1: 0.7935, Val Micro F1: 0.6043, Train Macro F1: 0.5672, Val Macro F1: 0.2732, Train Micro AUC: 0.9932, Val Micro AUC: 0.9633, Train Macro AUC: 0.9266, Val Macro AUC: 0.8103\n",
      "Epoch: 025, Train Recall@10: 0.9083, Val Recall@10: 0.7537, Train Micro F1: 0.7955, Val Micro F1: 0.6055, Train Macro F1: 0.5717, Val Macro F1: 0.2762, Train Micro AUC: 0.9933, Val Micro AUC: 0.9635, Train Macro AUC: 0.9267, Val Macro AUC: 0.8119\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(tfidf_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_tfidf_ksi = train_model(tfidf_model, \n",
    "                             train_dataloader=train_dataloader,\n",
    "                             val_dataloader=val_dataloader,\n",
    "                             wikivec=wikivec,\n",
    "                             optimizer=optimizer,\n",
    "                             scheduler=scheduler,\n",
    "                             n_epochs=n_epochs, \n",
    "                             profile=profile, \n",
    "                             log_path=f'./log/{model_type}_ModifiedKSI_tfidf',\n",
    "                             device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(tfidf_model, f'{dir}{model_type}_ModifiedKSI_tfidf_model.pt')\n",
    "if profile:\n",
    "    print(prof_tfidf_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7518, Test Micro F1: 0.6033, Test Macro F1: 0.2716, Test Micro AUC: 0.9652, Test Macro AUC: 0.8080\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(tfidf_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del tfidf_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
