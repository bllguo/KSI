{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, CAML\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "n_hidden = 100 # 300 in paper, but too intensive for my machine\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False\n",
    "model_type = 'CAML'\n",
    "early_stopping = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-3                            [32, 100, 2456]           100,100\n",
       "├─Linear: 1-4                            --                        34,400\n",
       "├─Linear: 1-5                            --                        34,744\n",
       "==========================================================================================\n",
       "Total params: 4,965,444\n",
       "Trainable params: 4,965,444\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.02\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 125.72\n",
       "Params size (MB): 19.86\n",
       "Estimated Total Size (MB): 147.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CAML(n_words, n_wiki, n_embedding, n_hidden)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), \n",
    "                                    (batch_size, n_vocab)], \n",
    "                       dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6281, Val Recall@10: 0.6273, Train Micro F1: 0.5048, Val Micro F1: 0.4980, Train Macro F1: 0.0409, Val Macro F1: 0.0486, Train Micro AUC: 0.9539, Val Micro AUC: 0.9428, Train Macro AUC: 0.6861, Val Macro AUC: 0.6866\n",
      "Epoch: 002, Train Recall@10: 0.7344, Val Recall@10: 0.7252, Train Micro F1: 0.6097, Val Micro F1: 0.5883, Train Macro F1: 0.0837, Val Macro F1: 0.0957, Train Micro AUC: 0.9674, Val Micro AUC: 0.9583, Train Macro AUC: 0.7714, Val Macro AUC: 0.7556\n",
      "Epoch: 003, Train Recall@10: 0.7776, Val Recall@10: 0.7622, Train Micro F1: 0.6525, Val Micro F1: 0.6225, Train Macro F1: 0.1186, Val Macro F1: 0.1333, Train Micro AUC: 0.9740, Val Micro AUC: 0.9649, Train Macro AUC: 0.8187, Val Macro AUC: 0.7834\n",
      "Epoch: 004, Train Recall@10: 0.8022, Val Recall@10: 0.7779, Train Micro F1: 0.6758, Val Micro F1: 0.6347, Train Macro F1: 0.1498, Val Macro F1: 0.1586, Train Micro AUC: 0.9782, Val Micro AUC: 0.9687, Train Macro AUC: 0.8525, Val Macro AUC: 0.8008\n",
      "Epoch: 005, Train Recall@10: 0.8206, Val Recall@10: 0.7890, Train Micro F1: 0.6980, Val Micro F1: 0.6490, Train Macro F1: 0.1830, Val Macro F1: 0.1887, Train Micro AUC: 0.9813, Val Micro AUC: 0.9713, Train Macro AUC: 0.8829, Val Macro AUC: 0.8135\n",
      "Epoch: 006, Train Recall@10: 0.8364, Val Recall@10: 0.7985, Train Micro F1: 0.7111, Val Micro F1: 0.6505, Train Macro F1: 0.2052, Val Macro F1: 0.2039, Train Micro AUC: 0.9837, Val Micro AUC: 0.9728, Train Macro AUC: 0.9109, Val Macro AUC: 0.8245\n",
      "Epoch: 007, Train Recall@10: 0.8493, Val Recall@10: 0.8023, Train Micro F1: 0.7241, Val Micro F1: 0.6572, Train Macro F1: 0.2301, Val Macro F1: 0.2174, Train Micro AUC: 0.9858, Val Micro AUC: 0.9739, Train Macro AUC: 0.9254, Val Macro AUC: 0.8335\n",
      "Epoch: 008, Train Recall@10: 0.8594, Val Recall@10: 0.8041, Train Micro F1: 0.7355, Val Micro F1: 0.6582, Train Macro F1: 0.2607, Val Macro F1: 0.2339, Train Micro AUC: 0.9874, Val Micro AUC: 0.9746, Train Macro AUC: 0.9397, Val Macro AUC: 0.8412\n",
      "Epoch: 009, Train Recall@10: 0.8679, Val Recall@10: 0.8079, Train Micro F1: 0.7454, Val Micro F1: 0.6606, Train Macro F1: 0.2877, Val Macro F1: 0.2460, Train Micro AUC: 0.9887, Val Micro AUC: 0.9750, Train Macro AUC: 0.9504, Val Macro AUC: 0.8473\n",
      "Epoch: 010, Train Recall@10: 0.8762, Val Recall@10: 0.8080, Train Micro F1: 0.7536, Val Micro F1: 0.6611, Train Macro F1: 0.3165, Val Macro F1: 0.2542, Train Micro AUC: 0.9898, Val Micro AUC: 0.9753, Train Macro AUC: 0.9570, Val Macro AUC: 0.8453\n",
      "Epoch: 011, Train Recall@10: 0.8828, Val Recall@10: 0.8081, Train Micro F1: 0.7598, Val Micro F1: 0.6607, Train Macro F1: 0.3488, Val Macro F1: 0.2588, Train Micro AUC: 0.9907, Val Micro AUC: 0.9753, Train Macro AUC: 0.9633, Val Macro AUC: 0.8481\n",
      "Epoch: 012, Train Recall@10: 0.8894, Val Recall@10: 0.8078, Train Micro F1: 0.7683, Val Micro F1: 0.6609, Train Macro F1: 0.3826, Val Macro F1: 0.2600, Train Micro AUC: 0.9916, Val Micro AUC: 0.9750, Train Macro AUC: 0.9673, Val Macro AUC: 0.8496\n",
      "Epoch: 013, Train Recall@10: 0.8959, Val Recall@10: 0.8089, Train Micro F1: 0.7771, Val Micro F1: 0.6632, Train Macro F1: 0.4300, Val Macro F1: 0.2640, Train Micro AUC: 0.9924, Val Micro AUC: 0.9752, Train Macro AUC: 0.9716, Val Macro AUC: 0.8488\n",
      "Epoch: 014, Train Recall@10: 0.9022, Val Recall@10: 0.8111, Train Micro F1: 0.7839, Val Micro F1: 0.6601, Train Macro F1: 0.4757, Val Macro F1: 0.2675, Train Micro AUC: 0.9931, Val Micro AUC: 0.9750, Train Macro AUC: 0.9753, Val Macro AUC: 0.8453\n",
      "Epoch: 015, Train Recall@10: 0.9082, Val Recall@10: 0.8100, Train Micro F1: 0.7912, Val Micro F1: 0.6601, Train Macro F1: 0.5235, Val Macro F1: 0.2698, Train Micro AUC: 0.9937, Val Micro AUC: 0.9749, Train Macro AUC: 0.9777, Val Macro AUC: 0.8485\n",
      "Epoch: 016, Train Recall@10: 0.9136, Val Recall@10: 0.8094, Train Micro F1: 0.7982, Val Micro F1: 0.6605, Train Macro F1: 0.5669, Val Macro F1: 0.2736, Train Micro AUC: 0.9943, Val Micro AUC: 0.9748, Train Macro AUC: 0.9801, Val Macro AUC: 0.8416\n",
      "Epoch: 017, Train Recall@10: 0.9177, Val Recall@10: 0.8107, Train Micro F1: 0.8039, Val Micro F1: 0.6600, Train Macro F1: 0.6014, Val Macro F1: 0.2740, Train Micro AUC: 0.9947, Val Micro AUC: 0.9747, Train Macro AUC: 0.9822, Val Macro AUC: 0.8436\n",
      "Epoch: 018, Train Recall@10: 0.9225, Val Recall@10: 0.8111, Train Micro F1: 0.8116, Val Micro F1: 0.6608, Train Macro F1: 0.6316, Val Macro F1: 0.2740, Train Micro AUC: 0.9951, Val Micro AUC: 0.9743, Train Macro AUC: 0.9840, Val Macro AUC: 0.8432\n",
      "Epoch: 019, Train Recall@10: 0.9272, Val Recall@10: 0.8082, Train Micro F1: 0.8181, Val Micro F1: 0.6587, Train Macro F1: 0.6587, Val Macro F1: 0.2756, Train Micro AUC: 0.9956, Val Micro AUC: 0.9742, Train Macro AUC: 0.9856, Val Macro AUC: 0.8439\n",
      "Early stopping at epoch 19\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path=f'./log/{model_type}',\n",
    "                        device=DEVICE,\n",
    "                        early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}{model_type}_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.8043, Test Micro F1: 0.6585, Test Macro F1: 0.2427, Test Micro AUC: 0.9763, Test Macro AUC: 0.8351\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,901\n",
       "Trainable params: 6,123,901\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 143.42\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 186.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7117, Val Recall@10: 0.7044, Train Micro F1: 0.5164, Val Micro F1: 0.5058, Train Macro F1: 0.0766, Val Macro F1: 0.0893, Train Micro AUC: 0.9722, Val Micro AUC: 0.9645, Train Macro AUC: 0.8515, Val Macro AUC: 0.8304\n",
      "Epoch: 002, Train Recall@10: 0.7777, Val Recall@10: 0.7671, Train Micro F1: 0.6137, Val Micro F1: 0.5923, Train Macro F1: 0.1256, Val Macro F1: 0.1382, Train Micro AUC: 0.9795, Val Micro AUC: 0.9716, Train Macro AUC: 0.9016, Val Macro AUC: 0.8568\n",
      "Epoch: 003, Train Recall@10: 0.8096, Val Recall@10: 0.7910, Train Micro F1: 0.6594, Val Micro F1: 0.6288, Train Macro F1: 0.1734, Val Macro F1: 0.1830, Train Micro AUC: 0.9832, Val Micro AUC: 0.9747, Train Macro AUC: 0.9269, Val Macro AUC: 0.8734\n",
      "Epoch: 004, Train Recall@10: 0.8275, Val Recall@10: 0.7998, Train Micro F1: 0.6818, Val Micro F1: 0.6401, Train Macro F1: 0.2162, Val Macro F1: 0.2147, Train Micro AUC: 0.9856, Val Micro AUC: 0.9762, Train Macro AUC: 0.9428, Val Macro AUC: 0.8807\n",
      "Epoch: 005, Train Recall@10: 0.8419, Val Recall@10: 0.8047, Train Micro F1: 0.7008, Val Micro F1: 0.6454, Train Macro F1: 0.2552, Val Macro F1: 0.2378, Train Micro AUC: 0.9874, Val Micro AUC: 0.9771, Train Macro AUC: 0.9529, Val Macro AUC: 0.8870\n",
      "Epoch: 006, Train Recall@10: 0.8544, Val Recall@10: 0.8050, Train Micro F1: 0.7157, Val Micro F1: 0.6482, Train Macro F1: 0.3054, Val Macro F1: 0.2534, Train Micro AUC: 0.9889, Val Micro AUC: 0.9772, Train Macro AUC: 0.9599, Val Macro AUC: 0.8844\n",
      "Epoch: 007, Train Recall@10: 0.8656, Val Recall@10: 0.8030, Train Micro F1: 0.7315, Val Micro F1: 0.6474, Train Macro F1: 0.3484, Val Macro F1: 0.2639, Train Micro AUC: 0.9901, Val Micro AUC: 0.9768, Train Macro AUC: 0.9662, Val Macro AUC: 0.8807\n",
      "Epoch: 008, Train Recall@10: 0.8768, Val Recall@10: 0.8022, Train Micro F1: 0.7454, Val Micro F1: 0.6481, Train Macro F1: 0.4092, Val Macro F1: 0.2731, Train Micro AUC: 0.9913, Val Micro AUC: 0.9763, Train Macro AUC: 0.9721, Val Macro AUC: 0.8788\n",
      "Epoch: 009, Train Recall@10: 0.8849, Val Recall@10: 0.7992, Train Micro F1: 0.7571, Val Micro F1: 0.6469, Train Macro F1: 0.4699, Val Macro F1: 0.2812, Train Micro AUC: 0.9922, Val Micro AUC: 0.9755, Train Macro AUC: 0.9758, Val Macro AUC: 0.8734\n",
      "Epoch: 010, Train Recall@10: 0.8953, Val Recall@10: 0.7968, Train Micro F1: 0.7708, Val Micro F1: 0.6450, Train Macro F1: 0.5153, Val Macro F1: 0.2886, Train Micro AUC: 0.9932, Val Micro AUC: 0.9746, Train Macro AUC: 0.9800, Val Macro AUC: 0.8720\n",
      "Epoch: 011, Train Recall@10: 0.9032, Val Recall@10: 0.7915, Train Micro F1: 0.7822, Val Micro F1: 0.6456, Train Macro F1: 0.5754, Val Macro F1: 0.2935, Train Micro AUC: 0.9939, Val Micro AUC: 0.9736, Train Macro AUC: 0.9832, Val Macro AUC: 0.8688\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path=f'./log/{model_type}_KSI',\n",
    "                       device=DEVICE,\n",
    "                       early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}{model_type}_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.8029, Test Micro F1: 0.6452, Test Macro F1: 0.2364, Test Micro AUC: 0.9785, Test Macro AUC: 0.8912\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,903\n",
       "Trainable params: 6,123,903\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.43\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 1258.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7414, Val Recall@10: 0.7404, Train Micro F1: 0.5554, Val Micro F1: 0.5498, Train Macro F1: 0.0940, Val Macro F1: 0.1128, Train Micro AUC: 0.9757, Val Micro AUC: 0.9699, Train Macro AUC: 0.8647, Val Macro AUC: 0.8641\n",
      "Epoch: 002, Train Recall@10: 0.7822, Val Recall@10: 0.7731, Train Micro F1: 0.6041, Val Micro F1: 0.5916, Train Macro F1: 0.1386, Val Macro F1: 0.1616, Train Micro AUC: 0.9803, Val Micro AUC: 0.9745, Train Macro AUC: 0.8950, Val Macro AUC: 0.8782\n",
      "Epoch: 003, Train Recall@10: 0.8058, Val Recall@10: 0.7912, Train Micro F1: 0.6370, Val Micro F1: 0.6137, Train Macro F1: 0.1883, Val Macro F1: 0.1982, Train Micro AUC: 0.9829, Val Micro AUC: 0.9766, Train Macro AUC: 0.9107, Val Macro AUC: 0.8868\n",
      "Epoch: 004, Train Recall@10: 0.8195, Val Recall@10: 0.7985, Train Micro F1: 0.6593, Val Micro F1: 0.6278, Train Macro F1: 0.2176, Val Macro F1: 0.2280, Train Micro AUC: 0.9847, Val Micro AUC: 0.9778, Train Macro AUC: 0.9291, Val Macro AUC: 0.8972\n",
      "Epoch: 005, Train Recall@10: 0.8303, Val Recall@10: 0.8029, Train Micro F1: 0.6778, Val Micro F1: 0.6357, Train Macro F1: 0.2472, Val Macro F1: 0.2454, Train Micro AUC: 0.9861, Val Micro AUC: 0.9782, Train Macro AUC: 0.9414, Val Macro AUC: 0.9008\n",
      "Epoch: 006, Train Recall@10: 0.8410, Val Recall@10: 0.8060, Train Micro F1: 0.6944, Val Micro F1: 0.6429, Train Macro F1: 0.2767, Val Macro F1: 0.2653, Train Micro AUC: 0.9874, Val Micro AUC: 0.9787, Train Macro AUC: 0.9507, Val Macro AUC: 0.9005\n",
      "Epoch: 007, Train Recall@10: 0.8508, Val Recall@10: 0.8062, Train Micro F1: 0.7078, Val Micro F1: 0.6465, Train Macro F1: 0.3200, Val Macro F1: 0.2728, Train Micro AUC: 0.9885, Val Micro AUC: 0.9788, Train Macro AUC: 0.9573, Val Macro AUC: 0.9019\n",
      "Epoch: 008, Train Recall@10: 0.8597, Val Recall@10: 0.8078, Train Micro F1: 0.7210, Val Micro F1: 0.6486, Train Macro F1: 0.3555, Val Macro F1: 0.2761, Train Micro AUC: 0.9895, Val Micro AUC: 0.9788, Train Macro AUC: 0.9632, Val Macro AUC: 0.9028\n",
      "Epoch: 009, Train Recall@10: 0.8670, Val Recall@10: 0.8090, Train Micro F1: 0.7330, Val Micro F1: 0.6496, Train Macro F1: 0.3991, Val Macro F1: 0.2896, Train Micro AUC: 0.9903, Val Micro AUC: 0.9788, Train Macro AUC: 0.9677, Val Macro AUC: 0.9051\n",
      "Epoch: 010, Train Recall@10: 0.8754, Val Recall@10: 0.8105, Train Micro F1: 0.7439, Val Micro F1: 0.6500, Train Macro F1: 0.4424, Val Macro F1: 0.2876, Train Micro AUC: 0.9912, Val Micro AUC: 0.9788, Train Macro AUC: 0.9721, Val Macro AUC: 0.9022\n",
      "Epoch: 011, Train Recall@10: 0.8824, Val Recall@10: 0.8075, Train Micro F1: 0.7543, Val Micro F1: 0.6526, Train Macro F1: 0.4833, Val Macro F1: 0.3101, Train Micro AUC: 0.9919, Val Micro AUC: 0.9784, Train Macro AUC: 0.9752, Val Macro AUC: 0.8980\n",
      "Epoch: 012, Train Recall@10: 0.8889, Val Recall@10: 0.8062, Train Micro F1: 0.7647, Val Micro F1: 0.6509, Train Macro F1: 0.5304, Val Macro F1: 0.3039, Train Micro AUC: 0.9926, Val Micro AUC: 0.9781, Train Macro AUC: 0.9781, Val Macro AUC: 0.8928\n",
      "Epoch: 013, Train Recall@10: 0.8958, Val Recall@10: 0.8046, Train Micro F1: 0.7743, Val Micro F1: 0.6513, Train Macro F1: 0.5760, Val Macro F1: 0.3042, Train Micro AUC: 0.9932, Val Micro AUC: 0.9780, Train Macro AUC: 0.9804, Val Macro AUC: 0.8948\n",
      "Epoch: 014, Train Recall@10: 0.9014, Val Recall@10: 0.8060, Train Micro F1: 0.7825, Val Micro F1: 0.6521, Train Macro F1: 0.6038, Val Macro F1: 0.2977, Train Micro AUC: 0.9937, Val Micro AUC: 0.9778, Train Macro AUC: 0.9825, Val Macro AUC: 0.8939\n",
      "Epoch: 015, Train Recall@10: 0.9074, Val Recall@10: 0.8036, Train Micro F1: 0.7927, Val Micro F1: 0.6533, Train Macro F1: 0.6508, Val Macro F1: 0.3149, Train Micro AUC: 0.9943, Val Micro AUC: 0.9771, Train Macro AUC: 0.9847, Val Macro AUC: 0.8893\n",
      "Early stopping at epoch 15\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path=f'./log/{model_type}_ModifiedKSI',\n",
    "                           device=DEVICE,\n",
    "                           early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}{model_type}_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.8067, Test Micro F1: 0.6480, Test Macro F1: 0.2777, Test Micro AUC: 0.9799, Test Macro AUC: 0.9011\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using tfidf vectors rather than binary vectors\n",
    "dir = 'data/original_tfidf/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CAML                                     --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2456]           100,100\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,123,903\n",
       "Trainable params: 6,123,903\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.06\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1215.43\n",
       "Params size (MB): 24.50\n",
       "Estimated Total Size (MB): 1258.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi2 = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi2.to(DEVICE)\n",
    "tfidf_model = CAML(n_words, n_wiki, n_embedding, n_hidden, ksi=mod_ksi2)\n",
    "tfidf_model = tfidf_model.to(DEVICE)\n",
    "tfidf_summary = summary(tfidf_model, [(batch_size, avg_note_size), \n",
    "                                      (batch_size, n_vocab),\n",
    "                                      (n_wiki, n_vocab)], \n",
    "                        dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7436, Val Recall@10: 0.7413, Train Micro F1: 0.5555, Val Micro F1: 0.5510, Train Macro F1: 0.1081, Val Macro F1: 0.1323, Train Micro AUC: 0.9763, Val Micro AUC: 0.9705, Train Macro AUC: 0.8720, Val Macro AUC: 0.8654\n",
      "Epoch: 002, Train Recall@10: 0.7893, Val Recall@10: 0.7790, Train Micro F1: 0.6127, Val Micro F1: 0.6002, Train Macro F1: 0.1687, Val Macro F1: 0.1938, Train Micro AUC: 0.9813, Val Micro AUC: 0.9754, Train Macro AUC: 0.8979, Val Macro AUC: 0.8894\n",
      "Epoch: 003, Train Recall@10: 0.8102, Val Recall@10: 0.7955, Train Micro F1: 0.6424, Val Micro F1: 0.6203, Train Macro F1: 0.2121, Val Macro F1: 0.2183, Train Micro AUC: 0.9836, Val Micro AUC: 0.9773, Train Macro AUC: 0.9173, Val Macro AUC: 0.8935\n",
      "Epoch: 004, Train Recall@10: 0.8234, Val Recall@10: 0.8039, Train Micro F1: 0.6632, Val Micro F1: 0.6287, Train Macro F1: 0.2427, Val Macro F1: 0.2382, Train Micro AUC: 0.9853, Val Micro AUC: 0.9783, Train Macro AUC: 0.9325, Val Macro AUC: 0.8991\n",
      "Epoch: 005, Train Recall@10: 0.8356, Val Recall@10: 0.8091, Train Micro F1: 0.6819, Val Micro F1: 0.6384, Train Macro F1: 0.2723, Val Macro F1: 0.2511, Train Micro AUC: 0.9867, Val Micro AUC: 0.9789, Train Macro AUC: 0.9434, Val Macro AUC: 0.9023\n",
      "Epoch: 006, Train Recall@10: 0.8458, Val Recall@10: 0.8103, Train Micro F1: 0.6965, Val Micro F1: 0.6432, Train Macro F1: 0.3060, Val Macro F1: 0.2632, Train Micro AUC: 0.9878, Val Micro AUC: 0.9790, Train Macro AUC: 0.9517, Val Macro AUC: 0.9026\n",
      "Epoch: 007, Train Recall@10: 0.8548, Val Recall@10: 0.8120, Train Micro F1: 0.7107, Val Micro F1: 0.6453, Train Macro F1: 0.3326, Val Macro F1: 0.2678, Train Micro AUC: 0.9888, Val Micro AUC: 0.9790, Train Macro AUC: 0.9577, Val Macro AUC: 0.9014\n",
      "Epoch: 008, Train Recall@10: 0.8648, Val Recall@10: 0.8102, Train Micro F1: 0.7229, Val Micro F1: 0.6463, Train Macro F1: 0.3705, Val Macro F1: 0.2731, Train Micro AUC: 0.9898, Val Micro AUC: 0.9788, Train Macro AUC: 0.9640, Val Macro AUC: 0.8998\n",
      "Epoch: 009, Train Recall@10: 0.8730, Val Recall@10: 0.8109, Train Micro F1: 0.7365, Val Micro F1: 0.6517, Train Macro F1: 0.4023, Val Macro F1: 0.2848, Train Micro AUC: 0.9907, Val Micro AUC: 0.9789, Train Macro AUC: 0.9693, Val Macro AUC: 0.9019\n",
      "Epoch: 010, Train Recall@10: 0.8803, Val Recall@10: 0.8102, Train Micro F1: 0.7474, Val Micro F1: 0.6523, Train Macro F1: 0.4353, Val Macro F1: 0.2913, Train Micro AUC: 0.9915, Val Micro AUC: 0.9786, Train Macro AUC: 0.9728, Val Macro AUC: 0.9010\n",
      "Epoch: 011, Train Recall@10: 0.8873, Val Recall@10: 0.8092, Train Micro F1: 0.7593, Val Micro F1: 0.6529, Train Macro F1: 0.4923, Val Macro F1: 0.2964, Train Micro AUC: 0.9923, Val Micro AUC: 0.9783, Train Macro AUC: 0.9753, Val Macro AUC: 0.8967\n",
      "Epoch: 012, Train Recall@10: 0.8940, Val Recall@10: 0.8062, Train Micro F1: 0.7693, Val Micro F1: 0.6515, Train Macro F1: 0.5373, Val Macro F1: 0.2981, Train Micro AUC: 0.9929, Val Micro AUC: 0.9780, Train Macro AUC: 0.9786, Val Macro AUC: 0.8939\n",
      "Early stopping at epoch 12\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(tfidf_model.parameters())\n",
    "prof_tfidf_ksi = train_model(tfidf_model, \n",
    "                             train_dataloader=train_dataloader,\n",
    "                             val_dataloader=val_dataloader,\n",
    "                             wikivec=wikivec,\n",
    "                             optimizer=optimizer,\n",
    "                             n_epochs=n_epochs, \n",
    "                             profile=profile, \n",
    "                             log_path=f'./log/{model_type}_ModifiedKSI_tfidf',\n",
    "                             device=DEVICE,\n",
    "                             early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(tfidf_model, f'{dir}{model_type}_ModifiedKSI_tfidf_model.pt')\n",
    "if profile:\n",
    "    print(prof_tfidf_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.8076, Test Micro F1: 0.6414, Test Macro F1: 0.2678, Test Micro AUC: 0.9805, Test Macro AUC: 0.9037\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(tfidf_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del tfidf_model\n",
    "gc.collect()\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
