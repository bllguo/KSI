{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "training_data=np.load(f'{dir}training_data.npy', allow_pickle=True)\n",
    "test_data=np.load(f'{dir}test_data.npy', allow_pickle=True)\n",
    "val_data=np.load(f'{dir}val_data.npy', allow_pickle=True)\n",
    "word_to_ix=np.load(f'{dir}word_to_ix.npy', allow_pickle=True).item() # words (in notes) to index\n",
    "ix_to_word=np.load(f'{dir}ix_to_word.npy', allow_pickle=True).item() # index to words (in notes). not strictly needed for model\n",
    "wikivec=np.load(f'{dir}newwikivec.npy', allow_pickle=True) # wiki article embeddings (# codes with wiki articles, vocab size)\n",
    "wikivoc=np.load(f'{dir}wikivoc.npy', allow_pickle=True).item() # ICD-9 codes with wiki articles. not strictly needed for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)\n",
    "n_embedding = 100\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "wikivec = torch.FloatTensor(wikivec).to(DEVICE) # wikivec is a model input for KSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(block):\n",
    "    block_size = len(block)\n",
    "    max_words = np.max([len(i[0]) for i in block])\n",
    "    mat = np.zeros((block_size, max_words), dtype=int)\n",
    "    for i in range(block_size):\n",
    "        for j in range(max_words):\n",
    "            try:\n",
    "                if block[i][0][j] in word_to_ix:\n",
    "                    mat[i,j] = word_to_ix[block[i][0][j]]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    mat = torch.from_numpy(mat)\n",
    "    embeddings = torch.FloatTensor(np.array([x for _, x, _ in block]))\n",
    "    labels = torch.FloatTensor(np.array([y for _, _, y in block]))\n",
    "    return mat, embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, collate_fn=collate_fn, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_data, collate_fn=collate_fn, batch_size=test_batch_size)\n",
    "test_dataloader = DataLoader(test_data, collate_fn=collate_fn, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSI(nn.Module):\n",
    "    def __init__(self, n_ksi_embedding, n_vocab):\n",
    "        super().__init__()\n",
    "        self.ksi_embedding = nn.Linear(n_vocab, n_ksi_embedding)\n",
    "        self.ksi_attention = nn.Linear(n_ksi_embedding, n_ksi_embedding)\n",
    "        self.ksi_output = nn.Linear(n_ksi_embedding, 1)\n",
    "        \n",
    "    def forward_ksi(self, notevec, wikivec):\n",
    "        with torch.profiler.record_function(\"KSI Forward\"):\n",
    "            n = notevec.shape[0]\n",
    "            n_codes = wikivec.shape[0]\n",
    "            notevec = notevec.unsqueeze(1).expand(n, n_codes, -1)\n",
    "            wikivec = wikivec.unsqueeze(0)\n",
    "        \n",
    "            z = torch.mul(wikivec, notevec)\n",
    "            e = self.ksi_embedding(z)\n",
    "            attention_scores = torch.sigmoid(self.ksi_attention(e))\n",
    "            v = torch.mul(attention_scores, e)\n",
    "            s = self.ksi_output(v)\n",
    "            o = s.squeeze(2)\n",
    "        \n",
    "        return o\n",
    "    \n",
    "    \n",
    "class ModifiedKSI(nn.Module):\n",
    "    \"\"\"Use weighted sum of note and wiki vectors instead of vector intersection\"\"\"\n",
    "    def __init__(self, n_ksi_embedding, n_vocab):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Linear(2, 1, bias=False)\n",
    "        self.ksi_embedding = nn.Linear(n_vocab, n_ksi_embedding)\n",
    "        self.ksi_attention = nn.Linear(n_ksi_embedding, n_ksi_embedding)\n",
    "        self.ksi_output = nn.Linear(n_ksi_embedding, 1)\n",
    "        \n",
    "    def forward_ksi(self, notevec, wikivec):\n",
    "        with torch.profiler.record_function(\"Modified KSI Forward\"):\n",
    "            n = notevec.shape[0]\n",
    "            n_codes = wikivec.shape[0]\n",
    "            notevec = notevec.unsqueeze(1).expand(n, n_codes, -1)\n",
    "            wikivec = wikivec.unsqueeze(0).expand(n, n_codes, -1)\n",
    "        \n",
    "            z = self.weights(torch.stack([notevec, wikivec], dim=-1)).squeeze()\n",
    "            e = self.ksi_embedding(z)\n",
    "            attention_scores = torch.sigmoid(self.ksi_attention(e))\n",
    "            v = torch.mul(attention_scores, e)\n",
    "            s = self.ksi_output(v)\n",
    "            o = s.squeeze(2)\n",
    "        \n",
    "        return o\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_words, n_wiki, n_embedding, ksi=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksi = ksi\n",
    "        self.word_embeddings = nn.Embedding(n_words+1, n_embedding)\n",
    "        self.dropout_embedding = nn.Dropout(p=0.2)\n",
    "        self.conv1 = nn.Conv1d(n_embedding, 100, 3)\n",
    "        self.conv2 = nn.Conv1d(n_embedding, 100, 4)\n",
    "        self.conv3 = nn.Conv1d(n_embedding, 100, 5)\n",
    "        self.output = nn.Linear(n_embedding*3, n_wiki)\n",
    "    \n",
    "    def forward(self, note, notevec=None, wikivec=None):\n",
    "        # batch_size, n = note.shape\n",
    "        with torch.profiler.record_function(\"CNN Embedding\"):\n",
    "            embeddings = self.word_embeddings(note) # (batch_size, n, n_embedding)\n",
    "            embeddings = self.dropout_embedding(embeddings)\n",
    "            embeddings = embeddings.permute(0, 2, 1) # (batch_size, n_embedding, n)\n",
    "        \n",
    "        with torch.profiler.record_function(\"CNN Forward\"):\n",
    "            a1 = F.relu(self.conv1(embeddings))\n",
    "            a1 = F.max_pool1d(a1, a1.shape[2])\n",
    "            a2 = F.relu(self.conv2(embeddings))\n",
    "            a2 = F.max_pool1d(a2, a2.shape[2])\n",
    "            a3 = F.relu(self.conv3(embeddings))\n",
    "            a3 = F.max_pool1d(a3, a3.shape[2])\n",
    "            combined = torch.cat([a1, a2, a3], 1).squeeze(2)\n",
    "       \n",
    "            out = self.output(combined)\n",
    "        if self.ksi:\n",
    "            out += self.ksi.forward_ksi(notevec, wikivec)\n",
    "        \n",
    "        scores = torch.sigmoid(out)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, wikivec=None, optimizer=None, profiler=None, scheduler=None):\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        note, embeddings, labels = data\n",
    "        note = note.to(DEVICE)\n",
    "        embeddings = embeddings.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        scores = model(note, embeddings, wikivec)\n",
    "        loss = loss_function(scores, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        if profiler:\n",
    "            profiler.step()\n",
    "\n",
    "        \n",
    "def test(model, dataloader, wikivec=None, threshold=0.5, k=10, by_label=False):\n",
    "    y = []\n",
    "    yhat = []\n",
    "    recall = []\n",
    "    for data in dataloader:\n",
    "        note, embeddings, labels = data\n",
    "        note = note.to(DEVICE)\n",
    "        embeddings = embeddings.to(DEVICE)\n",
    "        out = model(note, embeddings, wikivec).cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        y.append(labels)\n",
    "        yhat.append(out)\n",
    "        \n",
    "    y = np.concatenate(y)\n",
    "    yhat = np.concatenate(yhat)\n",
    "    preds = np.array(yhat > threshold, dtype=float)\n",
    "    for i in range(yhat.shape[0]):\n",
    "        n_labels = int(y[i, :].sum())\n",
    "        topk = max(k, n_labels)\n",
    "        ind_topk = np.argpartition(yhat[i, :], -topk)[-topk:]\n",
    "        recall.append(y[i, ind_topk].sum() / n_labels if n_labels > 0 else np.nan)\n",
    "    \n",
    "    # compute macro AUC by label frequency group\n",
    "    label_freq_aucs = None\n",
    "    if by_label:\n",
    "        code_frequencies = y.sum(axis=0)\n",
    "        bin_10 = np.argwhere((code_frequencies <= 10) & (code_frequencies > 0)).squeeze()\n",
    "        bin_50 = np.argwhere((code_frequencies <= 50) & (code_frequencies > 10)).squeeze()\n",
    "        bin_100 = np.argwhere((code_frequencies <= 100) & (code_frequencies > 50)).squeeze()\n",
    "        bin_500 = np.argwhere((code_frequencies <= 500) & (code_frequencies > 100)).squeeze()\n",
    "        bin_remaining = np.argwhere(code_frequencies > 500).squeeze()\n",
    "        label_freq_aucs = {}\n",
    "        label_freq_aucs['1-10'] = roc_auc_score(y[:, bin_10], yhat[:, bin_10], average='macro')\n",
    "        label_freq_aucs['11-50'] = roc_auc_score(y[:, bin_50], yhat[:, bin_50], average='macro')\n",
    "        label_freq_aucs['51-100'] = roc_auc_score(y[:, bin_100], yhat[:, bin_100], average='macro')\n",
    "        label_freq_aucs['101-500'] = roc_auc_score(y[:, bin_500], yhat[:, bin_500], average='macro')\n",
    "        label_freq_aucs['>500'] = roc_auc_score(y[:, bin_remaining], yhat[:, bin_remaining], average='macro')\n",
    "            \n",
    "    # compute overall metrics\n",
    "    mask = np.sum(y, axis=0) > 0 # mask out classes without both positive and negative examples\n",
    "    recall = np.nanmean(recall)\n",
    "    micro_f1 = f1_score(y[:, mask], preds[:, mask], average='micro')\n",
    "    macro_f1 = f1_score(y[:, mask], preds[:, mask], average='macro')\n",
    "    micro_auc = roc_auc_score(y[:, mask], yhat[:, mask], average='micro')\n",
    "    macro_auc = roc_auc_score(y[:, mask], yhat[:, mask], average='macro')\n",
    "    return recall, micro_f1, macro_f1, micro_auc, macro_auc, label_freq_aucs\n",
    "\n",
    "\n",
    "def train_model(model, n_epochs=10, profile=False, log_path='./log'):\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_dataloader), epochs=n_epochs)\n",
    "    if profile: \n",
    "        with torch.profiler.profile(activities=[\n",
    "                torch.profiler.ProfilerActivity.CPU,\n",
    "                torch.profiler.ProfilerActivity.CUDA,\n",
    "            ], profile_memory=True, use_cuda=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(log_path)) as prof:\n",
    "            for epoch in range(n_epochs):\n",
    "                train(model, train_dataloader, loss_function, wikivec=wikivec, optimizer=optimizer, profiler=prof, scheduler=scheduler)\n",
    "                t_recall_at_k, t_micro_f1, t_macro_f1, t_micro_auc, t_macro_auc, _ = test(model, train_dataloader, wikivec)\n",
    "                v_recall_at_k, v_micro_f1, v_macro_f1, v_micro_auc, v_macro_auc, _ = test(model, val_dataloader, wikivec)\n",
    "                print(f'Epoch: {epoch+1:03d}, Train Recall@10: {t_recall_at_k:.4f}, Val Recall@10: {v_recall_at_k:.4f}' + \n",
    "                    f', Train Micro F1: {t_micro_f1:.4f}, Val Micro F1: {v_micro_f1:.4f}' +\n",
    "                    f', Train Macro F1: {t_macro_f1:.4f}, Val Macro F1: {v_macro_f1:.4f}' +\n",
    "                    f', Train Micro AUC: {t_micro_auc:.4f}, Val Micro AUC: {v_micro_auc:.4f}' +\n",
    "                    f', Train Macro AUC: {t_macro_auc:.4f}, Val Macro AUC: {v_macro_auc:.4f}')\n",
    "    else: \n",
    "        for epoch in range(n_epochs):\n",
    "            train(model, train_dataloader, loss_function, wikivec=wikivec, optimizer=optimizer, profiler=None, scheduler=scheduler)\n",
    "            t_recall_at_k, t_micro_f1, t_macro_f1, t_micro_auc, t_macro_auc, _ = test(model, train_dataloader, wikivec)\n",
    "            v_recall_at_k, v_micro_f1, v_macro_f1, v_micro_auc, v_macro_auc, _ = test(model, val_dataloader, wikivec)\n",
    "            print(f'Epoch: {epoch+1:03d}, Train Recall@10: {t_recall_at_k:.4f}, Val Recall@10: {v_recall_at_k:.4f}' + \n",
    "                f', Train Micro F1: {t_micro_f1:.4f}, Val Micro F1: {v_micro_f1:.4f}' +\n",
    "                f', Train Macro F1: {t_macro_f1:.4f}, Val Macro F1: {v_macro_f1:.4f}' +\n",
    "                f', Train Micro AUC: {t_micro_auc:.4f}, Val Micro AUC: {v_micro_auc:.4f}' +\n",
    "                f', Train Macro AUC: {t_macro_auc:.4f}, Val Macro AUC: {v_macro_auc:.4f}')\n",
    "    return prof if prof else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "save = True\n",
    "profile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-3                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-4                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-6                            [32, 344]                 103,544\n",
       "==========================================================================================\n",
       "Total params: 5,020,044\n",
       "Trainable params: 5,020,044\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.60\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 251.25\n",
       "Params size (MB): 20.08\n",
       "Estimated Total Size (MB): 273.20\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CNN(n_words, n_wiki, n_embedding)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), (batch_size, n_vocab)], dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6853, Val Recall@10: 0.6770, Train Micro F1: 0.5554, Val Micro F1: 0.5435, Train Macro F1: 0.0781, Val Macro F1: 0.0910, Train Micro AUC: 0.9592, Val Micro AUC: 0.9470, Train Macro AUC: 0.7425, Val Macro AUC: 0.7196\n",
      "Epoch: 002, Train Recall@10: 0.7393, Val Recall@10: 0.7216, Train Micro F1: 0.5910, Val Micro F1: 0.5717, Train Macro F1: 0.1092, Val Macro F1: 0.1223, Train Micro AUC: 0.9720, Val Micro AUC: 0.9589, Train Macro AUC: 0.8700, Val Macro AUC: 0.7813\n",
      "Epoch: 003, Train Recall@10: 0.7611, Val Recall@10: 0.7345, Train Micro F1: 0.6174, Val Micro F1: 0.5895, Train Macro F1: 0.1453, Val Macro F1: 0.1409, Train Micro AUC: 0.9762, Val Micro AUC: 0.9614, Train Macro AUC: 0.9165, Val Macro AUC: 0.7954\n",
      "Epoch: 004, Train Recall@10: 0.7750, Val Recall@10: 0.7398, Train Micro F1: 0.6337, Val Micro F1: 0.5960, Train Macro F1: 0.1838, Val Macro F1: 0.1534, Train Micro AUC: 0.9788, Val Micro AUC: 0.9614, Train Macro AUC: 0.9346, Val Macro AUC: 0.7901\n",
      "Epoch: 005, Train Recall@10: 0.7842, Val Recall@10: 0.7374, Train Micro F1: 0.6489, Val Micro F1: 0.6003, Train Macro F1: 0.2404, Val Macro F1: 0.1652, Train Micro AUC: 0.9806, Val Micro AUC: 0.9613, Train Macro AUC: 0.9437, Val Macro AUC: 0.7777\n",
      "Epoch: 006, Train Recall@10: 0.7905, Val Recall@10: 0.7369, Train Micro F1: 0.6574, Val Micro F1: 0.6037, Train Macro F1: 0.2918, Val Macro F1: 0.1699, Train Micro AUC: 0.9820, Val Micro AUC: 0.9609, Train Macro AUC: 0.9507, Val Macro AUC: 0.7777\n",
      "Epoch: 007, Train Recall@10: 0.8014, Val Recall@10: 0.7382, Train Micro F1: 0.6644, Val Micro F1: 0.5985, Train Macro F1: 0.3405, Val Macro F1: 0.1719, Train Micro AUC: 0.9831, Val Micro AUC: 0.9602, Train Macro AUC: 0.9546, Val Macro AUC: 0.7733\n",
      "Epoch: 008, Train Recall@10: 0.8078, Val Recall@10: 0.7382, Train Micro F1: 0.6776, Val Micro F1: 0.5989, Train Macro F1: 0.3841, Val Macro F1: 0.1721, Train Micro AUC: 0.9838, Val Micro AUC: 0.9591, Train Macro AUC: 0.9568, Val Macro AUC: 0.7630\n",
      "Epoch: 009, Train Recall@10: 0.8138, Val Recall@10: 0.7353, Train Micro F1: 0.6833, Val Micro F1: 0.6019, Train Macro F1: 0.4119, Val Macro F1: 0.1801, Train Micro AUC: 0.9847, Val Micro AUC: 0.9585, Train Macro AUC: 0.9605, Val Macro AUC: 0.7548\n",
      "Epoch: 010, Train Recall@10: 0.8179, Val Recall@10: 0.7368, Train Micro F1: 0.6891, Val Micro F1: 0.5959, Train Macro F1: 0.4348, Val Macro F1: 0.1830, Train Micro AUC: 0.9853, Val Micro AUC: 0.9575, Train Macro AUC: 0.9628, Val Macro AUC: 0.7629\n"
     ]
    }
   ],
   "source": [
    "prof_base = train_model(base_model, n_epochs=n_epochs, profile=profile, log_path='./log/CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}CNN_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7305, Test Micro F1: 0.5930, Test Macro F1: 0.1729, Test Micro AUC: 0.9583, Test Macro AUC: 0.7544\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test(base_model, \n",
    "                                                                                             test_dataloader, \n",
    "                                                                                             wikivec,\n",
    "                                                                                             by_label=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-6                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-7                            [32, 344]                 103,544\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,247,645\n",
       "Trainable params: 6,247,645\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.63\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 268.95\n",
       "Params size (MB): 24.99\n",
       "Estimated Total Size (MB): 312.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = CNN(n_words, n_wiki, n_embedding, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7485, Val Recall@10: 0.7327, Train Micro F1: 0.5878, Val Micro F1: 0.5708, Train Macro F1: 0.1517, Val Macro F1: 0.1561, Train Micro AUC: 0.9732, Val Micro AUC: 0.9640, Train Macro AUC: 0.8508, Val Macro AUC: 0.8364\n",
      "Epoch: 002, Train Recall@10: 0.7887, Val Recall@10: 0.7621, Train Micro F1: 0.6312, Val Micro F1: 0.5991, Train Macro F1: 0.2224, Val Macro F1: 0.1994, Train Micro AUC: 0.9815, Val Micro AUC: 0.9707, Train Macro AUC: 0.9197, Val Macro AUC: 0.8554\n",
      "Epoch: 003, Train Recall@10: 0.8036, Val Recall@10: 0.7644, Train Micro F1: 0.6409, Val Micro F1: 0.5997, Train Macro F1: 0.2640, Val Macro F1: 0.2041, Train Micro AUC: 0.9840, Val Micro AUC: 0.9704, Train Macro AUC: 0.9459, Val Macro AUC: 0.8483\n",
      "Epoch: 004, Train Recall@10: 0.8112, Val Recall@10: 0.7665, Train Micro F1: 0.6523, Val Micro F1: 0.6015, Train Macro F1: 0.3080, Val Macro F1: 0.2192, Train Micro AUC: 0.9848, Val Micro AUC: 0.9690, Train Macro AUC: 0.9542, Val Macro AUC: 0.8416\n",
      "Epoch: 005, Train Recall@10: 0.8164, Val Recall@10: 0.7613, Train Micro F1: 0.6633, Val Micro F1: 0.6019, Train Macro F1: 0.3522, Val Macro F1: 0.2143, Train Micro AUC: 0.9852, Val Micro AUC: 0.9671, Train Macro AUC: 0.9586, Val Macro AUC: 0.8350\n",
      "Epoch: 006, Train Recall@10: 0.8279, Val Recall@10: 0.7572, Train Micro F1: 0.6815, Val Micro F1: 0.6049, Train Macro F1: 0.4231, Val Macro F1: 0.2400, Train Micro AUC: 0.9866, Val Micro AUC: 0.9668, Train Macro AUC: 0.9647, Val Macro AUC: 0.8232\n",
      "Epoch: 007, Train Recall@10: 0.8322, Val Recall@10: 0.7524, Train Micro F1: 0.6893, Val Micro F1: 0.6027, Train Macro F1: 0.4664, Val Macro F1: 0.2416, Train Micro AUC: 0.9870, Val Micro AUC: 0.9643, Train Macro AUC: 0.9675, Val Macro AUC: 0.8216\n",
      "Epoch: 008, Train Recall@10: 0.8319, Val Recall@10: 0.7430, Train Micro F1: 0.6856, Val Micro F1: 0.5910, Train Macro F1: 0.4775, Val Macro F1: 0.2380, Train Micro AUC: 0.9868, Val Micro AUC: 0.9614, Train Macro AUC: 0.9681, Val Macro AUC: 0.8128\n",
      "Epoch: 009, Train Recall@10: 0.8369, Val Recall@10: 0.7424, Train Micro F1: 0.6849, Val Micro F1: 0.5839, Train Macro F1: 0.4677, Val Macro F1: 0.2196, Train Micro AUC: 0.9874, Val Micro AUC: 0.9601, Train Macro AUC: 0.9704, Val Macro AUC: 0.8015\n",
      "Epoch: 010, Train Recall@10: 0.8459, Val Recall@10: 0.7425, Train Micro F1: 0.6882, Val Micro F1: 0.5761, Train Macro F1: 0.5110, Val Macro F1: 0.2198, Train Micro AUC: 0.9885, Val Micro AUC: 0.9604, Train Macro AUC: 0.9743, Val Macro AUC: 0.8064\n"
     ]
    }
   ],
   "source": [
    "prof_ksi = train_model(model, n_epochs=n_epochs, profile=profile, log_path='./log/CNN_KSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}CNN_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7406, Test Micro F1: 0.5716, Test Macro F1: 0.2236, Test Micro AUC: 0.9607, Test Macro AUC: 0.8018\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test(model, \n",
    "                                                                                            test_dataloader, \n",
    "                                                                                            wikivec,\n",
    "                                                                                            by_label=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-6                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-7                            [32, 344]                 103,544\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,247,647\n",
       "Trainable params: 6,247,647\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.63\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1340.95\n",
       "Params size (MB): 24.99\n",
       "Estimated Total Size (MB): 1384.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = CNN(n_words, n_wiki, n_embedding, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24528/1663869077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprof_mod_ksi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./log/CNN_ModifiedKSI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24528/3861562249.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, n_epochs, profile, log_path)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwikivec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mt_recall_at_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_micro_f1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_macro_f1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_micro_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_macro_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mv_recall_at_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_micro_f1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_macro_f1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_micro_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_macro_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             print(f'Epoch: {epoch+1:03d}, Train Recall@10: {t_recall_at_k:.4f}, Val Recall@10: {v_recall_at_k:.4f}' + \n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24528/3861562249.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, dataloader, wikivec, threshold, k, by_label)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mnote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwikivec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deepl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24528/2695142302.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, note, notevec, wikivec)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mksi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mksi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_ksi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotevec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwikivec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24528/2695142302.py\u001b[0m in \u001b[0;36mforward_ksi\u001b[1;34m(self, notevec, wikivec)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Modified KSI Forward\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotevec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mn_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwikivec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mnotevec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotevec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_codes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mwikivec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwikivec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_codes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "prof_mod_ksi = train_model(mod_model, n_epochs=n_epochs, profile=profile, log_path='./log/CNN_ModifiedKSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}CNN_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test(mod_model, \n",
    "                                                                                            test_dataloader, \n",
    "                                                                                            wikivec,\n",
    "                                                                                            by_label=True)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aucs_base = pd.DataFrame.from_dict(\n",
    "    label_aucs_base, \n",
    "    orient='index', \n",
    "    columns=['macro_AUC']\n",
    "    ).reset_index().rename({'index': 'label_frequency'}, axis=1)\n",
    "label_aucs_base['model'] = 'CNN'\n",
    "\n",
    "label_aucs_ksi = pd.DataFrame.from_dict(\n",
    "    label_aucs_ksi, \n",
    "    orient='index', \n",
    "    columns=['macro_AUC']\n",
    "    ).reset_index().rename({'index': 'label_frequency'}, axis=1)\n",
    "label_aucs_ksi['model'] = 'KSI+CNN'\n",
    "\n",
    "label_aucs_mod = pd.DataFrame.from_dict(\n",
    "    label_aucs_mod, \n",
    "    orient='index', \n",
    "    columns=['macro_AUC']\n",
    "    ).reset_index().rename({'index': 'label_frequency'}, axis=1)\n",
    "label_aucs_mod['model'] = 'ModifiedKSI+CNN'\n",
    "\n",
    "label_aucs = pd.concat([label_aucs_base, label_aucs_ksi, label_aucs_mod], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.barplot(x='label_frequency', y='macro_AUC', hue='model', \n",
    "                 data=label_aucs[label_aucs['model'] != 'ModifiedKSI+CNN'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.barplot(x='label_frequency', y='macro_AUC', hue='model', \n",
    "                 data=label_aucs)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
