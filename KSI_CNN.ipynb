{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from KSI_models import KSI, ModifiedKSI, CNN\n",
    "from KSI_utils import load_KSI_data, train_model, test_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 100\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "save = True\n",
    "profile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'data/original/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_lengths = []\n",
    "# for data in train_dataloader:\n",
    "#     n, _, _ = data\n",
    "#     note_lengths.append(n.shape[1])\n",
    "# avg_note_size = np.round(np.array(note_lengths).mean()).astype(int)\n",
    "\n",
    "avg_note_size = 2455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─Embedding: 1-1                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-2                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-3                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-4                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-6                            [32, 344]                 103,544\n",
       "==========================================================================================\n",
       "Total params: 5,020,044\n",
       "Trainable params: 5,020,044\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.60\n",
       "==========================================================================================\n",
       "Input size (MB): 1.87\n",
       "Forward/backward pass size (MB): 251.25\n",
       "Params size (MB): 20.08\n",
       "Estimated Total Size (MB): 273.20\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = CNN(n_words, n_wiki, n_embedding)\n",
    "base_model = base_model.to(DEVICE)\n",
    "base_summary = summary(base_model, [(batch_size, avg_note_size), (batch_size, n_vocab)], dtypes=[torch.int, torch.float])\n",
    "\n",
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.5913, Val Recall@10: 0.5895, Train Micro F1: 0.4216, Val Micro F1: 0.4183, Train Macro F1: 0.0302, Val Macro F1: 0.0360, Train Micro AUC: 0.9480, Val Micro AUC: 0.9364, Train Macro AUC: 0.6611, Val Macro AUC: 0.6603\n",
      "Epoch: 002, Train Recall@10: 0.6999, Val Recall@10: 0.6923, Train Micro F1: 0.5550, Val Micro F1: 0.5478, Train Macro F1: 0.0756, Val Macro F1: 0.0895, Train Micro AUC: 0.9595, Val Micro AUC: 0.9492, Train Macro AUC: 0.7896, Val Macro AUC: 0.7591\n",
      "Epoch: 003, Train Recall@10: 0.7343, Val Recall@10: 0.7240, Train Micro F1: 0.5750, Val Micro F1: 0.5656, Train Macro F1: 0.1008, Val Macro F1: 0.1178, Train Micro AUC: 0.9657, Val Micro AUC: 0.9552, Train Macro AUC: 0.8509, Val Macro AUC: 0.7840\n",
      "Epoch: 004, Train Recall@10: 0.7554, Val Recall@10: 0.7375, Train Micro F1: 0.6057, Val Micro F1: 0.5822, Train Macro F1: 0.1481, Val Macro F1: 0.1534, Train Micro AUC: 0.9734, Val Micro AUC: 0.9603, Train Macro AUC: 0.8971, Val Macro AUC: 0.7915\n",
      "Epoch: 005, Train Recall@10: 0.7544, Val Recall@10: 0.7309, Train Micro F1: 0.6118, Val Micro F1: 0.5868, Train Macro F1: 0.1821, Val Macro F1: 0.1654, Train Micro AUC: 0.9740, Val Micro AUC: 0.9591, Train Macro AUC: 0.9128, Val Macro AUC: 0.7772\n",
      "Epoch: 006, Train Recall@10: 0.7405, Val Recall@10: 0.7135, Train Micro F1: 0.5993, Val Micro F1: 0.5691, Train Macro F1: 0.1783, Val Macro F1: 0.1537, Train Micro AUC: 0.9708, Val Micro AUC: 0.9540, Train Macro AUC: 0.9024, Val Macro AUC: 0.7574\n",
      "Epoch: 007, Train Recall@10: 0.7249, Val Recall@10: 0.6977, Train Micro F1: 0.5936, Val Micro F1: 0.5618, Train Macro F1: 0.1696, Val Macro F1: 0.1455, Train Micro AUC: 0.9692, Val Micro AUC: 0.9518, Train Macro AUC: 0.8974, Val Macro AUC: 0.7603\n",
      "Epoch: 008, Train Recall@10: 0.7221, Val Recall@10: 0.6919, Train Micro F1: 0.6008, Val Micro F1: 0.5644, Train Macro F1: 0.1704, Val Macro F1: 0.1342, Train Micro AUC: 0.9675, Val Micro AUC: 0.9489, Train Macro AUC: 0.8881, Val Macro AUC: 0.7405\n",
      "Epoch: 009, Train Recall@10: 0.7221, Val Recall@10: 0.6923, Train Micro F1: 0.6082, Val Micro F1: 0.5717, Train Macro F1: 0.1551, Val Macro F1: 0.1324, Train Micro AUC: 0.9669, Val Micro AUC: 0.9489, Train Macro AUC: 0.8887, Val Macro AUC: 0.7399\n",
      "Epoch: 010, Train Recall@10: 0.7238, Val Recall@10: 0.6940, Train Micro F1: 0.6073, Val Micro F1: 0.5657, Train Macro F1: 0.1781, Val Macro F1: 0.1351, Train Micro AUC: 0.9673, Val Micro AUC: 0.9488, Train Macro AUC: 0.8881, Val Macro AUC: 0.7341\n",
      "Epoch: 011, Train Recall@10: 0.7231, Val Recall@10: 0.6904, Train Micro F1: 0.6028, Val Micro F1: 0.5595, Train Macro F1: 0.1703, Val Macro F1: 0.1323, Train Micro AUC: 0.9677, Val Micro AUC: 0.9486, Train Macro AUC: 0.8888, Val Macro AUC: 0.7380\n",
      "Epoch: 012, Train Recall@10: 0.7360, Val Recall@10: 0.7001, Train Micro F1: 0.6225, Val Micro F1: 0.5681, Train Macro F1: 0.1950, Val Macro F1: 0.1345, Train Micro AUC: 0.9697, Val Micro AUC: 0.9504, Train Macro AUC: 0.9008, Val Macro AUC: 0.7404\n",
      "Epoch: 013, Train Recall@10: 0.7419, Val Recall@10: 0.7027, Train Micro F1: 0.6253, Val Micro F1: 0.5666, Train Macro F1: 0.2028, Val Macro F1: 0.1357, Train Micro AUC: 0.9702, Val Micro AUC: 0.9504, Train Macro AUC: 0.9048, Val Macro AUC: 0.7421\n",
      "Epoch: 014, Train Recall@10: 0.7545, Val Recall@10: 0.7104, Train Micro F1: 0.6434, Val Micro F1: 0.5809, Train Macro F1: 0.2272, Val Macro F1: 0.1488, Train Micro AUC: 0.9731, Val Micro AUC: 0.9523, Train Macro AUC: 0.9134, Val Macro AUC: 0.7486\n",
      "Epoch: 015, Train Recall@10: 0.7628, Val Recall@10: 0.7146, Train Micro F1: 0.6512, Val Micro F1: 0.5822, Train Macro F1: 0.2318, Val Macro F1: 0.1459, Train Micro AUC: 0.9746, Val Micro AUC: 0.9541, Train Macro AUC: 0.9193, Val Macro AUC: 0.7470\n",
      "Epoch: 016, Train Recall@10: 0.7704, Val Recall@10: 0.7191, Train Micro F1: 0.6580, Val Micro F1: 0.5847, Train Macro F1: 0.2630, Val Macro F1: 0.1476, Train Micro AUC: 0.9763, Val Micro AUC: 0.9551, Train Macro AUC: 0.9252, Val Macro AUC: 0.7490\n",
      "Epoch: 017, Train Recall@10: 0.7792, Val Recall@10: 0.7257, Train Micro F1: 0.6692, Val Micro F1: 0.5932, Train Macro F1: 0.2726, Val Macro F1: 0.1490, Train Micro AUC: 0.9780, Val Micro AUC: 0.9564, Train Macro AUC: 0.9308, Val Macro AUC: 0.7535\n",
      "Epoch: 018, Train Recall@10: 0.7899, Val Recall@10: 0.7326, Train Micro F1: 0.6825, Val Micro F1: 0.5955, Train Macro F1: 0.3083, Val Macro F1: 0.1585, Train Micro AUC: 0.9798, Val Micro AUC: 0.9571, Train Macro AUC: 0.9373, Val Macro AUC: 0.7589\n",
      "Epoch: 019, Train Recall@10: 0.7984, Val Recall@10: 0.7362, Train Micro F1: 0.6945, Val Micro F1: 0.6038, Train Macro F1: 0.3255, Val Macro F1: 0.1640, Train Micro AUC: 0.9814, Val Micro AUC: 0.9585, Train Macro AUC: 0.9423, Val Macro AUC: 0.7617\n",
      "Epoch: 020, Train Recall@10: 0.8062, Val Recall@10: 0.7416, Train Micro F1: 0.7034, Val Micro F1: 0.6054, Train Macro F1: 0.3471, Val Macro F1: 0.1636, Train Micro AUC: 0.9826, Val Micro AUC: 0.9593, Train Macro AUC: 0.9467, Val Macro AUC: 0.7642\n",
      "Epoch: 021, Train Recall@10: 0.8118, Val Recall@10: 0.7422, Train Micro F1: 0.7118, Val Micro F1: 0.6093, Train Macro F1: 0.3706, Val Macro F1: 0.1734, Train Micro AUC: 0.9835, Val Micro AUC: 0.9600, Train Macro AUC: 0.9488, Val Macro AUC: 0.7616\n",
      "Epoch: 022, Train Recall@10: 0.8153, Val Recall@10: 0.7452, Train Micro F1: 0.7161, Val Micro F1: 0.6093, Train Macro F1: 0.3912, Val Macro F1: 0.1743, Train Micro AUC: 0.9841, Val Micro AUC: 0.9605, Train Macro AUC: 0.9508, Val Macro AUC: 0.7633\n",
      "Epoch: 023, Train Recall@10: 0.8182, Val Recall@10: 0.7455, Train Micro F1: 0.7168, Val Micro F1: 0.6081, Train Macro F1: 0.3771, Val Macro F1: 0.1728, Train Micro AUC: 0.9845, Val Micro AUC: 0.9604, Train Macro AUC: 0.9521, Val Macro AUC: 0.7628\n",
      "Epoch: 024, Train Recall@10: 0.8193, Val Recall@10: 0.7467, Train Micro F1: 0.7171, Val Micro F1: 0.6067, Train Macro F1: 0.3886, Val Macro F1: 0.1719, Train Micro AUC: 0.9846, Val Micro AUC: 0.9604, Train Macro AUC: 0.9528, Val Macro AUC: 0.7605\n",
      "Epoch: 025, Train Recall@10: 0.8188, Val Recall@10: 0.7487, Train Micro F1: 0.7180, Val Micro F1: 0.6068, Train Macro F1: 0.3693, Val Macro F1: 0.1731, Train Micro AUC: 0.9846, Val Micro AUC: 0.9604, Train Macro AUC: 0.9522, Val Macro AUC: 0.7637\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(base_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_base = train_model(base_model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        n_epochs=n_epochs,\n",
    "                        profile=profile, \n",
    "                        log_path='./log/CNN',\n",
    "                        device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(base_model, f'{dir}CNN_model.pt')\n",
    "if profile:\n",
    "    print(prof_base.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7453, Test Micro F1: 0.6051, Test Macro F1: 0.1598, Test Micro AUC: 0.9624, Test Macro AUC: 0.7581\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_base = test_model(base_model, \n",
    "                                                                                                   test_dataloader, \n",
    "                                                                                                   wikivec,\n",
    "                                                                                                   by_label=False,\n",
    "                                                                                                   device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del base_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-6                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-7                            [32, 344]                 103,544\n",
       "├─KSI: 1-1                               --                        --\n",
       "│    └─Linear: 2-4                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-5                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-6                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,247,645\n",
       "Trainable params: 6,247,645\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.63\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 268.95\n",
       "Params size (MB): 24.99\n",
       "Estimated Total Size (MB): 312.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksi = KSI(n_embedding, n_vocab)\n",
    "ksi.to(DEVICE)\n",
    "model = CNN(n_words, n_wiki, n_embedding, ksi=ksi)\n",
    "model = model.to(DEVICE)\n",
    "ksi_summary = summary(model, [(batch_size, avg_note_size), \n",
    "                              (batch_size, n_vocab),\n",
    "                              (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "ksi_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.6860, Val Recall@10: 0.6777, Train Micro F1: 0.4977, Val Micro F1: 0.4913, Train Macro F1: 0.0719, Val Macro F1: 0.0844, Train Micro AUC: 0.9688, Val Micro AUC: 0.9607, Train Macro AUC: 0.8290, Val Macro AUC: 0.8214\n",
      "Epoch: 002, Train Recall@10: 0.7488, Val Recall@10: 0.7337, Train Micro F1: 0.5747, Val Micro F1: 0.5618, Train Macro F1: 0.1345, Val Macro F1: 0.1537, Train Micro AUC: 0.9737, Val Micro AUC: 0.9652, Train Macro AUC: 0.8951, Val Macro AUC: 0.8605\n",
      "Epoch: 003, Train Recall@10: 0.7740, Val Recall@10: 0.7558, Train Micro F1: 0.6019, Val Micro F1: 0.5818, Train Macro F1: 0.1905, Val Macro F1: 0.1917, Train Micro AUC: 0.9775, Val Micro AUC: 0.9684, Train Macro AUC: 0.9123, Val Macro AUC: 0.8674\n",
      "Epoch: 004, Train Recall@10: 0.7981, Val Recall@10: 0.7692, Train Micro F1: 0.6313, Val Micro F1: 0.5986, Train Macro F1: 0.2742, Val Macro F1: 0.2200, Train Micro AUC: 0.9826, Val Micro AUC: 0.9714, Train Macro AUC: 0.9327, Val Macro AUC: 0.8596\n",
      "Epoch: 005, Train Recall@10: 0.7950, Val Recall@10: 0.7607, Train Micro F1: 0.6395, Val Micro F1: 0.6015, Train Macro F1: 0.2868, Val Macro F1: 0.2198, Train Micro AUC: 0.9825, Val Micro AUC: 0.9699, Train Macro AUC: 0.9427, Val Macro AUC: 0.8498\n",
      "Epoch: 006, Train Recall@10: 0.7810, Val Recall@10: 0.7460, Train Micro F1: 0.6079, Val Micro F1: 0.5662, Train Macro F1: 0.2718, Val Macro F1: 0.1840, Train Micro AUC: 0.9802, Val Micro AUC: 0.9653, Train Macro AUC: 0.9349, Val Macro AUC: 0.8335\n",
      "Epoch: 007, Train Recall@10: 0.7857, Val Recall@10: 0.7466, Train Micro F1: 0.6316, Val Micro F1: 0.5896, Train Macro F1: 0.2911, Val Macro F1: 0.1961, Train Micro AUC: 0.9809, Val Micro AUC: 0.9667, Train Macro AUC: 0.9345, Val Macro AUC: 0.8428\n",
      "Epoch: 008, Train Recall@10: 0.7829, Val Recall@10: 0.7394, Train Micro F1: 0.6220, Val Micro F1: 0.5773, Train Macro F1: 0.2753, Val Macro F1: 0.1957, Train Micro AUC: 0.9808, Val Micro AUC: 0.9658, Train Macro AUC: 0.9371, Val Macro AUC: 0.8464\n",
      "Epoch: 009, Train Recall@10: 0.7784, Val Recall@10: 0.7398, Train Micro F1: 0.6157, Val Micro F1: 0.5709, Train Macro F1: 0.2610, Val Macro F1: 0.1819, Train Micro AUC: 0.9800, Val Micro AUC: 0.9655, Train Macro AUC: 0.9349, Val Macro AUC: 0.8361\n",
      "Epoch: 010, Train Recall@10: 0.7787, Val Recall@10: 0.7386, Train Micro F1: 0.6100, Val Micro F1: 0.5616, Train Macro F1: 0.2525, Val Macro F1: 0.1846, Train Micro AUC: 0.9802, Val Micro AUC: 0.9644, Train Macro AUC: 0.9350, Val Macro AUC: 0.8369\n",
      "Epoch: 011, Train Recall@10: 0.7825, Val Recall@10: 0.7351, Train Micro F1: 0.6183, Val Micro F1: 0.5642, Train Macro F1: 0.2920, Val Macro F1: 0.2071, Train Micro AUC: 0.9801, Val Micro AUC: 0.9632, Train Macro AUC: 0.9377, Val Macro AUC: 0.8359\n",
      "Epoch: 012, Train Recall@10: 0.7881, Val Recall@10: 0.7399, Train Micro F1: 0.6309, Val Micro F1: 0.5742, Train Macro F1: 0.3005, Val Macro F1: 0.2186, Train Micro AUC: 0.9812, Val Micro AUC: 0.9644, Train Macro AUC: 0.9400, Val Macro AUC: 0.8370\n",
      "Epoch: 013, Train Recall@10: 0.7936, Val Recall@10: 0.7432, Train Micro F1: 0.6436, Val Micro F1: 0.5842, Train Macro F1: 0.3195, Val Macro F1: 0.2197, Train Micro AUC: 0.9825, Val Micro AUC: 0.9666, Train Macro AUC: 0.9426, Val Macro AUC: 0.8428\n",
      "Epoch: 014, Train Recall@10: 0.7989, Val Recall@10: 0.7474, Train Micro F1: 0.6481, Val Micro F1: 0.5829, Train Macro F1: 0.3336, Val Macro F1: 0.2183, Train Micro AUC: 0.9832, Val Micro AUC: 0.9662, Train Macro AUC: 0.9477, Val Macro AUC: 0.8425\n",
      "Epoch: 015, Train Recall@10: 0.8042, Val Recall@10: 0.7484, Train Micro F1: 0.6514, Val Micro F1: 0.5791, Train Macro F1: 0.3398, Val Macro F1: 0.2247, Train Micro AUC: 0.9840, Val Micro AUC: 0.9670, Train Macro AUC: 0.9511, Val Macro AUC: 0.8401\n",
      "Epoch: 016, Train Recall@10: 0.8020, Val Recall@10: 0.7439, Train Micro F1: 0.6553, Val Micro F1: 0.5837, Train Macro F1: 0.3545, Val Macro F1: 0.2160, Train Micro AUC: 0.9839, Val Micro AUC: 0.9648, Train Macro AUC: 0.9521, Val Macro AUC: 0.8380\n",
      "Epoch: 017, Train Recall@10: 0.8109, Val Recall@10: 0.7481, Train Micro F1: 0.6691, Val Micro F1: 0.5925, Train Macro F1: 0.3730, Val Macro F1: 0.2224, Train Micro AUC: 0.9850, Val Micro AUC: 0.9661, Train Macro AUC: 0.9552, Val Macro AUC: 0.8410\n",
      "Epoch: 018, Train Recall@10: 0.8173, Val Recall@10: 0.7468, Train Micro F1: 0.6733, Val Micro F1: 0.5900, Train Macro F1: 0.3963, Val Macro F1: 0.2248, Train Micro AUC: 0.9858, Val Micro AUC: 0.9661, Train Macro AUC: 0.9596, Val Macro AUC: 0.8332\n",
      "Epoch: 019, Train Recall@10: 0.8266, Val Recall@10: 0.7510, Train Micro F1: 0.6807, Val Micro F1: 0.5909, Train Macro F1: 0.4161, Val Macro F1: 0.2259, Train Micro AUC: 0.9868, Val Micro AUC: 0.9659, Train Macro AUC: 0.9629, Val Macro AUC: 0.8393\n",
      "Epoch: 020, Train Recall@10: 0.8357, Val Recall@10: 0.7537, Train Micro F1: 0.6912, Val Micro F1: 0.5903, Train Macro F1: 0.4386, Val Macro F1: 0.2290, Train Micro AUC: 0.9881, Val Micro AUC: 0.9661, Train Macro AUC: 0.9665, Val Macro AUC: 0.8342\n",
      "Epoch: 021, Train Recall@10: 0.8451, Val Recall@10: 0.7552, Train Micro F1: 0.7085, Val Micro F1: 0.6001, Train Macro F1: 0.4813, Val Macro F1: 0.2399, Train Micro AUC: 0.9892, Val Micro AUC: 0.9668, Train Macro AUC: 0.9700, Val Macro AUC: 0.8355\n",
      "Epoch: 022, Train Recall@10: 0.8528, Val Recall@10: 0.7587, Train Micro F1: 0.7166, Val Micro F1: 0.6030, Train Macro F1: 0.4856, Val Macro F1: 0.2398, Train Micro AUC: 0.9902, Val Micro AUC: 0.9673, Train Macro AUC: 0.9731, Val Macro AUC: 0.8348\n",
      "Epoch: 023, Train Recall@10: 0.8596, Val Recall@10: 0.7629, Train Micro F1: 0.7225, Val Micro F1: 0.6033, Train Macro F1: 0.5110, Val Macro F1: 0.2389, Train Micro AUC: 0.9909, Val Micro AUC: 0.9680, Train Macro AUC: 0.9753, Val Macro AUC: 0.8369\n",
      "Epoch: 024, Train Recall@10: 0.8624, Val Recall@10: 0.7637, Train Micro F1: 0.7270, Val Micro F1: 0.6044, Train Macro F1: 0.5126, Val Macro F1: 0.2409, Train Micro AUC: 0.9912, Val Micro AUC: 0.9676, Train Macro AUC: 0.9766, Val Macro AUC: 0.8327\n",
      "Epoch: 025, Train Recall@10: 0.8629, Val Recall@10: 0.7645, Train Micro F1: 0.7271, Val Micro F1: 0.6060, Train Macro F1: 0.5092, Val Macro F1: 0.2444, Train Micro AUC: 0.9912, Val Micro AUC: 0.9677, Train Macro AUC: 0.9764, Val Macro AUC: 0.8375\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_ksi = train_model(model, \n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       wikivec=wikivec,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       n_epochs=n_epochs, \n",
    "                       profile=profile, \n",
    "                       log_path='./log/CNN_KSI',\n",
    "                       device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(model, f'{dir}CNN_KSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7589, Test Micro F1: 0.5992, Test Macro F1: 0.2207, Test Micro AUC: 0.9691, Test Macro AUC: 0.8238\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_ksi = test_model(model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run modified KSI using frequency vectors rather than binary vectors\n",
    "dir = 'data/original_freqs/'\n",
    "loaders, wikivec, word_to_ix = load_KSI_data(dir=dir, \n",
    "                                             batch_size=batch_size, \n",
    "                                             train=True, \n",
    "                                             val=True, \n",
    "                                             test=True, \n",
    "                                             device=DEVICE)\n",
    "train_dataloader = loaders['train']\n",
    "val_dataloader = loaders['val']\n",
    "test_dataloader = loaders['test']\n",
    "\n",
    "n_wiki, n_vocab = wikivec.shape\n",
    "n_words = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      --                        --\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-1                       --                        (recursive)\n",
       "│    └─Linear: 2-2                       --                        (recursive)\n",
       "│    └─Linear: 2-3                       --                        (recursive)\n",
       "│    └─Linear: 2-4                       --                        (recursive)\n",
       "├─Embedding: 1-2                         [32, 2455, 100]           4,796,200\n",
       "├─Dropout: 1-3                           [32, 2455, 100]           --\n",
       "├─Conv1d: 1-4                            [32, 100, 2453]           30,100\n",
       "├─Conv1d: 1-5                            [32, 100, 2452]           40,100\n",
       "├─Conv1d: 1-6                            [32, 100, 2451]           50,100\n",
       "├─Linear: 1-7                            [32, 344]                 103,544\n",
       "├─ModifiedKSI: 1-1                       --                        --\n",
       "│    └─Linear: 2-5                       [32, 344, 12173, 1]       2\n",
       "│    └─Linear: 2-6                       [32, 344, 100]            1,217,400\n",
       "│    └─Linear: 2-7                       [32, 344, 100]            10,100\n",
       "│    └─Linear: 2-8                       [32, 344, 1]              101\n",
       "==========================================================================================\n",
       "Total params: 6,247,647\n",
       "Trainable params: 6,247,647\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.63\n",
       "==========================================================================================\n",
       "Input size (MB): 18.62\n",
       "Forward/backward pass size (MB): 1340.95\n",
       "Params size (MB): 24.99\n",
       "Estimated Total Size (MB): 1384.57\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_ksi = ModifiedKSI(n_embedding, n_vocab)\n",
    "mod_ksi.to(DEVICE)\n",
    "mod_model = CNN(n_words, n_wiki, n_embedding, ksi=mod_ksi)\n",
    "mod_model = mod_model.to(DEVICE)\n",
    "mod_summary = summary(mod_model, [(batch_size, avg_note_size), \n",
    "                                  (batch_size, n_vocab),\n",
    "                                  (n_wiki, n_vocab)], \n",
    "                      dtypes=[torch.int, torch.float, torch.float])\n",
    "\n",
    "mod_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Recall@10: 0.7014, Val Recall@10: 0.6963, Train Micro F1: 0.5071, Val Micro F1: 0.4998, Train Macro F1: 0.0824, Val Macro F1: 0.0988, Train Micro AUC: 0.9703, Val Micro AUC: 0.9634, Train Macro AUC: 0.8481, Val Macro AUC: 0.8548\n",
      "Epoch: 002, Train Recall@10: 0.7532, Val Recall@10: 0.7482, Train Micro F1: 0.5805, Val Micro F1: 0.5721, Train Macro F1: 0.1324, Val Macro F1: 0.1587, Train Micro AUC: 0.9744, Val Micro AUC: 0.9682, Train Macro AUC: 0.8968, Val Macro AUC: 0.8909\n",
      "Epoch: 003, Train Recall@10: 0.7652, Val Recall@10: 0.7596, Train Micro F1: 0.5838, Val Micro F1: 0.5720, Train Macro F1: 0.1571, Val Macro F1: 0.1732, Train Micro AUC: 0.9760, Val Micro AUC: 0.9690, Train Macro AUC: 0.9051, Val Macro AUC: 0.8782\n",
      "Epoch: 004, Train Recall@10: 0.7964, Val Recall@10: 0.7782, Train Micro F1: 0.6242, Val Micro F1: 0.6033, Train Macro F1: 0.2452, Val Macro F1: 0.2187, Train Micro AUC: 0.9826, Val Micro AUC: 0.9740, Train Macro AUC: 0.9285, Val Macro AUC: 0.8738\n",
      "Epoch: 005, Train Recall@10: 0.7974, Val Recall@10: 0.7768, Train Micro F1: 0.6214, Val Micro F1: 0.5969, Train Macro F1: 0.2641, Val Macro F1: 0.2082, Train Micro AUC: 0.9828, Val Micro AUC: 0.9730, Train Macro AUC: 0.9388, Val Macro AUC: 0.8667\n",
      "Epoch: 006, Train Recall@10: 0.7929, Val Recall@10: 0.7723, Train Micro F1: 0.6115, Val Micro F1: 0.5842, Train Macro F1: 0.2596, Val Macro F1: 0.2057, Train Micro AUC: 0.9819, Val Micro AUC: 0.9718, Train Macro AUC: 0.9324, Val Macro AUC: 0.8688\n",
      "Epoch: 007, Train Recall@10: 0.7893, Val Recall@10: 0.7673, Train Micro F1: 0.6049, Val Micro F1: 0.5784, Train Macro F1: 0.2327, Val Macro F1: 0.1960, Train Micro AUC: 0.9815, Val Micro AUC: 0.9706, Train Macro AUC: 0.9316, Val Macro AUC: 0.8634\n",
      "Epoch: 008, Train Recall@10: 0.7898, Val Recall@10: 0.7646, Train Micro F1: 0.6121, Val Micro F1: 0.5825, Train Macro F1: 0.2518, Val Macro F1: 0.2042, Train Micro AUC: 0.9818, Val Micro AUC: 0.9709, Train Macro AUC: 0.9344, Val Macro AUC: 0.8658\n",
      "Epoch: 009, Train Recall@10: 0.7964, Val Recall@10: 0.7712, Train Micro F1: 0.6126, Val Micro F1: 0.5769, Train Macro F1: 0.2629, Val Macro F1: 0.2072, Train Micro AUC: 0.9822, Val Micro AUC: 0.9711, Train Macro AUC: 0.9344, Val Macro AUC: 0.8738\n",
      "Epoch: 010, Train Recall@10: 0.8006, Val Recall@10: 0.7689, Train Micro F1: 0.6305, Val Micro F1: 0.5915, Train Macro F1: 0.2883, Val Macro F1: 0.2178, Train Micro AUC: 0.9827, Val Micro AUC: 0.9716, Train Macro AUC: 0.9381, Val Macro AUC: 0.8685\n",
      "Epoch: 011, Train Recall@10: 0.8059, Val Recall@10: 0.7696, Train Micro F1: 0.6378, Val Micro F1: 0.5945, Train Macro F1: 0.3106, Val Macro F1: 0.2304, Train Micro AUC: 0.9837, Val Micro AUC: 0.9724, Train Macro AUC: 0.9420, Val Macro AUC: 0.8670\n",
      "Epoch: 012, Train Recall@10: 0.8093, Val Recall@10: 0.7682, Train Micro F1: 0.6390, Val Micro F1: 0.5906, Train Macro F1: 0.3157, Val Macro F1: 0.2356, Train Micro AUC: 0.9842, Val Micro AUC: 0.9720, Train Macro AUC: 0.9440, Val Macro AUC: 0.8723\n",
      "Epoch: 013, Train Recall@10: 0.8141, Val Recall@10: 0.7663, Train Micro F1: 0.6500, Val Micro F1: 0.5934, Train Macro F1: 0.3342, Val Macro F1: 0.2413, Train Micro AUC: 0.9849, Val Micro AUC: 0.9714, Train Macro AUC: 0.9484, Val Macro AUC: 0.8561\n",
      "Epoch: 014, Train Recall@10: 0.8201, Val Recall@10: 0.7644, Train Micro F1: 0.6631, Val Micro F1: 0.5995, Train Macro F1: 0.3588, Val Macro F1: 0.2350, Train Micro AUC: 0.9857, Val Micro AUC: 0.9709, Train Macro AUC: 0.9505, Val Macro AUC: 0.8534\n",
      "Epoch: 015, Train Recall@10: 0.8226, Val Recall@10: 0.7612, Train Micro F1: 0.6722, Val Micro F1: 0.6022, Train Macro F1: 0.3702, Val Macro F1: 0.2480, Train Micro AUC: 0.9863, Val Micro AUC: 0.9707, Train Macro AUC: 0.9544, Val Macro AUC: 0.8505\n",
      "Epoch: 016, Train Recall@10: 0.8294, Val Recall@10: 0.7593, Train Micro F1: 0.6731, Val Micro F1: 0.5945, Train Macro F1: 0.3904, Val Macro F1: 0.2383, Train Micro AUC: 0.9870, Val Micro AUC: 0.9704, Train Macro AUC: 0.9569, Val Macro AUC: 0.8494\n",
      "Epoch: 017, Train Recall@10: 0.8336, Val Recall@10: 0.7565, Train Micro F1: 0.6739, Val Micro F1: 0.5917, Train Macro F1: 0.4164, Val Macro F1: 0.2342, Train Micro AUC: 0.9874, Val Micro AUC: 0.9689, Train Macro AUC: 0.9595, Val Macro AUC: 0.8390\n",
      "Epoch: 018, Train Recall@10: 0.8417, Val Recall@10: 0.7576, Train Micro F1: 0.6753, Val Micro F1: 0.5832, Train Macro F1: 0.4362, Val Macro F1: 0.2364, Train Micro AUC: 0.9884, Val Micro AUC: 0.9687, Train Macro AUC: 0.9629, Val Macro AUC: 0.8454\n",
      "Epoch: 019, Train Recall@10: 0.8497, Val Recall@10: 0.7585, Train Micro F1: 0.6933, Val Micro F1: 0.5919, Train Macro F1: 0.4723, Val Macro F1: 0.2528, Train Micro AUC: 0.9893, Val Micro AUC: 0.9688, Train Macro AUC: 0.9664, Val Macro AUC: 0.8370\n",
      "Epoch: 020, Train Recall@10: 0.8559, Val Recall@10: 0.7581, Train Micro F1: 0.7196, Val Micro F1: 0.6047, Train Macro F1: 0.5063, Val Macro F1: 0.2559, Train Micro AUC: 0.9900, Val Micro AUC: 0.9685, Train Macro AUC: 0.9691, Val Macro AUC: 0.8333\n",
      "Epoch: 021, Train Recall@10: 0.8600, Val Recall@10: 0.7576, Train Micro F1: 0.7272, Val Micro F1: 0.6070, Train Macro F1: 0.5250, Val Macro F1: 0.2523, Train Micro AUC: 0.9904, Val Micro AUC: 0.9681, Train Macro AUC: 0.9704, Val Macro AUC: 0.8261\n",
      "Epoch: 022, Train Recall@10: 0.8652, Val Recall@10: 0.7586, Train Micro F1: 0.7295, Val Micro F1: 0.6050, Train Macro F1: 0.5145, Val Macro F1: 0.2431, Train Micro AUC: 0.9909, Val Micro AUC: 0.9680, Train Macro AUC: 0.9721, Val Macro AUC: 0.8312\n",
      "Epoch: 023, Train Recall@10: 0.8713, Val Recall@10: 0.7604, Train Micro F1: 0.7366, Val Micro F1: 0.6016, Train Macro F1: 0.5451, Val Macro F1: 0.2436, Train Micro AUC: 0.9914, Val Micro AUC: 0.9680, Train Macro AUC: 0.9735, Val Macro AUC: 0.8240\n",
      "Epoch: 024, Train Recall@10: 0.8746, Val Recall@10: 0.7613, Train Micro F1: 0.7425, Val Micro F1: 0.6019, Train Macro F1: 0.5568, Val Macro F1: 0.2491, Train Micro AUC: 0.9917, Val Micro AUC: 0.9678, Train Macro AUC: 0.9749, Val Macro AUC: 0.8228\n",
      "Epoch: 025, Train Recall@10: 0.8757, Val Recall@10: 0.7606, Train Micro F1: 0.7445, Val Micro F1: 0.6027, Train Macro F1: 0.5527, Val Macro F1: 0.2465, Train Micro AUC: 0.9918, Val Micro AUC: 0.9680, Train Macro AUC: 0.9752, Val Macro AUC: 0.8303\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(mod_model.parameters())\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), \n",
    "                                          epochs=n_epochs)\n",
    "prof_mod_ksi = train_model(mod_model, \n",
    "                           train_dataloader=train_dataloader,\n",
    "                           val_dataloader=val_dataloader,\n",
    "                           wikivec=wikivec,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler,\n",
    "                           n_epochs=n_epochs, \n",
    "                           profile=profile, \n",
    "                           log_path='./log/CNN_ModifiedKSI',\n",
    "                           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    torch.save(mod_model, f'{dir}CNN_ModifiedKSI_model.pt')\n",
    "if profile:\n",
    "    print(prof_mod_ksi.key_averages(group_by_stack_n=5).table(sort_by='self_cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@10: 0.7571, Test Micro F1: 0.6018, Test Macro F1: 0.2452, Test Micro AUC: 0.9703, Test Macro AUC: 0.8288\n"
     ]
    }
   ],
   "source": [
    "tt_recall_at_k, tt_micro_f1, tt_macro_f1, tt_micro_auc, tt_macro_auc, label_aucs_mod = test_model(mod_model, \n",
    "                                                                                                  test_dataloader, \n",
    "                                                                                                  wikivec,\n",
    "                                                                                                  by_label=True,\n",
    "                                                                                                  device=DEVICE)\n",
    "print(f'Test Recall@10: {tt_recall_at_k:.4f}, Test Micro F1: {tt_micro_f1:.4f}, Test Macro F1: {tt_macro_f1:.4f}' +\n",
    "      f', Test Micro AUC: {tt_micro_auc:.4f}, Test Macro AUC: {tt_macro_auc:.4f}')\n",
    "del mod_model\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e07979f6a7af2a0b0e861d549d9c40e5b4b1911b131063753718048dd868ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
